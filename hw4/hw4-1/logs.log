2024-11-28 16:55:01,023:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-28 16:55:01,023:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-28 16:55:01,024:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-28 16:55:01,024:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-28 16:58:20,820:INFO:PyCaret ClassificationExperiment
2024-11-28 16:58:20,820:INFO:Logging name: clf-default-name
2024-11-28 16:58:20,821:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-11-28 16:58:20,821:INFO:version 3.3.2
2024-11-28 16:58:20,821:INFO:Initializing setup()
2024-11-28 16:58:20,821:INFO:self.USI: 5c07
2024-11-28 16:58:20,821:INFO:self._variable_keys: {'exp_name_log', 'y_test', 'idx', 'y_train', 'log_plots_param', 'memory', 'pipeline', 'X', 'gpu_param', 'fold_generator', 'logging_param', 'n_jobs_param', 'exp_id', 'is_multiclass', 'fix_imbalance', '_available_plots', 'html_param', 'gpu_n_jobs_param', 'X_test', 'X_train', 'y', 'data', 'fold_shuffle_param', 'seed', 'fold_groups_param', '_ml_usecase', 'target_param', 'USI'}
2024-11-28 16:58:20,821:INFO:Checking environment
2024-11-28 16:58:20,821:INFO:python_version: 3.10.11
2024-11-28 16:58:20,821:INFO:python_build: ('tags/v3.10.11:7d4cc5a', 'Apr  5 2023 00:38:17')
2024-11-28 16:58:20,821:INFO:machine: AMD64
2024-11-28 16:58:20,821:INFO:platform: Windows-10-10.0.19045-SP0
2024-11-28 16:58:20,824:INFO:Memory: svmem(total=34216488960, available=22337622016, percent=34.7, used=11878866944, free=22337622016)
2024-11-28 16:58:20,824:INFO:Physical Core: 6
2024-11-28 16:58:20,824:INFO:Logical Core: 6
2024-11-28 16:58:20,824:INFO:Checking libraries
2024-11-28 16:58:20,824:INFO:System:
2024-11-28 16:58:20,824:INFO:    python: 3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]
2024-11-28 16:58:20,824:INFO:executable: c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\Scripts\python.exe
2024-11-28 16:58:20,824:INFO:   machine: Windows-10-10.0.19045-SP0
2024-11-28 16:58:20,824:INFO:PyCaret required dependencies:
2024-11-28 16:58:20,866:INFO:                 pip: 23.0.1
2024-11-28 16:58:20,866:INFO:          setuptools: 65.5.0
2024-11-28 16:58:20,866:INFO:             pycaret: 3.3.2
2024-11-28 16:58:20,866:INFO:             IPython: 8.29.0
2024-11-28 16:58:20,866:INFO:          ipywidgets: 8.1.5
2024-11-28 16:58:20,866:INFO:                tqdm: 4.67.1
2024-11-28 16:58:20,866:INFO:               numpy: 1.26.4
2024-11-28 16:58:20,866:INFO:              pandas: 2.1.4
2024-11-28 16:58:20,866:INFO:              jinja2: 3.1.4
2024-11-28 16:58:20,866:INFO:               scipy: 1.11.4
2024-11-28 16:58:20,866:INFO:              joblib: 1.3.2
2024-11-28 16:58:20,866:INFO:             sklearn: 1.4.2
2024-11-28 16:58:20,866:INFO:                pyod: 2.0.2
2024-11-28 16:58:20,866:INFO:            imblearn: 0.12.4
2024-11-28 16:58:20,866:INFO:   category_encoders: 2.6.4
2024-11-28 16:58:20,866:INFO:            lightgbm: 4.5.0
2024-11-28 16:58:20,866:INFO:               numba: 0.60.0
2024-11-28 16:58:20,866:INFO:            requests: 2.32.3
2024-11-28 16:58:20,867:INFO:          matplotlib: 3.7.5
2024-11-28 16:58:20,867:INFO:          scikitplot: 0.3.7
2024-11-28 16:58:20,867:INFO:         yellowbrick: 1.5
2024-11-28 16:58:20,867:INFO:              plotly: 5.24.1
2024-11-28 16:58:20,867:INFO:    plotly-resampler: Not installed
2024-11-28 16:58:20,867:INFO:             kaleido: 0.2.1
2024-11-28 16:58:20,867:INFO:           schemdraw: 0.15
2024-11-28 16:58:20,867:INFO:         statsmodels: 0.14.4
2024-11-28 16:58:20,867:INFO:              sktime: 0.26.0
2024-11-28 16:58:20,867:INFO:               tbats: 1.1.3
2024-11-28 16:58:20,867:INFO:            pmdarima: 2.0.4
2024-11-28 16:58:20,867:INFO:              psutil: 6.1.0
2024-11-28 16:58:20,867:INFO:          markupsafe: 3.0.2
2024-11-28 16:58:20,867:INFO:             pickle5: Not installed
2024-11-28 16:58:20,867:INFO:         cloudpickle: 3.1.0
2024-11-28 16:58:20,867:INFO:         deprecation: 2.1.0
2024-11-28 16:58:20,867:INFO:              xxhash: 3.5.0
2024-11-28 16:58:20,867:INFO:           wurlitzer: Not installed
2024-11-28 16:58:20,867:INFO:PyCaret optional dependencies:
2024-11-28 16:58:27,888:INFO:                shap: Not installed
2024-11-28 16:58:27,888:INFO:           interpret: Not installed
2024-11-28 16:58:27,889:INFO:                umap: Not installed
2024-11-28 16:58:27,889:INFO:     ydata_profiling: Not installed
2024-11-28 16:58:27,889:INFO:  explainerdashboard: Not installed
2024-11-28 16:58:27,889:INFO:             autoviz: Not installed
2024-11-28 16:58:27,889:INFO:           fairlearn: Not installed
2024-11-28 16:58:27,889:INFO:          deepchecks: Not installed
2024-11-28 16:58:27,889:INFO:             xgboost: 2.1.3
2024-11-28 16:58:27,889:INFO:            catboost: 1.2.7
2024-11-28 16:58:27,889:INFO:              kmodes: Not installed
2024-11-28 16:58:27,889:INFO:             mlxtend: 0.23.3
2024-11-28 16:58:27,889:INFO:       statsforecast: Not installed
2024-11-28 16:58:27,889:INFO:        tune_sklearn: Not installed
2024-11-28 16:58:27,889:INFO:                 ray: Not installed
2024-11-28 16:58:27,889:INFO:            hyperopt: Not installed
2024-11-28 16:58:27,889:INFO:              optuna: Not installed
2024-11-28 16:58:27,889:INFO:               skopt: Not installed
2024-11-28 16:58:27,889:INFO:              mlflow: Not installed
2024-11-28 16:58:27,889:INFO:              gradio: Not installed
2024-11-28 16:58:27,889:INFO:             fastapi: Not installed
2024-11-28 16:58:27,889:INFO:             uvicorn: Not installed
2024-11-28 16:58:27,889:INFO:              m2cgen: Not installed
2024-11-28 16:58:27,889:INFO:           evidently: Not installed
2024-11-28 16:58:27,889:INFO:               fugue: Not installed
2024-11-28 16:58:27,889:INFO:           streamlit: 1.39.0
2024-11-28 16:58:27,889:INFO:             prophet: Not installed
2024-11-28 16:58:27,889:INFO:None
2024-11-28 16:58:27,890:INFO:Set up data.
2024-11-28 16:58:27,894:INFO:Set up folding strategy.
2024-11-28 16:58:27,894:INFO:Set up train/test split.
2024-11-28 16:58:27,899:INFO:Set up index.
2024-11-28 16:58:27,899:INFO:Assigning column types.
2024-11-28 16:58:27,902:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-28 16:58:27,940:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-28 16:58:27,942:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-28 16:58:28,037:INFO:Soft dependency imported: xgboost: 2.1.3
2024-11-28 16:58:28,039:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-28 16:58:29,776:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-28 16:58:29,777:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-28 16:58:29,820:INFO:Soft dependency imported: xgboost: 2.1.3
2024-11-28 16:58:29,825:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-28 16:58:29,826:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-28 16:58:29,896:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-28 16:58:29,941:INFO:Soft dependency imported: xgboost: 2.1.3
2024-11-28 16:58:29,945:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-28 16:58:30,018:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-28 16:58:30,063:INFO:Soft dependency imported: xgboost: 2.1.3
2024-11-28 16:58:30,067:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-28 16:58:30,068:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-11-28 16:58:30,184:INFO:Soft dependency imported: xgboost: 2.1.3
2024-11-28 16:58:30,188:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-28 16:58:30,303:INFO:Soft dependency imported: xgboost: 2.1.3
2024-11-28 16:58:30,309:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-28 16:58:30,310:INFO:Preparing preprocessing pipeline...
2024-11-28 16:58:30,311:INFO:Set up simple imputation.
2024-11-28 16:58:30,314:INFO:Set up encoding of ordinal features.
2024-11-28 16:58:30,315:INFO:Set up encoding of categorical features.
2024-11-28 16:58:30,380:INFO:Finished creating preprocessing pipeline.
2024-11-28 16:58:30,394:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\tsai\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare',
                                             'FamilySize'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('...
                                                               mapping=[{'col': 'Sex',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['Embarked'],
                                    transformer=OneHotEncoder(cols=['Embarked'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-11-28 16:58:30,394:INFO:Creating final display dataframe.
2024-11-28 16:58:30,557:INFO:Setup _display_container:                     Description             Value
0                    Session id              8973
1                        Target          Survived
2                   Target type            Binary
3           Original data shape         (891, 10)
4        Transformed data shape         (891, 12)
5   Transformed train set shape         (623, 12)
6    Transformed test set shape         (268, 12)
7              Numeric features                 7
8          Categorical features                 2
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              5c07
2024-11-28 16:58:30,627:INFO:Soft dependency imported: xgboost: 2.1.3
2024-11-28 16:58:30,629:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-28 16:58:30,691:INFO:Soft dependency imported: xgboost: 2.1.3
2024-11-28 16:58:30,693:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-28 16:58:30,694:INFO:setup() successfully completed in 9.88s...............
2024-11-28 16:58:30,694:INFO:Initializing compare_models()
2024-11-28 16:58:30,694:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC59ADA0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=16, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC59ADA0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 16, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-11-28 16:58:30,694:INFO:Checking exceptions
2024-11-28 16:58:30,697:INFO:Preparing display monitor
2024-11-28 16:58:30,719:INFO:Initializing Logistic Regression
2024-11-28 16:58:30,719:INFO:Total runtime is 0.0 minutes
2024-11-28 16:58:30,722:INFO:SubProcess create_model() called ==================================
2024-11-28 16:58:30,723:INFO:Initializing create_model()
2024-11-28 16:58:30,723:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC59ADA0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8D7B04C10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 16:58:30,723:INFO:Checking exceptions
2024-11-28 16:58:30,723:INFO:Importing libraries
2024-11-28 16:58:30,723:INFO:Copying training dataset
2024-11-28 16:58:30,729:INFO:Defining folds
2024-11-28 16:58:30,729:INFO:Declaring metric variables
2024-11-28 16:58:30,733:INFO:Importing untrained model
2024-11-28 16:58:30,737:INFO:Logistic Regression Imported successfully
2024-11-28 16:58:30,744:INFO:Starting cross validation
2024-11-28 16:58:30,745:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 16:58:33,927:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 16:58:33,928:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 16:58:33,932:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 16:58:33,970:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 16:58:34,129:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 16:58:34,171:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 16:58:34,192:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 16:58:34,196:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 16:58:34,201:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 16:58:34,297:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 16:58:34,339:INFO:Calculating mean and std
2024-11-28 16:58:34,340:INFO:Creating metrics dataframe
2024-11-28 16:58:34,342:INFO:Uploading results into container
2024-11-28 16:58:34,343:INFO:Uploading model into container now
2024-11-28 16:58:34,343:INFO:_master_model_container: 1
2024-11-28 16:58:34,343:INFO:_display_container: 2
2024-11-28 16:58:34,344:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8973, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-11-28 16:58:34,344:INFO:create_model() successfully completed......................................
2024-11-28 16:58:34,414:INFO:SubProcess create_model() end ==================================
2024-11-28 16:58:34,414:INFO:Creating metrics dataframe
2024-11-28 16:58:34,420:INFO:Initializing K Neighbors Classifier
2024-11-28 16:58:34,420:INFO:Total runtime is 0.061684954166412356 minutes
2024-11-28 16:58:34,423:INFO:SubProcess create_model() called ==================================
2024-11-28 16:58:34,424:INFO:Initializing create_model()
2024-11-28 16:58:34,424:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC59ADA0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8D7B04C10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 16:58:34,424:INFO:Checking exceptions
2024-11-28 16:58:34,424:INFO:Importing libraries
2024-11-28 16:58:34,424:INFO:Copying training dataset
2024-11-28 16:58:34,428:INFO:Defining folds
2024-11-28 16:58:34,428:INFO:Declaring metric variables
2024-11-28 16:58:34,430:INFO:Importing untrained model
2024-11-28 16:58:34,433:INFO:K Neighbors Classifier Imported successfully
2024-11-28 16:58:34,441:INFO:Starting cross validation
2024-11-28 16:58:34,442:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 16:58:34,775:INFO:Calculating mean and std
2024-11-28 16:58:34,780:INFO:Creating metrics dataframe
2024-11-28 16:58:34,789:INFO:Uploading results into container
2024-11-28 16:58:34,791:INFO:Uploading model into container now
2024-11-28 16:58:34,792:INFO:_master_model_container: 2
2024-11-28 16:58:34,793:INFO:_display_container: 2
2024-11-28 16:58:34,794:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-11-28 16:58:34,794:INFO:create_model() successfully completed......................................
2024-11-28 16:58:34,939:INFO:SubProcess create_model() end ==================================
2024-11-28 16:58:34,939:INFO:Creating metrics dataframe
2024-11-28 16:58:34,949:INFO:Initializing Naive Bayes
2024-11-28 16:58:34,949:INFO:Total runtime is 0.07049402793248495 minutes
2024-11-28 16:58:34,954:INFO:SubProcess create_model() called ==================================
2024-11-28 16:58:34,955:INFO:Initializing create_model()
2024-11-28 16:58:34,955:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC59ADA0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8D7B04C10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 16:58:34,956:INFO:Checking exceptions
2024-11-28 16:58:34,956:INFO:Importing libraries
2024-11-28 16:58:34,956:INFO:Copying training dataset
2024-11-28 16:58:34,963:INFO:Defining folds
2024-11-28 16:58:34,963:INFO:Declaring metric variables
2024-11-28 16:58:34,969:INFO:Importing untrained model
2024-11-28 16:58:34,976:INFO:Naive Bayes Imported successfully
2024-11-28 16:58:34,987:INFO:Starting cross validation
2024-11-28 16:58:34,989:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 16:58:35,181:INFO:Calculating mean and std
2024-11-28 16:58:35,185:INFO:Creating metrics dataframe
2024-11-28 16:58:35,195:INFO:Uploading results into container
2024-11-28 16:58:35,197:INFO:Uploading model into container now
2024-11-28 16:58:35,199:INFO:_master_model_container: 3
2024-11-28 16:58:35,199:INFO:_display_container: 2
2024-11-28 16:58:35,200:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-11-28 16:58:35,200:INFO:create_model() successfully completed......................................
2024-11-28 16:58:35,319:INFO:SubProcess create_model() end ==================================
2024-11-28 16:58:35,320:INFO:Creating metrics dataframe
2024-11-28 16:58:35,326:INFO:Initializing Decision Tree Classifier
2024-11-28 16:58:35,326:INFO:Total runtime is 0.07677100499471029 minutes
2024-11-28 16:58:35,328:INFO:SubProcess create_model() called ==================================
2024-11-28 16:58:35,329:INFO:Initializing create_model()
2024-11-28 16:58:35,329:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC59ADA0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8D7B04C10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 16:58:35,329:INFO:Checking exceptions
2024-11-28 16:58:35,329:INFO:Importing libraries
2024-11-28 16:58:35,329:INFO:Copying training dataset
2024-11-28 16:58:35,334:INFO:Defining folds
2024-11-28 16:58:35,334:INFO:Declaring metric variables
2024-11-28 16:58:35,339:INFO:Importing untrained model
2024-11-28 16:58:35,343:INFO:Decision Tree Classifier Imported successfully
2024-11-28 16:58:35,349:INFO:Starting cross validation
2024-11-28 16:58:35,351:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 16:58:35,536:INFO:Calculating mean and std
2024-11-28 16:58:35,544:INFO:Creating metrics dataframe
2024-11-28 16:58:35,550:INFO:Uploading results into container
2024-11-28 16:58:35,552:INFO:Uploading model into container now
2024-11-28 16:58:35,555:INFO:_master_model_container: 4
2024-11-28 16:58:35,556:INFO:_display_container: 2
2024-11-28 16:58:35,559:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=8973, splitter='best')
2024-11-28 16:58:35,560:INFO:create_model() successfully completed......................................
2024-11-28 16:58:35,696:INFO:SubProcess create_model() end ==================================
2024-11-28 16:58:35,696:INFO:Creating metrics dataframe
2024-11-28 16:58:35,703:INFO:Initializing SVM - Linear Kernel
2024-11-28 16:58:35,703:INFO:Total runtime is 0.08306204875310262 minutes
2024-11-28 16:58:35,706:INFO:SubProcess create_model() called ==================================
2024-11-28 16:58:35,706:INFO:Initializing create_model()
2024-11-28 16:58:35,706:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC59ADA0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8D7B04C10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 16:58:35,706:INFO:Checking exceptions
2024-11-28 16:58:35,706:INFO:Importing libraries
2024-11-28 16:58:35,706:INFO:Copying training dataset
2024-11-28 16:58:35,711:INFO:Defining folds
2024-11-28 16:58:35,712:INFO:Declaring metric variables
2024-11-28 16:58:35,715:INFO:Importing untrained model
2024-11-28 16:58:35,719:INFO:SVM - Linear Kernel Imported successfully
2024-11-28 16:58:35,726:INFO:Starting cross validation
2024-11-28 16:58:35,727:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 16:58:35,822:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 16:58:35,910:INFO:Calculating mean and std
2024-11-28 16:58:35,914:INFO:Creating metrics dataframe
2024-11-28 16:58:35,919:INFO:Uploading results into container
2024-11-28 16:58:35,922:INFO:Uploading model into container now
2024-11-28 16:58:35,923:INFO:_master_model_container: 5
2024-11-28 16:58:35,924:INFO:_display_container: 2
2024-11-28 16:58:35,925:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=8973, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-11-28 16:58:35,926:INFO:create_model() successfully completed......................................
2024-11-28 16:58:36,011:INFO:SubProcess create_model() end ==================================
2024-11-28 16:58:36,011:INFO:Creating metrics dataframe
2024-11-28 16:58:36,016:INFO:Initializing Ridge Classifier
2024-11-28 16:58:36,016:INFO:Total runtime is 0.08828577597935995 minutes
2024-11-28 16:58:36,021:INFO:SubProcess create_model() called ==================================
2024-11-28 16:58:36,021:INFO:Initializing create_model()
2024-11-28 16:58:36,021:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC59ADA0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8D7B04C10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 16:58:36,021:INFO:Checking exceptions
2024-11-28 16:58:36,021:INFO:Importing libraries
2024-11-28 16:58:36,021:INFO:Copying training dataset
2024-11-28 16:58:36,026:INFO:Defining folds
2024-11-28 16:58:36,026:INFO:Declaring metric variables
2024-11-28 16:58:36,028:INFO:Importing untrained model
2024-11-28 16:58:36,033:INFO:Ridge Classifier Imported successfully
2024-11-28 16:58:36,042:INFO:Starting cross validation
2024-11-28 16:58:36,043:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 16:58:36,223:INFO:Calculating mean and std
2024-11-28 16:58:36,224:INFO:Creating metrics dataframe
2024-11-28 16:58:36,226:INFO:Uploading results into container
2024-11-28 16:58:36,227:INFO:Uploading model into container now
2024-11-28 16:58:36,228:INFO:_master_model_container: 6
2024-11-28 16:58:36,228:INFO:_display_container: 2
2024-11-28 16:58:36,228:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=8973, solver='auto',
                tol=0.0001)
2024-11-28 16:58:36,228:INFO:create_model() successfully completed......................................
2024-11-28 16:58:36,292:INFO:SubProcess create_model() end ==================================
2024-11-28 16:58:36,292:INFO:Creating metrics dataframe
2024-11-28 16:58:36,299:INFO:Initializing Random Forest Classifier
2024-11-28 16:58:36,299:INFO:Total runtime is 0.09300039609273275 minutes
2024-11-28 16:58:36,302:INFO:SubProcess create_model() called ==================================
2024-11-28 16:58:36,302:INFO:Initializing create_model()
2024-11-28 16:58:36,302:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC59ADA0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8D7B04C10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 16:58:36,302:INFO:Checking exceptions
2024-11-28 16:58:36,302:INFO:Importing libraries
2024-11-28 16:58:36,302:INFO:Copying training dataset
2024-11-28 16:58:36,306:INFO:Defining folds
2024-11-28 16:58:36,306:INFO:Declaring metric variables
2024-11-28 16:58:36,309:INFO:Importing untrained model
2024-11-28 16:58:36,312:INFO:Random Forest Classifier Imported successfully
2024-11-28 16:58:36,318:INFO:Starting cross validation
2024-11-28 16:58:36,321:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 16:58:36,906:INFO:Calculating mean and std
2024-11-28 16:58:36,911:INFO:Creating metrics dataframe
2024-11-28 16:58:36,919:INFO:Uploading results into container
2024-11-28 16:58:36,921:INFO:Uploading model into container now
2024-11-28 16:58:36,924:INFO:_master_model_container: 7
2024-11-28 16:58:36,924:INFO:_display_container: 2
2024-11-28 16:58:36,926:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8973, verbose=0,
                       warm_start=False)
2024-11-28 16:58:36,926:INFO:create_model() successfully completed......................................
2024-11-28 16:58:37,093:INFO:SubProcess create_model() end ==================================
2024-11-28 16:58:37,093:INFO:Creating metrics dataframe
2024-11-28 16:58:37,101:INFO:Initializing Quadratic Discriminant Analysis
2024-11-28 16:58:37,101:INFO:Total runtime is 0.10636520783106486 minutes
2024-11-28 16:58:37,105:INFO:SubProcess create_model() called ==================================
2024-11-28 16:58:37,105:INFO:Initializing create_model()
2024-11-28 16:58:37,105:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC59ADA0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8D7B04C10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 16:58:37,105:INFO:Checking exceptions
2024-11-28 16:58:37,105:INFO:Importing libraries
2024-11-28 16:58:37,105:INFO:Copying training dataset
2024-11-28 16:58:37,110:INFO:Defining folds
2024-11-28 16:58:37,110:INFO:Declaring metric variables
2024-11-28 16:58:37,112:INFO:Importing untrained model
2024-11-28 16:58:37,116:INFO:Quadratic Discriminant Analysis Imported successfully
2024-11-28 16:58:37,123:INFO:Starting cross validation
2024-11-28 16:58:37,125:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 16:58:37,183:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 16:58:37,184:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 16:58:37,186:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 16:58:37,194:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 16:58:37,194:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 16:58:37,253:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 16:58:37,255:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 16:58:37,257:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 16:58:37,260:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 16:58:37,292:INFO:Calculating mean and std
2024-11-28 16:58:37,296:INFO:Creating metrics dataframe
2024-11-28 16:58:37,302:INFO:Uploading results into container
2024-11-28 16:58:37,303:INFO:Uploading model into container now
2024-11-28 16:58:37,305:INFO:_master_model_container: 8
2024-11-28 16:58:37,306:INFO:_display_container: 2
2024-11-28 16:58:37,307:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-11-28 16:58:37,307:INFO:create_model() successfully completed......................................
2024-11-28 16:58:37,405:INFO:SubProcess create_model() end ==================================
2024-11-28 16:58:37,405:INFO:Creating metrics dataframe
2024-11-28 16:58:37,412:INFO:Initializing Ada Boost Classifier
2024-11-28 16:58:37,412:INFO:Total runtime is 0.11154154936472575 minutes
2024-11-28 16:58:37,414:INFO:SubProcess create_model() called ==================================
2024-11-28 16:58:37,415:INFO:Initializing create_model()
2024-11-28 16:58:37,415:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC59ADA0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8D7B04C10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 16:58:37,415:INFO:Checking exceptions
2024-11-28 16:58:37,415:INFO:Importing libraries
2024-11-28 16:58:37,415:INFO:Copying training dataset
2024-11-28 16:58:37,420:INFO:Defining folds
2024-11-28 16:58:37,420:INFO:Declaring metric variables
2024-11-28 16:58:37,423:INFO:Importing untrained model
2024-11-28 16:58:37,427:INFO:Ada Boost Classifier Imported successfully
2024-11-28 16:58:37,433:INFO:Starting cross validation
2024-11-28 16:58:37,434:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 16:58:37,492:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 16:58:37,493:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 16:58:37,495:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 16:58:37,496:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 16:58:37,497:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 16:58:37,505:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 16:58:37,657:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 16:58:37,659:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 16:58:37,661:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 16:58:37,669:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 16:58:37,789:INFO:Calculating mean and std
2024-11-28 16:58:37,790:INFO:Creating metrics dataframe
2024-11-28 16:58:37,792:INFO:Uploading results into container
2024-11-28 16:58:37,793:INFO:Uploading model into container now
2024-11-28 16:58:37,793:INFO:_master_model_container: 9
2024-11-28 16:58:37,794:INFO:_display_container: 2
2024-11-28 16:58:37,794:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=8973)
2024-11-28 16:58:37,794:INFO:create_model() successfully completed......................................
2024-11-28 16:58:37,880:INFO:SubProcess create_model() end ==================================
2024-11-28 16:58:37,880:INFO:Creating metrics dataframe
2024-11-28 16:58:37,888:INFO:Initializing Gradient Boosting Classifier
2024-11-28 16:58:37,888:INFO:Total runtime is 0.1194703777631124 minutes
2024-11-28 16:58:37,891:INFO:SubProcess create_model() called ==================================
2024-11-28 16:58:37,892:INFO:Initializing create_model()
2024-11-28 16:58:37,892:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC59ADA0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8D7B04C10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 16:58:37,892:INFO:Checking exceptions
2024-11-28 16:58:37,892:INFO:Importing libraries
2024-11-28 16:58:37,892:INFO:Copying training dataset
2024-11-28 16:58:37,896:INFO:Defining folds
2024-11-28 16:58:37,896:INFO:Declaring metric variables
2024-11-28 16:58:37,899:INFO:Importing untrained model
2024-11-28 16:58:37,903:INFO:Gradient Boosting Classifier Imported successfully
2024-11-28 16:58:37,908:INFO:Starting cross validation
2024-11-28 16:58:37,910:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 16:58:38,378:INFO:Calculating mean and std
2024-11-28 16:58:38,379:INFO:Creating metrics dataframe
2024-11-28 16:58:38,381:INFO:Uploading results into container
2024-11-28 16:58:38,381:INFO:Uploading model into container now
2024-11-28 16:58:38,382:INFO:_master_model_container: 10
2024-11-28 16:58:38,382:INFO:_display_container: 2
2024-11-28 16:58:38,382:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8973, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-11-28 16:58:38,383:INFO:create_model() successfully completed......................................
2024-11-28 16:58:38,446:INFO:SubProcess create_model() end ==================================
2024-11-28 16:58:38,447:INFO:Creating metrics dataframe
2024-11-28 16:58:38,454:INFO:Initializing Linear Discriminant Analysis
2024-11-28 16:58:38,454:INFO:Total runtime is 0.1289084593454997 minutes
2024-11-28 16:58:38,457:INFO:SubProcess create_model() called ==================================
2024-11-28 16:58:38,457:INFO:Initializing create_model()
2024-11-28 16:58:38,457:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC59ADA0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8D7B04C10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 16:58:38,458:INFO:Checking exceptions
2024-11-28 16:58:38,458:INFO:Importing libraries
2024-11-28 16:58:38,458:INFO:Copying training dataset
2024-11-28 16:58:38,461:INFO:Defining folds
2024-11-28 16:58:38,462:INFO:Declaring metric variables
2024-11-28 16:58:38,464:INFO:Importing untrained model
2024-11-28 16:58:38,467:INFO:Linear Discriminant Analysis Imported successfully
2024-11-28 16:58:38,473:INFO:Starting cross validation
2024-11-28 16:58:38,475:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 16:58:38,642:INFO:Calculating mean and std
2024-11-28 16:58:38,643:INFO:Creating metrics dataframe
2024-11-28 16:58:38,645:INFO:Uploading results into container
2024-11-28 16:58:38,645:INFO:Uploading model into container now
2024-11-28 16:58:38,646:INFO:_master_model_container: 11
2024-11-28 16:58:38,646:INFO:_display_container: 2
2024-11-28 16:58:38,646:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-11-28 16:58:38,646:INFO:create_model() successfully completed......................................
2024-11-28 16:58:38,712:INFO:SubProcess create_model() end ==================================
2024-11-28 16:58:38,712:INFO:Creating metrics dataframe
2024-11-28 16:58:38,720:INFO:Initializing Extra Trees Classifier
2024-11-28 16:58:38,720:INFO:Total runtime is 0.13334659735361737 minutes
2024-11-28 16:58:38,723:INFO:SubProcess create_model() called ==================================
2024-11-28 16:58:38,723:INFO:Initializing create_model()
2024-11-28 16:58:38,723:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC59ADA0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8D7B04C10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 16:58:38,723:INFO:Checking exceptions
2024-11-28 16:58:38,723:INFO:Importing libraries
2024-11-28 16:58:38,724:INFO:Copying training dataset
2024-11-28 16:58:38,727:INFO:Defining folds
2024-11-28 16:58:38,727:INFO:Declaring metric variables
2024-11-28 16:58:38,730:INFO:Importing untrained model
2024-11-28 16:58:38,733:INFO:Extra Trees Classifier Imported successfully
2024-11-28 16:58:38,739:INFO:Starting cross validation
2024-11-28 16:58:38,740:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 16:58:39,294:INFO:Calculating mean and std
2024-11-28 16:58:39,296:INFO:Creating metrics dataframe
2024-11-28 16:58:39,300:INFO:Uploading results into container
2024-11-28 16:58:39,300:INFO:Uploading model into container now
2024-11-28 16:58:39,301:INFO:_master_model_container: 12
2024-11-28 16:58:39,301:INFO:_display_container: 2
2024-11-28 16:58:39,302:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=8973, verbose=0,
                     warm_start=False)
2024-11-28 16:58:39,302:INFO:create_model() successfully completed......................................
2024-11-28 16:58:39,376:INFO:SubProcess create_model() end ==================================
2024-11-28 16:58:39,376:INFO:Creating metrics dataframe
2024-11-28 16:58:39,384:INFO:Initializing Extreme Gradient Boosting
2024-11-28 16:58:39,384:INFO:Total runtime is 0.14441094398498536 minutes
2024-11-28 16:58:39,387:INFO:SubProcess create_model() called ==================================
2024-11-28 16:58:39,388:INFO:Initializing create_model()
2024-11-28 16:58:39,388:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC59ADA0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8D7B04C10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 16:58:39,388:INFO:Checking exceptions
2024-11-28 16:58:39,388:INFO:Importing libraries
2024-11-28 16:58:39,388:INFO:Copying training dataset
2024-11-28 16:58:39,393:INFO:Defining folds
2024-11-28 16:58:39,393:INFO:Declaring metric variables
2024-11-28 16:58:39,395:INFO:Importing untrained model
2024-11-28 16:58:39,398:INFO:Extreme Gradient Boosting Imported successfully
2024-11-28 16:58:39,406:INFO:Starting cross validation
2024-11-28 16:58:39,407:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 16:58:40,163:INFO:Calculating mean and std
2024-11-28 16:58:40,163:INFO:Creating metrics dataframe
2024-11-28 16:58:40,165:INFO:Uploading results into container
2024-11-28 16:58:40,166:INFO:Uploading model into container now
2024-11-28 16:58:40,166:INFO:_master_model_container: 13
2024-11-28 16:58:40,166:INFO:_display_container: 2
2024-11-28 16:58:40,167:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-11-28 16:58:40,167:INFO:create_model() successfully completed......................................
2024-11-28 16:58:40,232:INFO:SubProcess create_model() end ==================================
2024-11-28 16:58:40,232:INFO:Creating metrics dataframe
2024-11-28 16:58:40,241:INFO:Initializing Light Gradient Boosting Machine
2024-11-28 16:58:40,241:INFO:Total runtime is 0.15869447787602742 minutes
2024-11-28 16:58:40,244:INFO:SubProcess create_model() called ==================================
2024-11-28 16:58:40,245:INFO:Initializing create_model()
2024-11-28 16:58:40,245:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC59ADA0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8D7B04C10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 16:58:40,245:INFO:Checking exceptions
2024-11-28 16:58:40,245:INFO:Importing libraries
2024-11-28 16:58:40,245:INFO:Copying training dataset
2024-11-28 16:58:40,248:INFO:Defining folds
2024-11-28 16:58:40,249:INFO:Declaring metric variables
2024-11-28 16:58:40,252:INFO:Importing untrained model
2024-11-28 16:58:40,256:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-28 16:58:40,263:INFO:Starting cross validation
2024-11-28 16:58:40,264:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 16:58:40,891:INFO:Calculating mean and std
2024-11-28 16:58:40,892:INFO:Creating metrics dataframe
2024-11-28 16:58:40,895:INFO:Uploading results into container
2024-11-28 16:58:40,895:INFO:Uploading model into container now
2024-11-28 16:58:40,895:INFO:_master_model_container: 14
2024-11-28 16:58:40,896:INFO:_display_container: 2
2024-11-28 16:58:40,896:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8973, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-11-28 16:58:40,896:INFO:create_model() successfully completed......................................
2024-11-28 16:58:40,961:INFO:SubProcess create_model() end ==================================
2024-11-28 16:58:40,961:INFO:Creating metrics dataframe
2024-11-28 16:58:40,969:INFO:Initializing CatBoost Classifier
2024-11-28 16:58:40,969:INFO:Total runtime is 0.17082820733388265 minutes
2024-11-28 16:58:40,973:INFO:SubProcess create_model() called ==================================
2024-11-28 16:58:40,973:INFO:Initializing create_model()
2024-11-28 16:58:40,973:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC59ADA0>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8D7B04C10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 16:58:40,973:INFO:Checking exceptions
2024-11-28 16:58:40,974:INFO:Importing libraries
2024-11-28 16:58:40,974:INFO:Copying training dataset
2024-11-28 16:58:40,977:INFO:Defining folds
2024-11-28 16:58:40,977:INFO:Declaring metric variables
2024-11-28 16:58:40,980:INFO:Importing untrained model
2024-11-28 16:58:40,983:INFO:CatBoost Classifier Imported successfully
2024-11-28 16:58:40,990:INFO:Starting cross validation
2024-11-28 16:58:40,992:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 16:58:46,477:INFO:Calculating mean and std
2024-11-28 16:58:46,478:INFO:Creating metrics dataframe
2024-11-28 16:58:46,480:INFO:Uploading results into container
2024-11-28 16:58:46,480:INFO:Uploading model into container now
2024-11-28 16:58:46,481:INFO:_master_model_container: 15
2024-11-28 16:58:46,481:INFO:_display_container: 2
2024-11-28 16:58:46,481:INFO:<catboost.core.CatBoostClassifier object at 0x000002D8D9F1F1C0>
2024-11-28 16:58:46,481:INFO:create_model() successfully completed......................................
2024-11-28 16:58:46,546:INFO:SubProcess create_model() end ==================================
2024-11-28 16:58:46,546:INFO:Creating metrics dataframe
2024-11-28 16:58:46,555:INFO:Initializing Dummy Classifier
2024-11-28 16:58:46,555:INFO:Total runtime is 0.263922905921936 minutes
2024-11-28 16:58:46,560:INFO:SubProcess create_model() called ==================================
2024-11-28 16:58:46,560:INFO:Initializing create_model()
2024-11-28 16:58:46,561:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC59ADA0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8D7B04C10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 16:58:46,561:INFO:Checking exceptions
2024-11-28 16:58:46,561:INFO:Importing libraries
2024-11-28 16:58:46,561:INFO:Copying training dataset
2024-11-28 16:58:46,564:INFO:Defining folds
2024-11-28 16:58:46,564:INFO:Declaring metric variables
2024-11-28 16:58:46,567:INFO:Importing untrained model
2024-11-28 16:58:46,571:INFO:Dummy Classifier Imported successfully
2024-11-28 16:58:46,577:INFO:Starting cross validation
2024-11-28 16:58:46,579:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 16:58:46,661:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 16:58:46,662:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 16:58:46,663:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 16:58:46,676:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 16:58:46,677:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 16:58:46,681:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 16:58:46,732:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 16:58:46,733:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 16:58:46,734:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 16:58:46,747:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 16:58:46,756:INFO:Calculating mean and std
2024-11-28 16:58:46,757:INFO:Creating metrics dataframe
2024-11-28 16:58:46,759:INFO:Uploading results into container
2024-11-28 16:58:46,760:INFO:Uploading model into container now
2024-11-28 16:58:46,760:INFO:_master_model_container: 16
2024-11-28 16:58:46,761:INFO:_display_container: 2
2024-11-28 16:58:46,761:INFO:DummyClassifier(constant=None, random_state=8973, strategy='prior')
2024-11-28 16:58:46,761:INFO:create_model() successfully completed......................................
2024-11-28 16:58:46,827:INFO:SubProcess create_model() end ==================================
2024-11-28 16:58:46,827:INFO:Creating metrics dataframe
2024-11-28 16:58:46,837:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-11-28 16:58:46,844:INFO:Initializing create_model()
2024-11-28 16:58:46,844:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC59ADA0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8973, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 16:58:46,844:INFO:Checking exceptions
2024-11-28 16:58:46,846:INFO:Importing libraries
2024-11-28 16:58:46,846:INFO:Copying training dataset
2024-11-28 16:58:46,851:INFO:Defining folds
2024-11-28 16:58:46,851:INFO:Declaring metric variables
2024-11-28 16:58:46,851:INFO:Importing untrained model
2024-11-28 16:58:46,851:INFO:Declaring custom model
2024-11-28 16:58:46,851:INFO:Random Forest Classifier Imported successfully
2024-11-28 16:58:46,852:INFO:Cross validation set to False
2024-11-28 16:58:46,852:INFO:Fitting Model
2024-11-28 16:58:47,020:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8973, verbose=0,
                       warm_start=False)
2024-11-28 16:58:47,020:INFO:create_model() successfully completed......................................
2024-11-28 16:58:47,091:INFO:Initializing create_model()
2024-11-28 16:58:47,091:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC59ADA0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8973, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 16:58:47,092:INFO:Checking exceptions
2024-11-28 16:58:47,094:INFO:Importing libraries
2024-11-28 16:58:47,094:INFO:Copying training dataset
2024-11-28 16:58:47,097:INFO:Defining folds
2024-11-28 16:58:47,097:INFO:Declaring metric variables
2024-11-28 16:58:47,098:INFO:Importing untrained model
2024-11-28 16:58:47,098:INFO:Declaring custom model
2024-11-28 16:58:47,098:INFO:Gradient Boosting Classifier Imported successfully
2024-11-28 16:58:47,099:INFO:Cross validation set to False
2024-11-28 16:58:47,099:INFO:Fitting Model
2024-11-28 16:58:47,263:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8973, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-11-28 16:58:47,263:INFO:create_model() successfully completed......................................
2024-11-28 16:58:47,332:INFO:Initializing create_model()
2024-11-28 16:58:47,332:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC59ADA0>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=8973, verbose=0,
                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 16:58:47,332:INFO:Checking exceptions
2024-11-28 16:58:47,333:INFO:Importing libraries
2024-11-28 16:58:47,333:INFO:Copying training dataset
2024-11-28 16:58:47,338:INFO:Defining folds
2024-11-28 16:58:47,338:INFO:Declaring metric variables
2024-11-28 16:58:47,338:INFO:Importing untrained model
2024-11-28 16:58:47,338:INFO:Declaring custom model
2024-11-28 16:58:47,339:INFO:Extra Trees Classifier Imported successfully
2024-11-28 16:58:47,339:INFO:Cross validation set to False
2024-11-28 16:58:47,340:INFO:Fitting Model
2024-11-28 16:58:47,469:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=8973, verbose=0,
                     warm_start=False)
2024-11-28 16:58:47,469:INFO:create_model() successfully completed......................................
2024-11-28 16:58:47,536:INFO:Initializing create_model()
2024-11-28 16:58:47,537:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC59ADA0>, estimator=<catboost.core.CatBoostClassifier object at 0x000002D8D9F1F1C0>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 16:58:47,537:INFO:Checking exceptions
2024-11-28 16:58:47,540:INFO:Importing libraries
2024-11-28 16:58:47,540:INFO:Copying training dataset
2024-11-28 16:58:47,543:INFO:Defining folds
2024-11-28 16:58:47,543:INFO:Declaring metric variables
2024-11-28 16:58:47,544:INFO:Importing untrained model
2024-11-28 16:58:47,544:INFO:Declaring custom model
2024-11-28 16:58:47,544:INFO:CatBoost Classifier Imported successfully
2024-11-28 16:58:47,545:INFO:Cross validation set to False
2024-11-28 16:58:47,545:INFO:Fitting Model
2024-11-28 16:58:49,043:INFO:<catboost.core.CatBoostClassifier object at 0x000002D8DA463010>
2024-11-28 16:58:49,043:INFO:create_model() successfully completed......................................
2024-11-28 16:58:49,112:INFO:Initializing create_model()
2024-11-28 16:58:49,112:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC59ADA0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8973, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 16:58:49,112:INFO:Checking exceptions
2024-11-28 16:58:49,115:INFO:Importing libraries
2024-11-28 16:58:49,115:INFO:Copying training dataset
2024-11-28 16:58:49,118:INFO:Defining folds
2024-11-28 16:58:49,118:INFO:Declaring metric variables
2024-11-28 16:58:49,118:INFO:Importing untrained model
2024-11-28 16:58:49,118:INFO:Declaring custom model
2024-11-28 16:58:49,119:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-28 16:58:49,120:INFO:Cross validation set to False
2024-11-28 16:58:49,120:INFO:Fitting Model
2024-11-28 16:58:49,157:INFO:[LightGBM] [Info] Number of positive: 239, number of negative: 384
2024-11-28 16:58:49,158:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000150 seconds.
2024-11-28 16:58:49,158:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-11-28 16:58:49,158:INFO:[LightGBM] [Info] Total Bins 404
2024-11-28 16:58:49,158:INFO:[LightGBM] [Info] Number of data points in the train set: 623, number of used features: 11
2024-11-28 16:58:49,158:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383628 -> initscore=-0.474179
2024-11-28 16:58:49,158:INFO:[LightGBM] [Info] Start training from score -0.474179
2024-11-28 16:58:49,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 16:58:49,194:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8973, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-11-28 16:58:49,194:INFO:create_model() successfully completed......................................
2024-11-28 16:58:49,262:INFO:Initializing create_model()
2024-11-28 16:58:49,263:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC59ADA0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=8973, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 16:58:49,263:INFO:Checking exceptions
2024-11-28 16:58:49,265:INFO:Importing libraries
2024-11-28 16:58:49,265:INFO:Copying training dataset
2024-11-28 16:58:49,268:INFO:Defining folds
2024-11-28 16:58:49,268:INFO:Declaring metric variables
2024-11-28 16:58:49,269:INFO:Importing untrained model
2024-11-28 16:58:49,269:INFO:Declaring custom model
2024-11-28 16:58:49,269:INFO:Ridge Classifier Imported successfully
2024-11-28 16:58:49,270:INFO:Cross validation set to False
2024-11-28 16:58:49,270:INFO:Fitting Model
2024-11-28 16:58:49,306:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=8973, solver='auto',
                tol=0.0001)
2024-11-28 16:58:49,306:INFO:create_model() successfully completed......................................
2024-11-28 16:58:49,374:INFO:Initializing create_model()
2024-11-28 16:58:49,374:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC59ADA0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 16:58:49,374:INFO:Checking exceptions
2024-11-28 16:58:49,376:INFO:Importing libraries
2024-11-28 16:58:49,376:INFO:Copying training dataset
2024-11-28 16:58:49,380:INFO:Defining folds
2024-11-28 16:58:49,380:INFO:Declaring metric variables
2024-11-28 16:58:49,380:INFO:Importing untrained model
2024-11-28 16:58:49,380:INFO:Declaring custom model
2024-11-28 16:58:49,380:INFO:Linear Discriminant Analysis Imported successfully
2024-11-28 16:58:49,381:INFO:Cross validation set to False
2024-11-28 16:58:49,381:INFO:Fitting Model
2024-11-28 16:58:49,414:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-11-28 16:58:49,414:INFO:create_model() successfully completed......................................
2024-11-28 16:58:49,482:INFO:Initializing create_model()
2024-11-28 16:58:49,482:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC59ADA0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8973, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 16:58:49,482:INFO:Checking exceptions
2024-11-28 16:58:49,484:INFO:Importing libraries
2024-11-28 16:58:49,484:INFO:Copying training dataset
2024-11-28 16:58:49,489:INFO:Defining folds
2024-11-28 16:58:49,489:INFO:Declaring metric variables
2024-11-28 16:58:49,489:INFO:Importing untrained model
2024-11-28 16:58:49,489:INFO:Declaring custom model
2024-11-28 16:58:49,489:INFO:Logistic Regression Imported successfully
2024-11-28 16:58:49,490:INFO:Cross validation set to False
2024-11-28 16:58:49,490:INFO:Fitting Model
2024-11-28 16:58:49,643:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 16:58:49,643:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8973, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-11-28 16:58:49,643:INFO:create_model() successfully completed......................................
2024-11-28 16:58:49,716:INFO:Initializing create_model()
2024-11-28 16:58:49,716:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC59ADA0>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=8973), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 16:58:49,717:INFO:Checking exceptions
2024-11-28 16:58:49,719:INFO:Importing libraries
2024-11-28 16:58:49,719:INFO:Copying training dataset
2024-11-28 16:58:49,723:INFO:Defining folds
2024-11-28 16:58:49,723:INFO:Declaring metric variables
2024-11-28 16:58:49,724:INFO:Importing untrained model
2024-11-28 16:58:49,724:INFO:Declaring custom model
2024-11-28 16:58:49,724:INFO:Ada Boost Classifier Imported successfully
2024-11-28 16:58:49,725:INFO:Cross validation set to False
2024-11-28 16:58:49,725:INFO:Fitting Model
2024-11-28 16:58:49,762:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 16:58:49,842:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=8973)
2024-11-28 16:58:49,842:INFO:create_model() successfully completed......................................
2024-11-28 16:58:49,911:INFO:Initializing create_model()
2024-11-28 16:58:49,912:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC59ADA0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 16:58:49,912:INFO:Checking exceptions
2024-11-28 16:58:49,914:INFO:Importing libraries
2024-11-28 16:58:49,914:INFO:Copying training dataset
2024-11-28 16:58:49,917:INFO:Defining folds
2024-11-28 16:58:49,917:INFO:Declaring metric variables
2024-11-28 16:58:49,918:INFO:Importing untrained model
2024-11-28 16:58:49,918:INFO:Declaring custom model
2024-11-28 16:58:49,919:INFO:Extreme Gradient Boosting Imported successfully
2024-11-28 16:58:49,920:INFO:Cross validation set to False
2024-11-28 16:58:49,920:INFO:Fitting Model
2024-11-28 16:58:50,141:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-11-28 16:58:50,141:INFO:create_model() successfully completed......................................
2024-11-28 16:58:50,214:INFO:Initializing create_model()
2024-11-28 16:58:50,214:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC59ADA0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 16:58:50,215:INFO:Checking exceptions
2024-11-28 16:58:50,216:INFO:Importing libraries
2024-11-28 16:58:50,216:INFO:Copying training dataset
2024-11-28 16:58:50,220:INFO:Defining folds
2024-11-28 16:58:50,221:INFO:Declaring metric variables
2024-11-28 16:58:50,222:INFO:Importing untrained model
2024-11-28 16:58:50,222:INFO:Declaring custom model
2024-11-28 16:58:50,222:INFO:Naive Bayes Imported successfully
2024-11-28 16:58:50,224:INFO:Cross validation set to False
2024-11-28 16:58:50,224:INFO:Fitting Model
2024-11-28 16:58:50,262:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-11-28 16:58:50,262:INFO:create_model() successfully completed......................................
2024-11-28 16:58:50,331:INFO:Initializing create_model()
2024-11-28 16:58:50,331:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC59ADA0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=8973, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 16:58:50,331:INFO:Checking exceptions
2024-11-28 16:58:50,334:INFO:Importing libraries
2024-11-28 16:58:50,334:INFO:Copying training dataset
2024-11-28 16:58:50,338:INFO:Defining folds
2024-11-28 16:58:50,338:INFO:Declaring metric variables
2024-11-28 16:58:50,339:INFO:Importing untrained model
2024-11-28 16:58:50,339:INFO:Declaring custom model
2024-11-28 16:58:50,339:INFO:Decision Tree Classifier Imported successfully
2024-11-28 16:58:50,340:INFO:Cross validation set to False
2024-11-28 16:58:50,340:INFO:Fitting Model
2024-11-28 16:58:50,376:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=8973, splitter='best')
2024-11-28 16:58:50,376:INFO:create_model() successfully completed......................................
2024-11-28 16:58:50,457:INFO:Initializing create_model()
2024-11-28 16:58:50,457:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC59ADA0>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 16:58:50,457:INFO:Checking exceptions
2024-11-28 16:58:50,459:INFO:Importing libraries
2024-11-28 16:58:50,459:INFO:Copying training dataset
2024-11-28 16:58:50,464:INFO:Defining folds
2024-11-28 16:58:50,464:INFO:Declaring metric variables
2024-11-28 16:58:50,464:INFO:Importing untrained model
2024-11-28 16:58:50,464:INFO:Declaring custom model
2024-11-28 16:58:50,464:INFO:Quadratic Discriminant Analysis Imported successfully
2024-11-28 16:58:50,465:INFO:Cross validation set to False
2024-11-28 16:58:50,466:INFO:Fitting Model
2024-11-28 16:58:50,519:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 16:58:50,520:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-11-28 16:58:50,520:INFO:create_model() successfully completed......................................
2024-11-28 16:58:50,593:INFO:Initializing create_model()
2024-11-28 16:58:50,593:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC59ADA0>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 16:58:50,593:INFO:Checking exceptions
2024-11-28 16:58:50,594:INFO:Importing libraries
2024-11-28 16:58:50,595:INFO:Copying training dataset
2024-11-28 16:58:50,598:INFO:Defining folds
2024-11-28 16:58:50,598:INFO:Declaring metric variables
2024-11-28 16:58:50,598:INFO:Importing untrained model
2024-11-28 16:58:50,598:INFO:Declaring custom model
2024-11-28 16:58:50,599:INFO:K Neighbors Classifier Imported successfully
2024-11-28 16:58:50,600:INFO:Cross validation set to False
2024-11-28 16:58:50,600:INFO:Fitting Model
2024-11-28 16:58:50,632:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-11-28 16:58:50,633:INFO:create_model() successfully completed......................................
2024-11-28 16:58:50,701:INFO:Initializing create_model()
2024-11-28 16:58:50,701:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC59ADA0>, estimator=DummyClassifier(constant=None, random_state=8973, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 16:58:50,702:INFO:Checking exceptions
2024-11-28 16:58:50,705:INFO:Importing libraries
2024-11-28 16:58:50,705:INFO:Copying training dataset
2024-11-28 16:58:50,709:INFO:Defining folds
2024-11-28 16:58:50,709:INFO:Declaring metric variables
2024-11-28 16:58:50,709:INFO:Importing untrained model
2024-11-28 16:58:50,709:INFO:Declaring custom model
2024-11-28 16:58:50,709:INFO:Dummy Classifier Imported successfully
2024-11-28 16:58:50,710:INFO:Cross validation set to False
2024-11-28 16:58:50,710:INFO:Fitting Model
2024-11-28 16:58:50,743:INFO:DummyClassifier(constant=None, random_state=8973, strategy='prior')
2024-11-28 16:58:50,744:INFO:create_model() successfully completed......................................
2024-11-28 16:58:50,816:INFO:Initializing create_model()
2024-11-28 16:58:50,816:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC59ADA0>, estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=8973, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 16:58:50,816:INFO:Checking exceptions
2024-11-28 16:58:50,818:INFO:Importing libraries
2024-11-28 16:58:50,818:INFO:Copying training dataset
2024-11-28 16:58:50,822:INFO:Defining folds
2024-11-28 16:58:50,823:INFO:Declaring metric variables
2024-11-28 16:58:50,823:INFO:Importing untrained model
2024-11-28 16:58:50,823:INFO:Declaring custom model
2024-11-28 16:58:50,823:INFO:SVM - Linear Kernel Imported successfully
2024-11-28 16:58:50,824:INFO:Cross validation set to False
2024-11-28 16:58:50,824:INFO:Fitting Model
2024-11-28 16:58:50,861:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=8973, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-11-28 16:58:50,861:INFO:create_model() successfully completed......................................
2024-11-28 16:58:50,943:INFO:_master_model_container: 16
2024-11-28 16:58:50,943:INFO:_display_container: 2
2024-11-28 16:58:50,947:INFO:[RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8973, verbose=0,
                       warm_start=False), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8973, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=8973, verbose=0,
                     warm_start=False), <catboost.core.CatBoostClassifier object at 0x000002D8DA463010>, LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8973, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=8973, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8973, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=8973), XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=8973, splitter='best'), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), DummyClassifier(constant=None, random_state=8973, strategy='prior'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=8973, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)]
2024-11-28 16:58:50,947:INFO:compare_models() successfully completed......................................
2024-11-28 17:03:05,956:INFO:PyCaret ClassificationExperiment
2024-11-28 17:03:05,956:INFO:Logging name: clf-default-name
2024-11-28 17:03:05,956:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-11-28 17:03:05,956:INFO:version 3.3.2
2024-11-28 17:03:05,956:INFO:Initializing setup()
2024-11-28 17:03:05,956:INFO:self.USI: fbc7
2024-11-28 17:03:05,956:INFO:self._variable_keys: {'exp_name_log', 'y_test', 'idx', 'y_train', 'log_plots_param', 'memory', 'pipeline', 'X', 'gpu_param', 'fold_generator', 'logging_param', 'n_jobs_param', 'exp_id', 'is_multiclass', 'fix_imbalance', '_available_plots', 'html_param', 'gpu_n_jobs_param', 'X_test', 'X_train', 'y', 'data', 'fold_shuffle_param', 'seed', 'fold_groups_param', '_ml_usecase', 'target_param', 'USI'}
2024-11-28 17:03:05,956:INFO:Checking environment
2024-11-28 17:03:05,956:INFO:python_version: 3.10.11
2024-11-28 17:03:05,956:INFO:python_build: ('tags/v3.10.11:7d4cc5a', 'Apr  5 2023 00:38:17')
2024-11-28 17:03:05,956:INFO:machine: AMD64
2024-11-28 17:03:05,956:INFO:platform: Windows-10-10.0.19045-SP0
2024-11-28 17:03:05,960:INFO:Memory: svmem(total=34216488960, available=20680065024, percent=39.6, used=13536423936, free=20680065024)
2024-11-28 17:03:05,960:INFO:Physical Core: 6
2024-11-28 17:03:05,960:INFO:Logical Core: 6
2024-11-28 17:03:05,960:INFO:Checking libraries
2024-11-28 17:03:05,960:INFO:System:
2024-11-28 17:03:05,960:INFO:    python: 3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]
2024-11-28 17:03:05,960:INFO:executable: c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\Scripts\python.exe
2024-11-28 17:03:05,960:INFO:   machine: Windows-10-10.0.19045-SP0
2024-11-28 17:03:05,960:INFO:PyCaret required dependencies:
2024-11-28 17:03:05,960:INFO:                 pip: 23.0.1
2024-11-28 17:03:05,960:INFO:          setuptools: 65.5.0
2024-11-28 17:03:05,960:INFO:             pycaret: 3.3.2
2024-11-28 17:03:05,960:INFO:             IPython: 8.29.0
2024-11-28 17:03:05,960:INFO:          ipywidgets: 8.1.5
2024-11-28 17:03:05,960:INFO:                tqdm: 4.67.1
2024-11-28 17:03:05,960:INFO:               numpy: 1.26.4
2024-11-28 17:03:05,960:INFO:              pandas: 2.1.4
2024-11-28 17:03:05,960:INFO:              jinja2: 3.1.4
2024-11-28 17:03:05,960:INFO:               scipy: 1.11.4
2024-11-28 17:03:05,960:INFO:              joblib: 1.3.2
2024-11-28 17:03:05,961:INFO:             sklearn: 1.4.2
2024-11-28 17:03:05,961:INFO:                pyod: 2.0.2
2024-11-28 17:03:05,961:INFO:            imblearn: 0.12.4
2024-11-28 17:03:05,961:INFO:   category_encoders: 2.6.4
2024-11-28 17:03:05,961:INFO:            lightgbm: 4.5.0
2024-11-28 17:03:05,961:INFO:               numba: 0.60.0
2024-11-28 17:03:05,961:INFO:            requests: 2.32.3
2024-11-28 17:03:05,961:INFO:          matplotlib: 3.7.5
2024-11-28 17:03:05,961:INFO:          scikitplot: 0.3.7
2024-11-28 17:03:05,961:INFO:         yellowbrick: 1.5
2024-11-28 17:03:05,961:INFO:              plotly: 5.24.1
2024-11-28 17:03:05,961:INFO:    plotly-resampler: Not installed
2024-11-28 17:03:05,961:INFO:             kaleido: 0.2.1
2024-11-28 17:03:05,961:INFO:           schemdraw: 0.15
2024-11-28 17:03:05,961:INFO:         statsmodels: 0.14.4
2024-11-28 17:03:05,961:INFO:              sktime: 0.26.0
2024-11-28 17:03:05,961:INFO:               tbats: 1.1.3
2024-11-28 17:03:05,961:INFO:            pmdarima: 2.0.4
2024-11-28 17:03:05,961:INFO:              psutil: 6.1.0
2024-11-28 17:03:05,961:INFO:          markupsafe: 3.0.2
2024-11-28 17:03:05,961:INFO:             pickle5: Not installed
2024-11-28 17:03:05,961:INFO:         cloudpickle: 3.1.0
2024-11-28 17:03:05,961:INFO:         deprecation: 2.1.0
2024-11-28 17:03:05,961:INFO:              xxhash: 3.5.0
2024-11-28 17:03:05,961:INFO:           wurlitzer: Not installed
2024-11-28 17:03:05,961:INFO:PyCaret optional dependencies:
2024-11-28 17:03:05,961:INFO:                shap: Not installed
2024-11-28 17:03:05,962:INFO:           interpret: Not installed
2024-11-28 17:03:05,962:INFO:                umap: Not installed
2024-11-28 17:03:05,962:INFO:     ydata_profiling: Not installed
2024-11-28 17:03:05,962:INFO:  explainerdashboard: Not installed
2024-11-28 17:03:05,962:INFO:             autoviz: Not installed
2024-11-28 17:03:05,962:INFO:           fairlearn: Not installed
2024-11-28 17:03:05,962:INFO:          deepchecks: Not installed
2024-11-28 17:03:05,962:INFO:             xgboost: 2.1.3
2024-11-28 17:03:05,962:INFO:            catboost: 1.2.7
2024-11-28 17:03:05,962:INFO:              kmodes: Not installed
2024-11-28 17:03:05,962:INFO:             mlxtend: 0.23.3
2024-11-28 17:03:05,962:INFO:       statsforecast: Not installed
2024-11-28 17:03:05,962:INFO:        tune_sklearn: Not installed
2024-11-28 17:03:05,962:INFO:                 ray: Not installed
2024-11-28 17:03:05,962:INFO:            hyperopt: Not installed
2024-11-28 17:03:05,962:INFO:              optuna: Not installed
2024-11-28 17:03:05,962:INFO:               skopt: Not installed
2024-11-28 17:03:05,962:INFO:              mlflow: Not installed
2024-11-28 17:03:05,962:INFO:              gradio: Not installed
2024-11-28 17:03:05,962:INFO:             fastapi: Not installed
2024-11-28 17:03:05,962:INFO:             uvicorn: Not installed
2024-11-28 17:03:05,962:INFO:              m2cgen: Not installed
2024-11-28 17:03:05,962:INFO:           evidently: Not installed
2024-11-28 17:03:05,962:INFO:               fugue: Not installed
2024-11-28 17:03:05,962:INFO:           streamlit: 1.39.0
2024-11-28 17:03:05,962:INFO:             prophet: Not installed
2024-11-28 17:03:05,962:INFO:None
2024-11-28 17:03:05,963:INFO:Set up data.
2024-11-28 17:03:05,966:INFO:Set up folding strategy.
2024-11-28 17:03:05,966:INFO:Set up train/test split.
2024-11-28 17:03:05,971:INFO:Set up index.
2024-11-28 17:03:05,972:INFO:Assigning column types.
2024-11-28 17:03:05,975:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-28 17:03:06,014:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-28 17:03:06,015:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-28 17:03:06,046:INFO:Soft dependency imported: xgboost: 2.1.3
2024-11-28 17:03:06,048:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-28 17:03:06,090:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-28 17:03:06,090:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-28 17:03:06,113:INFO:Soft dependency imported: xgboost: 2.1.3
2024-11-28 17:03:06,115:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-28 17:03:06,116:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-28 17:03:06,157:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-28 17:03:06,185:INFO:Soft dependency imported: xgboost: 2.1.3
2024-11-28 17:03:06,188:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-28 17:03:06,228:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-28 17:03:06,253:INFO:Soft dependency imported: xgboost: 2.1.3
2024-11-28 17:03:06,255:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-28 17:03:06,256:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-11-28 17:03:06,318:INFO:Soft dependency imported: xgboost: 2.1.3
2024-11-28 17:03:06,320:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-28 17:03:06,383:INFO:Soft dependency imported: xgboost: 2.1.3
2024-11-28 17:03:06,385:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-28 17:03:06,387:INFO:Preparing preprocessing pipeline...
2024-11-28 17:03:06,388:INFO:Set up simple imputation.
2024-11-28 17:03:06,390:INFO:Set up encoding of ordinal features.
2024-11-28 17:03:06,391:INFO:Set up encoding of categorical features.
2024-11-28 17:03:06,441:INFO:Finished creating preprocessing pipeline.
2024-11-28 17:03:06,455:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\tsai\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare',
                                             'FamilySize'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('...
                                                               mapping=[{'col': 'Sex',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['Embarked'],
                                    transformer=OneHotEncoder(cols=['Embarked'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-11-28 17:03:06,455:INFO:Creating final display dataframe.
2024-11-28 17:03:06,614:INFO:Setup _display_container:                     Description             Value
0                    Session id              1842
1                        Target          Survived
2                   Target type            Binary
3           Original data shape         (891, 10)
4        Transformed data shape         (891, 12)
5   Transformed train set shape         (623, 12)
6    Transformed test set shape         (268, 12)
7              Numeric features                 7
8          Categorical features                 2
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              fbc7
2024-11-28 17:03:06,682:INFO:Soft dependency imported: xgboost: 2.1.3
2024-11-28 17:03:06,684:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-28 17:03:06,746:INFO:Soft dependency imported: xgboost: 2.1.3
2024-11-28 17:03:06,749:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-28 17:03:06,750:INFO:setup() successfully completed in 0.8s...............
2024-11-28 17:03:06,751:INFO:Initializing compare_models()
2024-11-28 17:03:06,751:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC45BBE0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=16, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC45BBE0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 16, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-11-28 17:03:06,751:INFO:Checking exceptions
2024-11-28 17:03:06,754:INFO:Preparing display monitor
2024-11-28 17:03:06,773:INFO:Initializing Logistic Regression
2024-11-28 17:03:06,773:INFO:Total runtime is 0.0 minutes
2024-11-28 17:03:06,777:INFO:SubProcess create_model() called ==================================
2024-11-28 17:03:06,777:INFO:Initializing create_model()
2024-11-28 17:03:06,778:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC45BBE0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8D82EAFE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:03:06,778:INFO:Checking exceptions
2024-11-28 17:03:06,778:INFO:Importing libraries
2024-11-28 17:03:06,778:INFO:Copying training dataset
2024-11-28 17:03:06,783:INFO:Defining folds
2024-11-28 17:03:06,783:INFO:Declaring metric variables
2024-11-28 17:03:06,786:INFO:Importing untrained model
2024-11-28 17:03:06,790:INFO:Logistic Regression Imported successfully
2024-11-28 17:03:06,796:INFO:Starting cross validation
2024-11-28 17:03:06,797:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:03:06,985:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:03:06,985:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:03:06,990:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:03:07,000:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:03:07,005:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:03:07,020:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:03:07,165:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:03:07,175:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:03:07,187:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:03:07,223:INFO:Calculating mean and std
2024-11-28 17:03:07,223:INFO:Creating metrics dataframe
2024-11-28 17:03:07,225:INFO:Uploading results into container
2024-11-28 17:03:07,225:INFO:Uploading model into container now
2024-11-28 17:03:07,225:INFO:_master_model_container: 1
2024-11-28 17:03:07,226:INFO:_display_container: 2
2024-11-28 17:03:07,226:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1842, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-11-28 17:03:07,226:INFO:create_model() successfully completed......................................
2024-11-28 17:03:07,293:INFO:SubProcess create_model() end ==================================
2024-11-28 17:03:07,293:INFO:Creating metrics dataframe
2024-11-28 17:03:07,298:INFO:Initializing K Neighbors Classifier
2024-11-28 17:03:07,298:INFO:Total runtime is 0.008750665187835693 minutes
2024-11-28 17:03:07,301:INFO:SubProcess create_model() called ==================================
2024-11-28 17:03:07,301:INFO:Initializing create_model()
2024-11-28 17:03:07,302:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC45BBE0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8D82EAFE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:03:07,302:INFO:Checking exceptions
2024-11-28 17:03:07,302:INFO:Importing libraries
2024-11-28 17:03:07,302:INFO:Copying training dataset
2024-11-28 17:03:07,307:INFO:Defining folds
2024-11-28 17:03:07,307:INFO:Declaring metric variables
2024-11-28 17:03:07,310:INFO:Importing untrained model
2024-11-28 17:03:07,314:INFO:K Neighbors Classifier Imported successfully
2024-11-28 17:03:07,322:INFO:Starting cross validation
2024-11-28 17:03:07,323:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:03:07,673:INFO:Calculating mean and std
2024-11-28 17:03:07,673:INFO:Creating metrics dataframe
2024-11-28 17:03:07,675:INFO:Uploading results into container
2024-11-28 17:03:07,675:INFO:Uploading model into container now
2024-11-28 17:03:07,676:INFO:_master_model_container: 2
2024-11-28 17:03:07,676:INFO:_display_container: 2
2024-11-28 17:03:07,676:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-11-28 17:03:07,676:INFO:create_model() successfully completed......................................
2024-11-28 17:03:07,743:INFO:SubProcess create_model() end ==================================
2024-11-28 17:03:07,743:INFO:Creating metrics dataframe
2024-11-28 17:03:07,748:INFO:Initializing Naive Bayes
2024-11-28 17:03:07,749:INFO:Total runtime is 0.016243823369344074 minutes
2024-11-28 17:03:07,751:INFO:SubProcess create_model() called ==================================
2024-11-28 17:03:07,751:INFO:Initializing create_model()
2024-11-28 17:03:07,752:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC45BBE0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8D82EAFE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:03:07,752:INFO:Checking exceptions
2024-11-28 17:03:07,752:INFO:Importing libraries
2024-11-28 17:03:07,752:INFO:Copying training dataset
2024-11-28 17:03:07,756:INFO:Defining folds
2024-11-28 17:03:07,756:INFO:Declaring metric variables
2024-11-28 17:03:07,759:INFO:Importing untrained model
2024-11-28 17:03:07,762:INFO:Naive Bayes Imported successfully
2024-11-28 17:03:07,769:INFO:Starting cross validation
2024-11-28 17:03:07,771:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:03:07,938:INFO:Calculating mean and std
2024-11-28 17:03:07,938:INFO:Creating metrics dataframe
2024-11-28 17:03:07,941:INFO:Uploading results into container
2024-11-28 17:03:07,941:INFO:Uploading model into container now
2024-11-28 17:03:07,942:INFO:_master_model_container: 3
2024-11-28 17:03:07,942:INFO:_display_container: 2
2024-11-28 17:03:07,942:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-11-28 17:03:07,942:INFO:create_model() successfully completed......................................
2024-11-28 17:03:08,006:INFO:SubProcess create_model() end ==================================
2024-11-28 17:03:08,006:INFO:Creating metrics dataframe
2024-11-28 17:03:08,012:INFO:Initializing Decision Tree Classifier
2024-11-28 17:03:08,012:INFO:Total runtime is 0.020654515425364173 minutes
2024-11-28 17:03:08,015:INFO:SubProcess create_model() called ==================================
2024-11-28 17:03:08,015:INFO:Initializing create_model()
2024-11-28 17:03:08,015:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC45BBE0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8D82EAFE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:03:08,015:INFO:Checking exceptions
2024-11-28 17:03:08,015:INFO:Importing libraries
2024-11-28 17:03:08,015:INFO:Copying training dataset
2024-11-28 17:03:08,019:INFO:Defining folds
2024-11-28 17:03:08,019:INFO:Declaring metric variables
2024-11-28 17:03:08,022:INFO:Importing untrained model
2024-11-28 17:03:08,025:INFO:Decision Tree Classifier Imported successfully
2024-11-28 17:03:08,058:INFO:Starting cross validation
2024-11-28 17:03:08,059:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:03:08,247:INFO:Calculating mean and std
2024-11-28 17:03:08,248:INFO:Creating metrics dataframe
2024-11-28 17:03:08,250:INFO:Uploading results into container
2024-11-28 17:03:08,251:INFO:Uploading model into container now
2024-11-28 17:03:08,251:INFO:_master_model_container: 4
2024-11-28 17:03:08,251:INFO:_display_container: 2
2024-11-28 17:03:08,252:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=1842, splitter='best')
2024-11-28 17:03:08,252:INFO:create_model() successfully completed......................................
2024-11-28 17:03:08,319:INFO:SubProcess create_model() end ==================================
2024-11-28 17:03:08,319:INFO:Creating metrics dataframe
2024-11-28 17:03:08,327:INFO:Initializing SVM - Linear Kernel
2024-11-28 17:03:08,327:INFO:Total runtime is 0.025906006495157875 minutes
2024-11-28 17:03:08,330:INFO:SubProcess create_model() called ==================================
2024-11-28 17:03:08,330:INFO:Initializing create_model()
2024-11-28 17:03:08,331:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC45BBE0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8D82EAFE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:03:08,331:INFO:Checking exceptions
2024-11-28 17:03:08,331:INFO:Importing libraries
2024-11-28 17:03:08,331:INFO:Copying training dataset
2024-11-28 17:03:08,334:INFO:Defining folds
2024-11-28 17:03:08,334:INFO:Declaring metric variables
2024-11-28 17:03:08,338:INFO:Importing untrained model
2024-11-28 17:03:08,341:INFO:SVM - Linear Kernel Imported successfully
2024-11-28 17:03:08,348:INFO:Starting cross validation
2024-11-28 17:03:08,350:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:03:08,450:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:03:08,542:INFO:Calculating mean and std
2024-11-28 17:03:08,543:INFO:Creating metrics dataframe
2024-11-28 17:03:08,545:INFO:Uploading results into container
2024-11-28 17:03:08,545:INFO:Uploading model into container now
2024-11-28 17:03:08,546:INFO:_master_model_container: 5
2024-11-28 17:03:08,546:INFO:_display_container: 2
2024-11-28 17:03:08,546:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1842, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-11-28 17:03:08,546:INFO:create_model() successfully completed......................................
2024-11-28 17:03:08,616:INFO:SubProcess create_model() end ==================================
2024-11-28 17:03:08,616:INFO:Creating metrics dataframe
2024-11-28 17:03:08,623:INFO:Initializing Ridge Classifier
2024-11-28 17:03:08,623:INFO:Total runtime is 0.030835135777791338 minutes
2024-11-28 17:03:08,625:INFO:SubProcess create_model() called ==================================
2024-11-28 17:03:08,626:INFO:Initializing create_model()
2024-11-28 17:03:08,626:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC45BBE0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8D82EAFE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:03:08,626:INFO:Checking exceptions
2024-11-28 17:03:08,626:INFO:Importing libraries
2024-11-28 17:03:08,626:INFO:Copying training dataset
2024-11-28 17:03:08,631:INFO:Defining folds
2024-11-28 17:03:08,631:INFO:Declaring metric variables
2024-11-28 17:03:08,633:INFO:Importing untrained model
2024-11-28 17:03:08,636:INFO:Ridge Classifier Imported successfully
2024-11-28 17:03:08,644:INFO:Starting cross validation
2024-11-28 17:03:08,645:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:03:08,835:INFO:Calculating mean and std
2024-11-28 17:03:08,837:INFO:Creating metrics dataframe
2024-11-28 17:03:08,839:INFO:Uploading results into container
2024-11-28 17:03:08,839:INFO:Uploading model into container now
2024-11-28 17:03:08,840:INFO:_master_model_container: 6
2024-11-28 17:03:08,840:INFO:_display_container: 2
2024-11-28 17:03:08,840:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1842, solver='auto',
                tol=0.0001)
2024-11-28 17:03:08,841:INFO:create_model() successfully completed......................................
2024-11-28 17:03:08,910:INFO:SubProcess create_model() end ==================================
2024-11-28 17:03:08,910:INFO:Creating metrics dataframe
2024-11-28 17:03:08,917:INFO:Initializing Random Forest Classifier
2024-11-28 17:03:08,917:INFO:Total runtime is 0.03573871850967407 minutes
2024-11-28 17:03:08,921:INFO:SubProcess create_model() called ==================================
2024-11-28 17:03:08,921:INFO:Initializing create_model()
2024-11-28 17:03:08,922:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC45BBE0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8D82EAFE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:03:08,922:INFO:Checking exceptions
2024-11-28 17:03:08,922:INFO:Importing libraries
2024-11-28 17:03:08,923:INFO:Copying training dataset
2024-11-28 17:03:08,927:INFO:Defining folds
2024-11-28 17:03:08,927:INFO:Declaring metric variables
2024-11-28 17:03:08,929:INFO:Importing untrained model
2024-11-28 17:03:08,932:INFO:Random Forest Classifier Imported successfully
2024-11-28 17:03:08,940:INFO:Starting cross validation
2024-11-28 17:03:08,941:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:03:09,640:INFO:Calculating mean and std
2024-11-28 17:03:09,644:INFO:Creating metrics dataframe
2024-11-28 17:03:09,649:INFO:Uploading results into container
2024-11-28 17:03:09,650:INFO:Uploading model into container now
2024-11-28 17:03:09,651:INFO:_master_model_container: 7
2024-11-28 17:03:09,652:INFO:_display_container: 2
2024-11-28 17:03:09,653:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=1842, verbose=0,
                       warm_start=False)
2024-11-28 17:03:09,653:INFO:create_model() successfully completed......................................
2024-11-28 17:03:09,736:INFO:SubProcess create_model() end ==================================
2024-11-28 17:03:09,736:INFO:Creating metrics dataframe
2024-11-28 17:03:09,745:INFO:Initializing Quadratic Discriminant Analysis
2024-11-28 17:03:09,745:INFO:Total runtime is 0.049535791079203285 minutes
2024-11-28 17:03:09,748:INFO:SubProcess create_model() called ==================================
2024-11-28 17:03:09,748:INFO:Initializing create_model()
2024-11-28 17:03:09,748:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC45BBE0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8D82EAFE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:03:09,748:INFO:Checking exceptions
2024-11-28 17:03:09,748:INFO:Importing libraries
2024-11-28 17:03:09,748:INFO:Copying training dataset
2024-11-28 17:03:09,753:INFO:Defining folds
2024-11-28 17:03:09,753:INFO:Declaring metric variables
2024-11-28 17:03:09,757:INFO:Importing untrained model
2024-11-28 17:03:09,760:INFO:Quadratic Discriminant Analysis Imported successfully
2024-11-28 17:03:09,766:INFO:Starting cross validation
2024-11-28 17:03:09,768:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:03:09,822:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:03:09,824:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:03:09,826:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:03:09,827:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:03:09,828:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:03:09,830:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:03:09,896:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:03:09,900:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:03:09,900:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:03:09,901:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:03:09,933:INFO:Calculating mean and std
2024-11-28 17:03:09,934:INFO:Creating metrics dataframe
2024-11-28 17:03:09,936:INFO:Uploading results into container
2024-11-28 17:03:09,937:INFO:Uploading model into container now
2024-11-28 17:03:09,937:INFO:_master_model_container: 8
2024-11-28 17:03:09,937:INFO:_display_container: 2
2024-11-28 17:03:09,937:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-11-28 17:03:09,937:INFO:create_model() successfully completed......................................
2024-11-28 17:03:10,002:INFO:SubProcess create_model() end ==================================
2024-11-28 17:03:10,003:INFO:Creating metrics dataframe
2024-11-28 17:03:10,011:INFO:Initializing Ada Boost Classifier
2024-11-28 17:03:10,011:INFO:Total runtime is 0.05396575927734375 minutes
2024-11-28 17:03:10,013:INFO:SubProcess create_model() called ==================================
2024-11-28 17:03:10,014:INFO:Initializing create_model()
2024-11-28 17:03:10,014:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC45BBE0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8D82EAFE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:03:10,014:INFO:Checking exceptions
2024-11-28 17:03:10,014:INFO:Importing libraries
2024-11-28 17:03:10,014:INFO:Copying training dataset
2024-11-28 17:03:10,018:INFO:Defining folds
2024-11-28 17:03:10,018:INFO:Declaring metric variables
2024-11-28 17:03:10,021:INFO:Importing untrained model
2024-11-28 17:03:10,024:INFO:Ada Boost Classifier Imported successfully
2024-11-28 17:03:10,031:INFO:Starting cross validation
2024-11-28 17:03:10,032:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:03:10,085:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:03:10,086:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:03:10,087:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:03:10,089:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:03:10,101:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:03:10,108:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:03:10,250:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:03:10,254:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:03:10,263:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:03:10,265:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:03:10,424:INFO:Calculating mean and std
2024-11-28 17:03:10,425:INFO:Creating metrics dataframe
2024-11-28 17:03:10,427:INFO:Uploading results into container
2024-11-28 17:03:10,427:INFO:Uploading model into container now
2024-11-28 17:03:10,428:INFO:_master_model_container: 9
2024-11-28 17:03:10,428:INFO:_display_container: 2
2024-11-28 17:03:10,428:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=1842)
2024-11-28 17:03:10,428:INFO:create_model() successfully completed......................................
2024-11-28 17:03:10,493:INFO:SubProcess create_model() end ==================================
2024-11-28 17:03:10,493:INFO:Creating metrics dataframe
2024-11-28 17:03:10,501:INFO:Initializing Gradient Boosting Classifier
2024-11-28 17:03:10,501:INFO:Total runtime is 0.06212628682454427 minutes
2024-11-28 17:03:10,504:INFO:SubProcess create_model() called ==================================
2024-11-28 17:03:10,504:INFO:Initializing create_model()
2024-11-28 17:03:10,504:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC45BBE0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8D82EAFE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:03:10,504:INFO:Checking exceptions
2024-11-28 17:03:10,504:INFO:Importing libraries
2024-11-28 17:03:10,504:INFO:Copying training dataset
2024-11-28 17:03:10,508:INFO:Defining folds
2024-11-28 17:03:10,508:INFO:Declaring metric variables
2024-11-28 17:03:10,511:INFO:Importing untrained model
2024-11-28 17:03:10,514:INFO:Gradient Boosting Classifier Imported successfully
2024-11-28 17:03:10,520:INFO:Starting cross validation
2024-11-28 17:03:10,522:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:03:11,041:INFO:Calculating mean and std
2024-11-28 17:03:11,042:INFO:Creating metrics dataframe
2024-11-28 17:03:11,044:INFO:Uploading results into container
2024-11-28 17:03:11,044:INFO:Uploading model into container now
2024-11-28 17:03:11,044:INFO:_master_model_container: 10
2024-11-28 17:03:11,044:INFO:_display_container: 2
2024-11-28 17:03:11,045:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1842, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-11-28 17:03:11,045:INFO:create_model() successfully completed......................................
2024-11-28 17:03:11,111:INFO:SubProcess create_model() end ==================================
2024-11-28 17:03:11,111:INFO:Creating metrics dataframe
2024-11-28 17:03:11,119:INFO:Initializing Linear Discriminant Analysis
2024-11-28 17:03:11,119:INFO:Total runtime is 0.07243206103642781 minutes
2024-11-28 17:03:11,122:INFO:SubProcess create_model() called ==================================
2024-11-28 17:03:11,123:INFO:Initializing create_model()
2024-11-28 17:03:11,123:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC45BBE0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8D82EAFE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:03:11,123:INFO:Checking exceptions
2024-11-28 17:03:11,123:INFO:Importing libraries
2024-11-28 17:03:11,123:INFO:Copying training dataset
2024-11-28 17:03:11,126:INFO:Defining folds
2024-11-28 17:03:11,126:INFO:Declaring metric variables
2024-11-28 17:03:11,129:INFO:Importing untrained model
2024-11-28 17:03:11,132:INFO:Linear Discriminant Analysis Imported successfully
2024-11-28 17:03:11,138:INFO:Starting cross validation
2024-11-28 17:03:11,140:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:03:11,306:INFO:Calculating mean and std
2024-11-28 17:03:11,307:INFO:Creating metrics dataframe
2024-11-28 17:03:11,308:INFO:Uploading results into container
2024-11-28 17:03:11,309:INFO:Uploading model into container now
2024-11-28 17:03:11,309:INFO:_master_model_container: 11
2024-11-28 17:03:11,309:INFO:_display_container: 2
2024-11-28 17:03:11,309:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-11-28 17:03:11,309:INFO:create_model() successfully completed......................................
2024-11-28 17:03:11,376:INFO:SubProcess create_model() end ==================================
2024-11-28 17:03:11,376:INFO:Creating metrics dataframe
2024-11-28 17:03:11,385:INFO:Initializing Extra Trees Classifier
2024-11-28 17:03:11,385:INFO:Total runtime is 0.07687017917633056 minutes
2024-11-28 17:03:11,389:INFO:SubProcess create_model() called ==================================
2024-11-28 17:03:11,389:INFO:Initializing create_model()
2024-11-28 17:03:11,389:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC45BBE0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8D82EAFE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:03:11,389:INFO:Checking exceptions
2024-11-28 17:03:11,389:INFO:Importing libraries
2024-11-28 17:03:11,389:INFO:Copying training dataset
2024-11-28 17:03:11,393:INFO:Defining folds
2024-11-28 17:03:11,393:INFO:Declaring metric variables
2024-11-28 17:03:11,395:INFO:Importing untrained model
2024-11-28 17:03:11,398:INFO:Extra Trees Classifier Imported successfully
2024-11-28 17:03:11,404:INFO:Starting cross validation
2024-11-28 17:03:11,405:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:03:12,206:INFO:Calculating mean and std
2024-11-28 17:03:12,208:INFO:Creating metrics dataframe
2024-11-28 17:03:12,212:INFO:Uploading results into container
2024-11-28 17:03:12,213:INFO:Uploading model into container now
2024-11-28 17:03:12,213:INFO:_master_model_container: 12
2024-11-28 17:03:12,214:INFO:_display_container: 2
2024-11-28 17:03:12,214:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=1842, verbose=0,
                     warm_start=False)
2024-11-28 17:03:12,214:INFO:create_model() successfully completed......................................
2024-11-28 17:03:12,291:INFO:SubProcess create_model() end ==================================
2024-11-28 17:03:12,291:INFO:Creating metrics dataframe
2024-11-28 17:03:12,300:INFO:Initializing Extreme Gradient Boosting
2024-11-28 17:03:12,300:INFO:Total runtime is 0.09212149779001871 minutes
2024-11-28 17:03:12,303:INFO:SubProcess create_model() called ==================================
2024-11-28 17:03:12,304:INFO:Initializing create_model()
2024-11-28 17:03:12,304:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC45BBE0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8D82EAFE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:03:12,304:INFO:Checking exceptions
2024-11-28 17:03:12,304:INFO:Importing libraries
2024-11-28 17:03:12,304:INFO:Copying training dataset
2024-11-28 17:03:12,309:INFO:Defining folds
2024-11-28 17:03:12,309:INFO:Declaring metric variables
2024-11-28 17:03:12,312:INFO:Importing untrained model
2024-11-28 17:03:12,317:INFO:Extreme Gradient Boosting Imported successfully
2024-11-28 17:03:12,324:INFO:Starting cross validation
2024-11-28 17:03:12,326:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:03:12,609:INFO:Calculating mean and std
2024-11-28 17:03:12,613:INFO:Creating metrics dataframe
2024-11-28 17:03:12,618:INFO:Uploading results into container
2024-11-28 17:03:12,620:INFO:Uploading model into container now
2024-11-28 17:03:12,621:INFO:_master_model_container: 13
2024-11-28 17:03:12,621:INFO:_display_container: 2
2024-11-28 17:03:12,623:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-11-28 17:03:12,623:INFO:create_model() successfully completed......................................
2024-11-28 17:03:12,743:INFO:SubProcess create_model() end ==================================
2024-11-28 17:03:12,745:INFO:Creating metrics dataframe
2024-11-28 17:03:12,755:INFO:Initializing Light Gradient Boosting Machine
2024-11-28 17:03:12,756:INFO:Total runtime is 0.09972285429636638 minutes
2024-11-28 17:03:12,759:INFO:SubProcess create_model() called ==================================
2024-11-28 17:03:12,759:INFO:Initializing create_model()
2024-11-28 17:03:12,759:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC45BBE0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8D82EAFE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:03:12,759:INFO:Checking exceptions
2024-11-28 17:03:12,759:INFO:Importing libraries
2024-11-28 17:03:12,759:INFO:Copying training dataset
2024-11-28 17:03:12,765:INFO:Defining folds
2024-11-28 17:03:12,765:INFO:Declaring metric variables
2024-11-28 17:03:12,769:INFO:Importing untrained model
2024-11-28 17:03:12,772:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-28 17:03:12,778:INFO:Starting cross validation
2024-11-28 17:03:12,779:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:03:13,444:INFO:Calculating mean and std
2024-11-28 17:03:13,445:INFO:Creating metrics dataframe
2024-11-28 17:03:13,447:INFO:Uploading results into container
2024-11-28 17:03:13,448:INFO:Uploading model into container now
2024-11-28 17:03:13,448:INFO:_master_model_container: 14
2024-11-28 17:03:13,449:INFO:_display_container: 2
2024-11-28 17:03:13,449:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1842, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-11-28 17:03:13,449:INFO:create_model() successfully completed......................................
2024-11-28 17:03:13,515:INFO:SubProcess create_model() end ==================================
2024-11-28 17:03:13,515:INFO:Creating metrics dataframe
2024-11-28 17:03:13,524:INFO:Initializing CatBoost Classifier
2024-11-28 17:03:13,524:INFO:Total runtime is 0.11250904401143393 minutes
2024-11-28 17:03:13,526:INFO:SubProcess create_model() called ==================================
2024-11-28 17:03:13,527:INFO:Initializing create_model()
2024-11-28 17:03:13,527:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC45BBE0>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8D82EAFE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:03:13,527:INFO:Checking exceptions
2024-11-28 17:03:13,527:INFO:Importing libraries
2024-11-28 17:03:13,527:INFO:Copying training dataset
2024-11-28 17:03:13,532:INFO:Defining folds
2024-11-28 17:03:13,532:INFO:Declaring metric variables
2024-11-28 17:03:13,534:INFO:Importing untrained model
2024-11-28 17:03:13,538:INFO:CatBoost Classifier Imported successfully
2024-11-28 17:03:13,545:INFO:Starting cross validation
2024-11-28 17:03:13,546:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:03:18,272:INFO:Calculating mean and std
2024-11-28 17:03:18,273:INFO:Creating metrics dataframe
2024-11-28 17:03:18,275:INFO:Uploading results into container
2024-11-28 17:03:18,275:INFO:Uploading model into container now
2024-11-28 17:03:18,276:INFO:_master_model_container: 15
2024-11-28 17:03:18,276:INFO:_display_container: 2
2024-11-28 17:03:18,276:INFO:<catboost.core.CatBoostClassifier object at 0x000002D8DA653700>
2024-11-28 17:03:18,276:INFO:create_model() successfully completed......................................
2024-11-28 17:03:18,344:INFO:SubProcess create_model() end ==================================
2024-11-28 17:03:18,344:INFO:Creating metrics dataframe
2024-11-28 17:03:18,353:INFO:Initializing Dummy Classifier
2024-11-28 17:03:18,353:INFO:Total runtime is 0.19299125274022422 minutes
2024-11-28 17:03:18,355:INFO:SubProcess create_model() called ==================================
2024-11-28 17:03:18,355:INFO:Initializing create_model()
2024-11-28 17:03:18,355:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC45BBE0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8D82EAFE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:03:18,356:INFO:Checking exceptions
2024-11-28 17:03:18,356:INFO:Importing libraries
2024-11-28 17:03:18,356:INFO:Copying training dataset
2024-11-28 17:03:18,360:INFO:Defining folds
2024-11-28 17:03:18,360:INFO:Declaring metric variables
2024-11-28 17:03:18,363:INFO:Importing untrained model
2024-11-28 17:03:18,366:INFO:Dummy Classifier Imported successfully
2024-11-28 17:03:18,373:INFO:Starting cross validation
2024-11-28 17:03:18,375:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:03:18,455:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:03:18,456:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:03:18,458:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:03:18,460:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:03:18,466:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:03:18,524:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:03:18,525:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:03:18,525:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:03:18,525:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:03:18,534:INFO:Calculating mean and std
2024-11-28 17:03:18,540:INFO:Creating metrics dataframe
2024-11-28 17:03:18,544:INFO:Uploading results into container
2024-11-28 17:03:18,545:INFO:Uploading model into container now
2024-11-28 17:03:18,546:INFO:_master_model_container: 16
2024-11-28 17:03:18,546:INFO:_display_container: 2
2024-11-28 17:03:18,546:INFO:DummyClassifier(constant=None, random_state=1842, strategy='prior')
2024-11-28 17:03:18,547:INFO:create_model() successfully completed......................................
2024-11-28 17:03:18,625:INFO:SubProcess create_model() end ==================================
2024-11-28 17:03:18,625:INFO:Creating metrics dataframe
2024-11-28 17:03:18,634:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-11-28 17:03:18,642:INFO:Initializing create_model()
2024-11-28 17:03:18,642:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC45BBE0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=1842, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:03:18,642:INFO:Checking exceptions
2024-11-28 17:03:18,644:INFO:Importing libraries
2024-11-28 17:03:18,644:INFO:Copying training dataset
2024-11-28 17:03:18,648:INFO:Defining folds
2024-11-28 17:03:18,648:INFO:Declaring metric variables
2024-11-28 17:03:18,648:INFO:Importing untrained model
2024-11-28 17:03:18,648:INFO:Declaring custom model
2024-11-28 17:03:18,649:INFO:Random Forest Classifier Imported successfully
2024-11-28 17:03:18,650:INFO:Cross validation set to False
2024-11-28 17:03:18,650:INFO:Fitting Model
2024-11-28 17:03:18,812:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=1842, verbose=0,
                       warm_start=False)
2024-11-28 17:03:18,812:INFO:create_model() successfully completed......................................
2024-11-28 17:03:18,880:INFO:Initializing create_model()
2024-11-28 17:03:18,880:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC45BBE0>, estimator=<catboost.core.CatBoostClassifier object at 0x000002D8DA653700>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:03:18,880:INFO:Checking exceptions
2024-11-28 17:03:18,881:INFO:Importing libraries
2024-11-28 17:03:18,881:INFO:Copying training dataset
2024-11-28 17:03:18,885:INFO:Defining folds
2024-11-28 17:03:18,885:INFO:Declaring metric variables
2024-11-28 17:03:18,885:INFO:Importing untrained model
2024-11-28 17:03:18,885:INFO:Declaring custom model
2024-11-28 17:03:18,886:INFO:CatBoost Classifier Imported successfully
2024-11-28 17:03:18,887:INFO:Cross validation set to False
2024-11-28 17:03:18,887:INFO:Fitting Model
2024-11-28 17:03:20,241:INFO:<catboost.core.CatBoostClassifier object at 0x000002D8D98ECA90>
2024-11-28 17:03:20,241:INFO:create_model() successfully completed......................................
2024-11-28 17:03:20,315:INFO:Initializing create_model()
2024-11-28 17:03:20,316:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC45BBE0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1842, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:03:20,316:INFO:Checking exceptions
2024-11-28 17:03:20,319:INFO:Importing libraries
2024-11-28 17:03:20,319:INFO:Copying training dataset
2024-11-28 17:03:20,323:INFO:Defining folds
2024-11-28 17:03:20,323:INFO:Declaring metric variables
2024-11-28 17:03:20,323:INFO:Importing untrained model
2024-11-28 17:03:20,323:INFO:Declaring custom model
2024-11-28 17:03:20,324:INFO:Gradient Boosting Classifier Imported successfully
2024-11-28 17:03:20,325:INFO:Cross validation set to False
2024-11-28 17:03:20,325:INFO:Fitting Model
2024-11-28 17:03:20,492:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1842, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-11-28 17:03:20,492:INFO:create_model() successfully completed......................................
2024-11-28 17:03:20,562:INFO:Initializing create_model()
2024-11-28 17:03:20,562:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC45BBE0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1842, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:03:20,563:INFO:Checking exceptions
2024-11-28 17:03:20,564:INFO:Importing libraries
2024-11-28 17:03:20,564:INFO:Copying training dataset
2024-11-28 17:03:20,567:INFO:Defining folds
2024-11-28 17:03:20,567:INFO:Declaring metric variables
2024-11-28 17:03:20,567:INFO:Importing untrained model
2024-11-28 17:03:20,567:INFO:Declaring custom model
2024-11-28 17:03:20,568:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-28 17:03:20,569:INFO:Cross validation set to False
2024-11-28 17:03:20,569:INFO:Fitting Model
2024-11-28 17:03:20,604:INFO:[LightGBM] [Info] Number of positive: 239, number of negative: 384
2024-11-28 17:03:20,604:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000099 seconds.
2024-11-28 17:03:20,605:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-11-28 17:03:20,605:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-11-28 17:03:20,605:INFO:[LightGBM] [Info] Total Bins 412
2024-11-28 17:03:20,605:INFO:[LightGBM] [Info] Number of data points in the train set: 623, number of used features: 11
2024-11-28 17:03:20,605:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383628 -> initscore=-0.474179
2024-11-28 17:03:20,605:INFO:[LightGBM] [Info] Start training from score -0.474179
2024-11-28 17:03:20,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:03:20,641:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1842, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-11-28 17:03:20,641:INFO:create_model() successfully completed......................................
2024-11-28 17:03:20,712:INFO:Initializing create_model()
2024-11-28 17:03:20,712:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC45BBE0>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=1842, verbose=0,
                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:03:20,712:INFO:Checking exceptions
2024-11-28 17:03:20,714:INFO:Importing libraries
2024-11-28 17:03:20,714:INFO:Copying training dataset
2024-11-28 17:03:20,717:INFO:Defining folds
2024-11-28 17:03:20,717:INFO:Declaring metric variables
2024-11-28 17:03:20,718:INFO:Importing untrained model
2024-11-28 17:03:20,718:INFO:Declaring custom model
2024-11-28 17:03:20,718:INFO:Extra Trees Classifier Imported successfully
2024-11-28 17:03:20,719:INFO:Cross validation set to False
2024-11-28 17:03:20,720:INFO:Fitting Model
2024-11-28 17:03:20,853:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=1842, verbose=0,
                     warm_start=False)
2024-11-28 17:03:20,853:INFO:create_model() successfully completed......................................
2024-11-28 17:03:20,923:INFO:Initializing create_model()
2024-11-28 17:03:20,923:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC45BBE0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:03:20,924:INFO:Checking exceptions
2024-11-28 17:03:20,925:INFO:Importing libraries
2024-11-28 17:03:20,925:INFO:Copying training dataset
2024-11-28 17:03:20,928:INFO:Defining folds
2024-11-28 17:03:20,928:INFO:Declaring metric variables
2024-11-28 17:03:20,928:INFO:Importing untrained model
2024-11-28 17:03:20,929:INFO:Declaring custom model
2024-11-28 17:03:20,930:INFO:Extreme Gradient Boosting Imported successfully
2024-11-28 17:03:20,930:INFO:Cross validation set to False
2024-11-28 17:03:20,930:INFO:Fitting Model
2024-11-28 17:03:20,999:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-11-28 17:03:21,000:INFO:create_model() successfully completed......................................
2024-11-28 17:03:21,069:INFO:Initializing create_model()
2024-11-28 17:03:21,070:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC45BBE0>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=1842), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:03:21,070:INFO:Checking exceptions
2024-11-28 17:03:21,072:INFO:Importing libraries
2024-11-28 17:03:21,072:INFO:Copying training dataset
2024-11-28 17:03:21,075:INFO:Defining folds
2024-11-28 17:03:21,075:INFO:Declaring metric variables
2024-11-28 17:03:21,075:INFO:Importing untrained model
2024-11-28 17:03:21,075:INFO:Declaring custom model
2024-11-28 17:03:21,076:INFO:Ada Boost Classifier Imported successfully
2024-11-28 17:03:21,077:INFO:Cross validation set to False
2024-11-28 17:03:21,077:INFO:Fitting Model
2024-11-28 17:03:21,109:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:03:21,178:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=1842)
2024-11-28 17:03:21,178:INFO:create_model() successfully completed......................................
2024-11-28 17:03:21,262:INFO:Initializing create_model()
2024-11-28 17:03:21,263:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC45BBE0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1842, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:03:21,263:INFO:Checking exceptions
2024-11-28 17:03:21,266:INFO:Importing libraries
2024-11-28 17:03:21,266:INFO:Copying training dataset
2024-11-28 17:03:21,271:INFO:Defining folds
2024-11-28 17:03:21,271:INFO:Declaring metric variables
2024-11-28 17:03:21,271:INFO:Importing untrained model
2024-11-28 17:03:21,272:INFO:Declaring custom model
2024-11-28 17:03:21,272:INFO:Ridge Classifier Imported successfully
2024-11-28 17:03:21,273:INFO:Cross validation set to False
2024-11-28 17:03:21,273:INFO:Fitting Model
2024-11-28 17:03:21,311:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1842, solver='auto',
                tol=0.0001)
2024-11-28 17:03:21,311:INFO:create_model() successfully completed......................................
2024-11-28 17:03:21,382:INFO:Initializing create_model()
2024-11-28 17:03:21,383:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC45BBE0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1842, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:03:21,383:INFO:Checking exceptions
2024-11-28 17:03:21,384:INFO:Importing libraries
2024-11-28 17:03:21,384:INFO:Copying training dataset
2024-11-28 17:03:21,388:INFO:Defining folds
2024-11-28 17:03:21,388:INFO:Declaring metric variables
2024-11-28 17:03:21,389:INFO:Importing untrained model
2024-11-28 17:03:21,389:INFO:Declaring custom model
2024-11-28 17:03:21,389:INFO:Logistic Regression Imported successfully
2024-11-28 17:03:21,390:INFO:Cross validation set to False
2024-11-28 17:03:21,390:INFO:Fitting Model
2024-11-28 17:03:21,529:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:03:21,530:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1842, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-11-28 17:03:21,530:INFO:create_model() successfully completed......................................
2024-11-28 17:03:21,600:INFO:Initializing create_model()
2024-11-28 17:03:21,601:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC45BBE0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:03:21,601:INFO:Checking exceptions
2024-11-28 17:03:21,604:INFO:Importing libraries
2024-11-28 17:03:21,604:INFO:Copying training dataset
2024-11-28 17:03:21,607:INFO:Defining folds
2024-11-28 17:03:21,607:INFO:Declaring metric variables
2024-11-28 17:03:21,607:INFO:Importing untrained model
2024-11-28 17:03:21,607:INFO:Declaring custom model
2024-11-28 17:03:21,608:INFO:Linear Discriminant Analysis Imported successfully
2024-11-28 17:03:21,608:INFO:Cross validation set to False
2024-11-28 17:03:21,608:INFO:Fitting Model
2024-11-28 17:03:21,641:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-11-28 17:03:21,641:INFO:create_model() successfully completed......................................
2024-11-28 17:03:21,710:INFO:Initializing create_model()
2024-11-28 17:03:21,710:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC45BBE0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:03:21,710:INFO:Checking exceptions
2024-11-28 17:03:21,713:INFO:Importing libraries
2024-11-28 17:03:21,713:INFO:Copying training dataset
2024-11-28 17:03:21,716:INFO:Defining folds
2024-11-28 17:03:21,716:INFO:Declaring metric variables
2024-11-28 17:03:21,716:INFO:Importing untrained model
2024-11-28 17:03:21,716:INFO:Declaring custom model
2024-11-28 17:03:21,716:INFO:Naive Bayes Imported successfully
2024-11-28 17:03:21,717:INFO:Cross validation set to False
2024-11-28 17:03:21,717:INFO:Fitting Model
2024-11-28 17:03:21,749:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-11-28 17:03:21,749:INFO:create_model() successfully completed......................................
2024-11-28 17:03:21,839:INFO:Initializing create_model()
2024-11-28 17:03:21,839:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC45BBE0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=1842, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:03:21,839:INFO:Checking exceptions
2024-11-28 17:03:21,843:INFO:Importing libraries
2024-11-28 17:03:21,843:INFO:Copying training dataset
2024-11-28 17:03:21,847:INFO:Defining folds
2024-11-28 17:03:21,847:INFO:Declaring metric variables
2024-11-28 17:03:21,847:INFO:Importing untrained model
2024-11-28 17:03:21,847:INFO:Declaring custom model
2024-11-28 17:03:21,847:INFO:Decision Tree Classifier Imported successfully
2024-11-28 17:03:21,848:INFO:Cross validation set to False
2024-11-28 17:03:21,848:INFO:Fitting Model
2024-11-28 17:03:21,888:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=1842, splitter='best')
2024-11-28 17:03:21,888:INFO:create_model() successfully completed......................................
2024-11-28 17:03:21,959:INFO:Initializing create_model()
2024-11-28 17:03:21,959:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC45BBE0>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:03:21,959:INFO:Checking exceptions
2024-11-28 17:03:21,962:INFO:Importing libraries
2024-11-28 17:03:21,962:INFO:Copying training dataset
2024-11-28 17:03:21,965:INFO:Defining folds
2024-11-28 17:03:21,965:INFO:Declaring metric variables
2024-11-28 17:03:21,965:INFO:Importing untrained model
2024-11-28 17:03:21,965:INFO:Declaring custom model
2024-11-28 17:03:21,966:INFO:Quadratic Discriminant Analysis Imported successfully
2024-11-28 17:03:21,967:INFO:Cross validation set to False
2024-11-28 17:03:21,967:INFO:Fitting Model
2024-11-28 17:03:21,999:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:03:22,000:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-11-28 17:03:22,000:INFO:create_model() successfully completed......................................
2024-11-28 17:03:22,068:INFO:Initializing create_model()
2024-11-28 17:03:22,068:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC45BBE0>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:03:22,068:INFO:Checking exceptions
2024-11-28 17:03:22,070:INFO:Importing libraries
2024-11-28 17:03:22,070:INFO:Copying training dataset
2024-11-28 17:03:22,074:INFO:Defining folds
2024-11-28 17:03:22,074:INFO:Declaring metric variables
2024-11-28 17:03:22,075:INFO:Importing untrained model
2024-11-28 17:03:22,075:INFO:Declaring custom model
2024-11-28 17:03:22,075:INFO:K Neighbors Classifier Imported successfully
2024-11-28 17:03:22,076:INFO:Cross validation set to False
2024-11-28 17:03:22,076:INFO:Fitting Model
2024-11-28 17:03:22,109:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-11-28 17:03:22,109:INFO:create_model() successfully completed......................................
2024-11-28 17:03:22,178:INFO:Initializing create_model()
2024-11-28 17:03:22,178:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC45BBE0>, estimator=DummyClassifier(constant=None, random_state=1842, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:03:22,178:INFO:Checking exceptions
2024-11-28 17:03:22,181:INFO:Importing libraries
2024-11-28 17:03:22,181:INFO:Copying training dataset
2024-11-28 17:03:22,184:INFO:Defining folds
2024-11-28 17:03:22,184:INFO:Declaring metric variables
2024-11-28 17:03:22,184:INFO:Importing untrained model
2024-11-28 17:03:22,184:INFO:Declaring custom model
2024-11-28 17:03:22,185:INFO:Dummy Classifier Imported successfully
2024-11-28 17:03:22,186:INFO:Cross validation set to False
2024-11-28 17:03:22,186:INFO:Fitting Model
2024-11-28 17:03:22,216:INFO:DummyClassifier(constant=None, random_state=1842, strategy='prior')
2024-11-28 17:03:22,216:INFO:create_model() successfully completed......................................
2024-11-28 17:03:22,285:INFO:Initializing create_model()
2024-11-28 17:03:22,285:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8BC45BBE0>, estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1842, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:03:22,285:INFO:Checking exceptions
2024-11-28 17:03:22,287:INFO:Importing libraries
2024-11-28 17:03:22,287:INFO:Copying training dataset
2024-11-28 17:03:22,292:INFO:Defining folds
2024-11-28 17:03:22,292:INFO:Declaring metric variables
2024-11-28 17:03:22,292:INFO:Importing untrained model
2024-11-28 17:03:22,292:INFO:Declaring custom model
2024-11-28 17:03:22,292:INFO:SVM - Linear Kernel Imported successfully
2024-11-28 17:03:22,293:INFO:Cross validation set to False
2024-11-28 17:03:22,293:INFO:Fitting Model
2024-11-28 17:03:22,328:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1842, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-11-28 17:03:22,329:INFO:create_model() successfully completed......................................
2024-11-28 17:03:22,410:INFO:_master_model_container: 16
2024-11-28 17:03:22,410:INFO:_display_container: 2
2024-11-28 17:03:22,413:INFO:[RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=1842, verbose=0,
                       warm_start=False), <catboost.core.CatBoostClassifier object at 0x000002D8D98ECA90>, GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1842, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1842, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=1842, verbose=0,
                     warm_start=False), XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=1842), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1842, solver='auto',
                tol=0.0001), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1842, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=1842, splitter='best'), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), DummyClassifier(constant=None, random_state=1842, strategy='prior'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1842, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)]
2024-11-28 17:03:22,413:INFO:compare_models() successfully completed......................................
2024-11-28 17:03:55,543:INFO:PyCaret ClassificationExperiment
2024-11-28 17:03:55,543:INFO:Logging name: clf-default-name
2024-11-28 17:03:55,543:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-11-28 17:03:55,543:INFO:version 3.3.2
2024-11-28 17:03:55,543:INFO:Initializing setup()
2024-11-28 17:03:55,543:INFO:self.USI: 9c49
2024-11-28 17:03:55,543:INFO:self._variable_keys: {'exp_name_log', 'y_test', 'idx', 'y_train', 'log_plots_param', 'memory', 'pipeline', 'X', 'gpu_param', 'fold_generator', 'logging_param', 'n_jobs_param', 'exp_id', 'is_multiclass', 'fix_imbalance', '_available_plots', 'html_param', 'gpu_n_jobs_param', 'X_test', 'X_train', 'y', 'data', 'fold_shuffle_param', 'seed', 'fold_groups_param', '_ml_usecase', 'target_param', 'USI'}
2024-11-28 17:03:55,543:INFO:Checking environment
2024-11-28 17:03:55,543:INFO:python_version: 3.10.11
2024-11-28 17:03:55,543:INFO:python_build: ('tags/v3.10.11:7d4cc5a', 'Apr  5 2023 00:38:17')
2024-11-28 17:03:55,543:INFO:machine: AMD64
2024-11-28 17:03:55,543:INFO:platform: Windows-10-10.0.19045-SP0
2024-11-28 17:03:55,547:INFO:Memory: svmem(total=34216488960, available=20689678336, percent=39.5, used=13526810624, free=20689678336)
2024-11-28 17:03:55,547:INFO:Physical Core: 6
2024-11-28 17:03:55,547:INFO:Logical Core: 6
2024-11-28 17:03:55,547:INFO:Checking libraries
2024-11-28 17:03:55,547:INFO:System:
2024-11-28 17:03:55,547:INFO:    python: 3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]
2024-11-28 17:03:55,548:INFO:executable: c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\Scripts\python.exe
2024-11-28 17:03:55,548:INFO:   machine: Windows-10-10.0.19045-SP0
2024-11-28 17:03:55,548:INFO:PyCaret required dependencies:
2024-11-28 17:03:55,548:INFO:                 pip: 23.0.1
2024-11-28 17:03:55,548:INFO:          setuptools: 65.5.0
2024-11-28 17:03:55,548:INFO:             pycaret: 3.3.2
2024-11-28 17:03:55,548:INFO:             IPython: 8.29.0
2024-11-28 17:03:55,548:INFO:          ipywidgets: 8.1.5
2024-11-28 17:03:55,548:INFO:                tqdm: 4.67.1
2024-11-28 17:03:55,548:INFO:               numpy: 1.26.4
2024-11-28 17:03:55,548:INFO:              pandas: 2.1.4
2024-11-28 17:03:55,548:INFO:              jinja2: 3.1.4
2024-11-28 17:03:55,548:INFO:               scipy: 1.11.4
2024-11-28 17:03:55,548:INFO:              joblib: 1.3.2
2024-11-28 17:03:55,548:INFO:             sklearn: 1.4.2
2024-11-28 17:03:55,548:INFO:                pyod: 2.0.2
2024-11-28 17:03:55,548:INFO:            imblearn: 0.12.4
2024-11-28 17:03:55,548:INFO:   category_encoders: 2.6.4
2024-11-28 17:03:55,548:INFO:            lightgbm: 4.5.0
2024-11-28 17:03:55,548:INFO:               numba: 0.60.0
2024-11-28 17:03:55,548:INFO:            requests: 2.32.3
2024-11-28 17:03:55,548:INFO:          matplotlib: 3.7.5
2024-11-28 17:03:55,548:INFO:          scikitplot: 0.3.7
2024-11-28 17:03:55,548:INFO:         yellowbrick: 1.5
2024-11-28 17:03:55,548:INFO:              plotly: 5.24.1
2024-11-28 17:03:55,548:INFO:    plotly-resampler: Not installed
2024-11-28 17:03:55,548:INFO:             kaleido: 0.2.1
2024-11-28 17:03:55,549:INFO:           schemdraw: 0.15
2024-11-28 17:03:55,549:INFO:         statsmodels: 0.14.4
2024-11-28 17:03:55,549:INFO:              sktime: 0.26.0
2024-11-28 17:03:55,549:INFO:               tbats: 1.1.3
2024-11-28 17:03:55,549:INFO:            pmdarima: 2.0.4
2024-11-28 17:03:55,549:INFO:              psutil: 6.1.0
2024-11-28 17:03:55,549:INFO:          markupsafe: 3.0.2
2024-11-28 17:03:55,549:INFO:             pickle5: Not installed
2024-11-28 17:03:55,549:INFO:         cloudpickle: 3.1.0
2024-11-28 17:03:55,549:INFO:         deprecation: 2.1.0
2024-11-28 17:03:55,549:INFO:              xxhash: 3.5.0
2024-11-28 17:03:55,549:INFO:           wurlitzer: Not installed
2024-11-28 17:03:55,549:INFO:PyCaret optional dependencies:
2024-11-28 17:03:55,549:INFO:                shap: Not installed
2024-11-28 17:03:55,549:INFO:           interpret: Not installed
2024-11-28 17:03:55,549:INFO:                umap: Not installed
2024-11-28 17:03:55,549:INFO:     ydata_profiling: Not installed
2024-11-28 17:03:55,549:INFO:  explainerdashboard: Not installed
2024-11-28 17:03:55,549:INFO:             autoviz: Not installed
2024-11-28 17:03:55,549:INFO:           fairlearn: Not installed
2024-11-28 17:03:55,549:INFO:          deepchecks: Not installed
2024-11-28 17:03:55,549:INFO:             xgboost: 2.1.3
2024-11-28 17:03:55,549:INFO:            catboost: 1.2.7
2024-11-28 17:03:55,549:INFO:              kmodes: Not installed
2024-11-28 17:03:55,549:INFO:             mlxtend: 0.23.3
2024-11-28 17:03:55,549:INFO:       statsforecast: Not installed
2024-11-28 17:03:55,549:INFO:        tune_sklearn: Not installed
2024-11-28 17:03:55,549:INFO:                 ray: Not installed
2024-11-28 17:03:55,550:INFO:            hyperopt: Not installed
2024-11-28 17:03:55,550:INFO:              optuna: Not installed
2024-11-28 17:03:55,550:INFO:               skopt: Not installed
2024-11-28 17:03:55,550:INFO:              mlflow: Not installed
2024-11-28 17:03:55,550:INFO:              gradio: Not installed
2024-11-28 17:03:55,550:INFO:             fastapi: Not installed
2024-11-28 17:03:55,550:INFO:             uvicorn: Not installed
2024-11-28 17:03:55,550:INFO:              m2cgen: Not installed
2024-11-28 17:03:55,550:INFO:           evidently: Not installed
2024-11-28 17:03:55,550:INFO:               fugue: Not installed
2024-11-28 17:03:55,550:INFO:           streamlit: 1.39.0
2024-11-28 17:03:55,550:INFO:             prophet: Not installed
2024-11-28 17:03:55,550:INFO:None
2024-11-28 17:03:55,550:INFO:Set up data.
2024-11-28 17:03:55,555:INFO:Set up folding strategy.
2024-11-28 17:03:55,555:INFO:Set up train/test split.
2024-11-28 17:03:55,558:INFO:Set up index.
2024-11-28 17:03:55,559:INFO:Assigning column types.
2024-11-28 17:03:55,561:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-28 17:03:55,599:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-28 17:03:55,600:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-28 17:03:55,623:INFO:Soft dependency imported: xgboost: 2.1.3
2024-11-28 17:03:55,626:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-28 17:03:55,663:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-28 17:03:55,664:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-28 17:03:55,688:INFO:Soft dependency imported: xgboost: 2.1.3
2024-11-28 17:03:55,690:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-28 17:03:55,691:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-28 17:03:55,731:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-28 17:03:55,757:INFO:Soft dependency imported: xgboost: 2.1.3
2024-11-28 17:03:55,759:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-28 17:03:55,801:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-28 17:03:55,825:INFO:Soft dependency imported: xgboost: 2.1.3
2024-11-28 17:03:55,828:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-28 17:03:55,828:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-11-28 17:03:55,890:INFO:Soft dependency imported: xgboost: 2.1.3
2024-11-28 17:03:55,892:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-28 17:03:55,955:INFO:Soft dependency imported: xgboost: 2.1.3
2024-11-28 17:03:55,957:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-28 17:03:55,959:INFO:Preparing preprocessing pipeline...
2024-11-28 17:03:55,959:INFO:Set up simple imputation.
2024-11-28 17:03:55,962:INFO:Set up encoding of ordinal features.
2024-11-28 17:03:55,963:INFO:Set up encoding of categorical features.
2024-11-28 17:03:56,017:INFO:Finished creating preprocessing pipeline.
2024-11-28 17:03:56,031:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\tsai\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare',
                                             'FamilySize'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('...
                                                               mapping=[{'col': 'Sex',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['Embarked'],
                                    transformer=OneHotEncoder(cols=['Embarked'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-11-28 17:03:56,031:INFO:Creating final display dataframe.
2024-11-28 17:03:56,189:INFO:Setup _display_container:                     Description             Value
0                    Session id              7045
1                        Target          Survived
2                   Target type            Binary
3           Original data shape         (891, 10)
4        Transformed data shape         (891, 12)
5   Transformed train set shape         (623, 12)
6    Transformed test set shape         (268, 12)
7              Numeric features                 7
8          Categorical features                 2
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              9c49
2024-11-28 17:03:56,256:INFO:Soft dependency imported: xgboost: 2.1.3
2024-11-28 17:03:56,259:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-28 17:03:56,324:INFO:Soft dependency imported: xgboost: 2.1.3
2024-11-28 17:03:56,327:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-28 17:03:56,328:INFO:setup() successfully completed in 0.79s...............
2024-11-28 17:03:56,329:INFO:Initializing compare_models()
2024-11-28 17:03:56,329:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA38C700>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=16, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA38C700>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 16, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-11-28 17:03:56,329:INFO:Checking exceptions
2024-11-28 17:03:56,332:INFO:Preparing display monitor
2024-11-28 17:03:56,353:INFO:Initializing Logistic Regression
2024-11-28 17:03:56,353:INFO:Total runtime is 0.0 minutes
2024-11-28 17:03:56,356:INFO:SubProcess create_model() called ==================================
2024-11-28 17:03:56,357:INFO:Initializing create_model()
2024-11-28 17:03:56,357:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA38C700>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8BC45BB20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:03:56,357:INFO:Checking exceptions
2024-11-28 17:03:56,357:INFO:Importing libraries
2024-11-28 17:03:56,357:INFO:Copying training dataset
2024-11-28 17:03:56,362:INFO:Defining folds
2024-11-28 17:03:56,362:INFO:Declaring metric variables
2024-11-28 17:03:56,366:INFO:Importing untrained model
2024-11-28 17:03:56,370:INFO:Logistic Regression Imported successfully
2024-11-28 17:03:56,377:INFO:Starting cross validation
2024-11-28 17:03:56,378:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:03:56,566:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:03:56,568:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:03:56,571:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:03:56,572:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:03:56,577:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:03:56,578:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:03:56,746:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:03:56,747:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:03:56,754:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:03:56,754:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:03:56,797:INFO:Calculating mean and std
2024-11-28 17:03:56,799:INFO:Creating metrics dataframe
2024-11-28 17:03:56,804:INFO:Uploading results into container
2024-11-28 17:03:56,805:INFO:Uploading model into container now
2024-11-28 17:03:56,806:INFO:_master_model_container: 1
2024-11-28 17:03:56,806:INFO:_display_container: 2
2024-11-28 17:03:56,807:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7045, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-11-28 17:03:56,808:INFO:create_model() successfully completed......................................
2024-11-28 17:03:56,939:INFO:SubProcess create_model() end ==================================
2024-11-28 17:03:56,939:INFO:Creating metrics dataframe
2024-11-28 17:03:56,946:INFO:Initializing K Neighbors Classifier
2024-11-28 17:03:56,946:INFO:Total runtime is 0.009875945250193278 minutes
2024-11-28 17:03:56,949:INFO:SubProcess create_model() called ==================================
2024-11-28 17:03:56,950:INFO:Initializing create_model()
2024-11-28 17:03:56,950:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA38C700>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8BC45BB20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:03:56,950:INFO:Checking exceptions
2024-11-28 17:03:56,950:INFO:Importing libraries
2024-11-28 17:03:56,950:INFO:Copying training dataset
2024-11-28 17:03:56,955:INFO:Defining folds
2024-11-28 17:03:56,955:INFO:Declaring metric variables
2024-11-28 17:03:56,959:INFO:Importing untrained model
2024-11-28 17:03:56,962:INFO:K Neighbors Classifier Imported successfully
2024-11-28 17:03:56,994:INFO:Starting cross validation
2024-11-28 17:03:56,996:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:03:57,356:INFO:Calculating mean and std
2024-11-28 17:03:57,358:INFO:Creating metrics dataframe
2024-11-28 17:03:57,361:INFO:Uploading results into container
2024-11-28 17:03:57,361:INFO:Uploading model into container now
2024-11-28 17:03:57,362:INFO:_master_model_container: 2
2024-11-28 17:03:57,362:INFO:_display_container: 2
2024-11-28 17:03:57,362:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-11-28 17:03:57,363:INFO:create_model() successfully completed......................................
2024-11-28 17:03:57,445:INFO:SubProcess create_model() end ==================================
2024-11-28 17:03:57,445:INFO:Creating metrics dataframe
2024-11-28 17:03:57,452:INFO:Initializing Naive Bayes
2024-11-28 17:03:57,452:INFO:Total runtime is 0.018306473890940346 minutes
2024-11-28 17:03:57,456:INFO:SubProcess create_model() called ==================================
2024-11-28 17:03:57,456:INFO:Initializing create_model()
2024-11-28 17:03:57,456:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA38C700>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8BC45BB20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:03:57,456:INFO:Checking exceptions
2024-11-28 17:03:57,456:INFO:Importing libraries
2024-11-28 17:03:57,457:INFO:Copying training dataset
2024-11-28 17:03:57,461:INFO:Defining folds
2024-11-28 17:03:57,461:INFO:Declaring metric variables
2024-11-28 17:03:57,465:INFO:Importing untrained model
2024-11-28 17:03:57,468:INFO:Naive Bayes Imported successfully
2024-11-28 17:03:57,476:INFO:Starting cross validation
2024-11-28 17:03:57,479:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:03:57,651:INFO:Calculating mean and std
2024-11-28 17:03:57,659:INFO:Creating metrics dataframe
2024-11-28 17:03:57,666:INFO:Uploading results into container
2024-11-28 17:03:57,670:INFO:Uploading model into container now
2024-11-28 17:03:57,672:INFO:_master_model_container: 3
2024-11-28 17:03:57,672:INFO:_display_container: 2
2024-11-28 17:03:57,673:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-11-28 17:03:57,673:INFO:create_model() successfully completed......................................
2024-11-28 17:03:57,795:INFO:SubProcess create_model() end ==================================
2024-11-28 17:03:57,795:INFO:Creating metrics dataframe
2024-11-28 17:03:57,802:INFO:Initializing Decision Tree Classifier
2024-11-28 17:03:57,802:INFO:Total runtime is 0.02414300441741943 minutes
2024-11-28 17:03:57,805:INFO:SubProcess create_model() called ==================================
2024-11-28 17:03:57,805:INFO:Initializing create_model()
2024-11-28 17:03:57,806:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA38C700>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8BC45BB20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:03:57,806:INFO:Checking exceptions
2024-11-28 17:03:57,806:INFO:Importing libraries
2024-11-28 17:03:57,806:INFO:Copying training dataset
2024-11-28 17:03:57,810:INFO:Defining folds
2024-11-28 17:03:57,810:INFO:Declaring metric variables
2024-11-28 17:03:57,813:INFO:Importing untrained model
2024-11-28 17:03:57,818:INFO:Decision Tree Classifier Imported successfully
2024-11-28 17:03:57,825:INFO:Starting cross validation
2024-11-28 17:03:57,826:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:03:57,990:INFO:Calculating mean and std
2024-11-28 17:03:57,993:INFO:Creating metrics dataframe
2024-11-28 17:03:57,997:INFO:Uploading results into container
2024-11-28 17:03:57,998:INFO:Uploading model into container now
2024-11-28 17:03:57,999:INFO:_master_model_container: 4
2024-11-28 17:03:57,999:INFO:_display_container: 2
2024-11-28 17:03:58,000:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7045, splitter='best')
2024-11-28 17:03:58,000:INFO:create_model() successfully completed......................................
2024-11-28 17:03:58,084:INFO:SubProcess create_model() end ==================================
2024-11-28 17:03:58,084:INFO:Creating metrics dataframe
2024-11-28 17:03:58,092:INFO:Initializing SVM - Linear Kernel
2024-11-28 17:03:58,092:INFO:Total runtime is 0.02898004055023193 minutes
2024-11-28 17:03:58,094:INFO:SubProcess create_model() called ==================================
2024-11-28 17:03:58,094:INFO:Initializing create_model()
2024-11-28 17:03:58,094:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA38C700>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8BC45BB20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:03:58,094:INFO:Checking exceptions
2024-11-28 17:03:58,094:INFO:Importing libraries
2024-11-28 17:03:58,095:INFO:Copying training dataset
2024-11-28 17:03:58,099:INFO:Defining folds
2024-11-28 17:03:58,099:INFO:Declaring metric variables
2024-11-28 17:03:58,102:INFO:Importing untrained model
2024-11-28 17:03:58,107:INFO:SVM - Linear Kernel Imported successfully
2024-11-28 17:03:58,113:INFO:Starting cross validation
2024-11-28 17:03:58,114:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:03:58,285:INFO:Calculating mean and std
2024-11-28 17:03:58,286:INFO:Creating metrics dataframe
2024-11-28 17:03:58,288:INFO:Uploading results into container
2024-11-28 17:03:58,288:INFO:Uploading model into container now
2024-11-28 17:03:58,288:INFO:_master_model_container: 5
2024-11-28 17:03:58,288:INFO:_display_container: 2
2024-11-28 17:03:58,289:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=7045, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-11-28 17:03:58,289:INFO:create_model() successfully completed......................................
2024-11-28 17:03:58,354:INFO:SubProcess create_model() end ==================================
2024-11-28 17:03:58,355:INFO:Creating metrics dataframe
2024-11-28 17:03:58,361:INFO:Initializing Ridge Classifier
2024-11-28 17:03:58,361:INFO:Total runtime is 0.033457008997599284 minutes
2024-11-28 17:03:58,364:INFO:SubProcess create_model() called ==================================
2024-11-28 17:03:58,364:INFO:Initializing create_model()
2024-11-28 17:03:58,364:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA38C700>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8BC45BB20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:03:58,364:INFO:Checking exceptions
2024-11-28 17:03:58,364:INFO:Importing libraries
2024-11-28 17:03:58,365:INFO:Copying training dataset
2024-11-28 17:03:58,368:INFO:Defining folds
2024-11-28 17:03:58,368:INFO:Declaring metric variables
2024-11-28 17:03:58,372:INFO:Importing untrained model
2024-11-28 17:03:58,374:INFO:Ridge Classifier Imported successfully
2024-11-28 17:03:58,381:INFO:Starting cross validation
2024-11-28 17:03:58,382:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:03:58,548:INFO:Calculating mean and std
2024-11-28 17:03:58,552:INFO:Creating metrics dataframe
2024-11-28 17:03:58,557:INFO:Uploading results into container
2024-11-28 17:03:58,558:INFO:Uploading model into container now
2024-11-28 17:03:58,559:INFO:_master_model_container: 6
2024-11-28 17:03:58,559:INFO:_display_container: 2
2024-11-28 17:03:58,559:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=7045, solver='auto',
                tol=0.0001)
2024-11-28 17:03:58,559:INFO:create_model() successfully completed......................................
2024-11-28 17:03:58,644:INFO:SubProcess create_model() end ==================================
2024-11-28 17:03:58,644:INFO:Creating metrics dataframe
2024-11-28 17:03:58,652:INFO:Initializing Random Forest Classifier
2024-11-28 17:03:58,652:INFO:Total runtime is 0.03831180334091187 minutes
2024-11-28 17:03:58,655:INFO:SubProcess create_model() called ==================================
2024-11-28 17:03:58,655:INFO:Initializing create_model()
2024-11-28 17:03:58,655:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA38C700>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8BC45BB20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:03:58,655:INFO:Checking exceptions
2024-11-28 17:03:58,656:INFO:Importing libraries
2024-11-28 17:03:58,656:INFO:Copying training dataset
2024-11-28 17:03:58,660:INFO:Defining folds
2024-11-28 17:03:58,660:INFO:Declaring metric variables
2024-11-28 17:03:58,662:INFO:Importing untrained model
2024-11-28 17:03:58,666:INFO:Random Forest Classifier Imported successfully
2024-11-28 17:03:58,672:INFO:Starting cross validation
2024-11-28 17:03:58,674:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:03:59,305:INFO:Calculating mean and std
2024-11-28 17:03:59,306:INFO:Creating metrics dataframe
2024-11-28 17:03:59,307:INFO:Uploading results into container
2024-11-28 17:03:59,308:INFO:Uploading model into container now
2024-11-28 17:03:59,308:INFO:_master_model_container: 7
2024-11-28 17:03:59,308:INFO:_display_container: 2
2024-11-28 17:03:59,308:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=7045, verbose=0,
                       warm_start=False)
2024-11-28 17:03:59,309:INFO:create_model() successfully completed......................................
2024-11-28 17:03:59,374:INFO:SubProcess create_model() end ==================================
2024-11-28 17:03:59,374:INFO:Creating metrics dataframe
2024-11-28 17:03:59,381:INFO:Initializing Quadratic Discriminant Analysis
2024-11-28 17:03:59,382:INFO:Total runtime is 0.05047746102015178 minutes
2024-11-28 17:03:59,387:INFO:SubProcess create_model() called ==================================
2024-11-28 17:03:59,387:INFO:Initializing create_model()
2024-11-28 17:03:59,387:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA38C700>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8BC45BB20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:03:59,387:INFO:Checking exceptions
2024-11-28 17:03:59,387:INFO:Importing libraries
2024-11-28 17:03:59,387:INFO:Copying training dataset
2024-11-28 17:03:59,391:INFO:Defining folds
2024-11-28 17:03:59,392:INFO:Declaring metric variables
2024-11-28 17:03:59,394:INFO:Importing untrained model
2024-11-28 17:03:59,397:INFO:Quadratic Discriminant Analysis Imported successfully
2024-11-28 17:03:59,404:INFO:Starting cross validation
2024-11-28 17:03:59,405:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:03:59,458:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:03:59,459:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:03:59,463:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:03:59,463:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:03:59,465:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:03:59,466:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:03:59,529:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:03:59,532:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:03:59,533:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:03:59,535:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:03:59,569:INFO:Calculating mean and std
2024-11-28 17:03:59,572:INFO:Creating metrics dataframe
2024-11-28 17:03:59,576:INFO:Uploading results into container
2024-11-28 17:03:59,577:INFO:Uploading model into container now
2024-11-28 17:03:59,578:INFO:_master_model_container: 8
2024-11-28 17:03:59,578:INFO:_display_container: 2
2024-11-28 17:03:59,579:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-11-28 17:03:59,579:INFO:create_model() successfully completed......................................
2024-11-28 17:03:59,646:INFO:SubProcess create_model() end ==================================
2024-11-28 17:03:59,646:INFO:Creating metrics dataframe
2024-11-28 17:03:59,653:INFO:Initializing Ada Boost Classifier
2024-11-28 17:03:59,653:INFO:Total runtime is 0.054995814959208175 minutes
2024-11-28 17:03:59,656:INFO:SubProcess create_model() called ==================================
2024-11-28 17:03:59,656:INFO:Initializing create_model()
2024-11-28 17:03:59,656:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA38C700>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8BC45BB20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:03:59,656:INFO:Checking exceptions
2024-11-28 17:03:59,657:INFO:Importing libraries
2024-11-28 17:03:59,657:INFO:Copying training dataset
2024-11-28 17:03:59,660:INFO:Defining folds
2024-11-28 17:03:59,661:INFO:Declaring metric variables
2024-11-28 17:03:59,663:INFO:Importing untrained model
2024-11-28 17:03:59,666:INFO:Ada Boost Classifier Imported successfully
2024-11-28 17:03:59,672:INFO:Starting cross validation
2024-11-28 17:03:59,673:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:03:59,736:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:03:59,739:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:03:59,770:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:03:59,771:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:03:59,774:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:03:59,775:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:03:59,902:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:03:59,932:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:03:59,945:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:03:59,954:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:04:00,110:INFO:Calculating mean and std
2024-11-28 17:04:00,114:INFO:Creating metrics dataframe
2024-11-28 17:04:00,120:INFO:Uploading results into container
2024-11-28 17:04:00,121:INFO:Uploading model into container now
2024-11-28 17:04:00,122:INFO:_master_model_container: 9
2024-11-28 17:04:00,123:INFO:_display_container: 2
2024-11-28 17:04:00,123:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=7045)
2024-11-28 17:04:00,124:INFO:create_model() successfully completed......................................
2024-11-28 17:04:00,262:INFO:SubProcess create_model() end ==================================
2024-11-28 17:04:00,262:INFO:Creating metrics dataframe
2024-11-28 17:04:00,280:INFO:Initializing Gradient Boosting Classifier
2024-11-28 17:04:00,280:INFO:Total runtime is 0.06544463634490967 minutes
2024-11-28 17:04:00,286:INFO:SubProcess create_model() called ==================================
2024-11-28 17:04:00,287:INFO:Initializing create_model()
2024-11-28 17:04:00,287:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA38C700>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8BC45BB20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:04:00,287:INFO:Checking exceptions
2024-11-28 17:04:00,287:INFO:Importing libraries
2024-11-28 17:04:00,287:INFO:Copying training dataset
2024-11-28 17:04:00,295:INFO:Defining folds
2024-11-28 17:04:00,296:INFO:Declaring metric variables
2024-11-28 17:04:00,302:INFO:Importing untrained model
2024-11-28 17:04:00,309:INFO:Gradient Boosting Classifier Imported successfully
2024-11-28 17:04:00,322:INFO:Starting cross validation
2024-11-28 17:04:00,324:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:04:00,775:INFO:Calculating mean and std
2024-11-28 17:04:00,780:INFO:Creating metrics dataframe
2024-11-28 17:04:00,786:INFO:Uploading results into container
2024-11-28 17:04:00,788:INFO:Uploading model into container now
2024-11-28 17:04:00,789:INFO:_master_model_container: 10
2024-11-28 17:04:00,789:INFO:_display_container: 2
2024-11-28 17:04:00,790:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=7045, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-11-28 17:04:00,791:INFO:create_model() successfully completed......................................
2024-11-28 17:04:00,900:INFO:SubProcess create_model() end ==================================
2024-11-28 17:04:00,900:INFO:Creating metrics dataframe
2024-11-28 17:04:00,916:INFO:Initializing Linear Discriminant Analysis
2024-11-28 17:04:00,916:INFO:Total runtime is 0.0760424017906189 minutes
2024-11-28 17:04:00,921:INFO:SubProcess create_model() called ==================================
2024-11-28 17:04:00,921:INFO:Initializing create_model()
2024-11-28 17:04:00,921:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA38C700>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8BC45BB20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:04:00,921:INFO:Checking exceptions
2024-11-28 17:04:00,921:INFO:Importing libraries
2024-11-28 17:04:00,922:INFO:Copying training dataset
2024-11-28 17:04:00,926:INFO:Defining folds
2024-11-28 17:04:00,927:INFO:Declaring metric variables
2024-11-28 17:04:00,930:INFO:Importing untrained model
2024-11-28 17:04:00,935:INFO:Linear Discriminant Analysis Imported successfully
2024-11-28 17:04:00,944:INFO:Starting cross validation
2024-11-28 17:04:00,946:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:04:01,116:INFO:Calculating mean and std
2024-11-28 17:04:01,117:INFO:Creating metrics dataframe
2024-11-28 17:04:01,119:INFO:Uploading results into container
2024-11-28 17:04:01,120:INFO:Uploading model into container now
2024-11-28 17:04:01,120:INFO:_master_model_container: 11
2024-11-28 17:04:01,120:INFO:_display_container: 2
2024-11-28 17:04:01,120:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-11-28 17:04:01,120:INFO:create_model() successfully completed......................................
2024-11-28 17:04:01,185:INFO:SubProcess create_model() end ==================================
2024-11-28 17:04:01,186:INFO:Creating metrics dataframe
2024-11-28 17:04:01,194:INFO:Initializing Extra Trees Classifier
2024-11-28 17:04:01,194:INFO:Total runtime is 0.08067888816197713 minutes
2024-11-28 17:04:01,197:INFO:SubProcess create_model() called ==================================
2024-11-28 17:04:01,197:INFO:Initializing create_model()
2024-11-28 17:04:01,197:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA38C700>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8BC45BB20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:04:01,197:INFO:Checking exceptions
2024-11-28 17:04:01,197:INFO:Importing libraries
2024-11-28 17:04:01,197:INFO:Copying training dataset
2024-11-28 17:04:01,201:INFO:Defining folds
2024-11-28 17:04:01,201:INFO:Declaring metric variables
2024-11-28 17:04:01,204:INFO:Importing untrained model
2024-11-28 17:04:01,207:INFO:Extra Trees Classifier Imported successfully
2024-11-28 17:04:01,213:INFO:Starting cross validation
2024-11-28 17:04:01,215:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:04:01,701:INFO:Calculating mean and std
2024-11-28 17:04:01,702:INFO:Creating metrics dataframe
2024-11-28 17:04:01,704:INFO:Uploading results into container
2024-11-28 17:04:01,705:INFO:Uploading model into container now
2024-11-28 17:04:01,705:INFO:_master_model_container: 12
2024-11-28 17:04:01,705:INFO:_display_container: 2
2024-11-28 17:04:01,705:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=7045, verbose=0,
                     warm_start=False)
2024-11-28 17:04:01,706:INFO:create_model() successfully completed......................................
2024-11-28 17:04:01,771:INFO:SubProcess create_model() end ==================================
2024-11-28 17:04:01,771:INFO:Creating metrics dataframe
2024-11-28 17:04:01,778:INFO:Initializing Extreme Gradient Boosting
2024-11-28 17:04:01,779:INFO:Total runtime is 0.090418541431427 minutes
2024-11-28 17:04:01,781:INFO:SubProcess create_model() called ==================================
2024-11-28 17:04:01,782:INFO:Initializing create_model()
2024-11-28 17:04:01,782:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA38C700>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8BC45BB20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:04:01,782:INFO:Checking exceptions
2024-11-28 17:04:01,782:INFO:Importing libraries
2024-11-28 17:04:01,782:INFO:Copying training dataset
2024-11-28 17:04:01,786:INFO:Defining folds
2024-11-28 17:04:01,786:INFO:Declaring metric variables
2024-11-28 17:04:01,789:INFO:Importing untrained model
2024-11-28 17:04:01,792:INFO:Extreme Gradient Boosting Imported successfully
2024-11-28 17:04:01,798:INFO:Starting cross validation
2024-11-28 17:04:01,799:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:04:02,058:INFO:Calculating mean and std
2024-11-28 17:04:02,059:INFO:Creating metrics dataframe
2024-11-28 17:04:02,061:INFO:Uploading results into container
2024-11-28 17:04:02,061:INFO:Uploading model into container now
2024-11-28 17:04:02,062:INFO:_master_model_container: 13
2024-11-28 17:04:02,062:INFO:_display_container: 2
2024-11-28 17:04:02,062:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-11-28 17:04:02,062:INFO:create_model() successfully completed......................................
2024-11-28 17:04:02,128:INFO:SubProcess create_model() end ==================================
2024-11-28 17:04:02,128:INFO:Creating metrics dataframe
2024-11-28 17:04:02,137:INFO:Initializing Light Gradient Boosting Machine
2024-11-28 17:04:02,137:INFO:Total runtime is 0.09640203714370726 minutes
2024-11-28 17:04:02,140:INFO:SubProcess create_model() called ==================================
2024-11-28 17:04:02,140:INFO:Initializing create_model()
2024-11-28 17:04:02,140:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA38C700>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8BC45BB20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:04:02,140:INFO:Checking exceptions
2024-11-28 17:04:02,140:INFO:Importing libraries
2024-11-28 17:04:02,140:INFO:Copying training dataset
2024-11-28 17:04:02,145:INFO:Defining folds
2024-11-28 17:04:02,145:INFO:Declaring metric variables
2024-11-28 17:04:02,147:INFO:Importing untrained model
2024-11-28 17:04:02,150:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-28 17:04:02,158:INFO:Starting cross validation
2024-11-28 17:04:02,160:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:04:02,787:INFO:Calculating mean and std
2024-11-28 17:04:02,788:INFO:Creating metrics dataframe
2024-11-28 17:04:02,791:INFO:Uploading results into container
2024-11-28 17:04:02,791:INFO:Uploading model into container now
2024-11-28 17:04:02,791:INFO:_master_model_container: 14
2024-11-28 17:04:02,791:INFO:_display_container: 2
2024-11-28 17:04:02,792:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7045, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-11-28 17:04:02,792:INFO:create_model() successfully completed......................................
2024-11-28 17:04:02,856:INFO:SubProcess create_model() end ==================================
2024-11-28 17:04:02,856:INFO:Creating metrics dataframe
2024-11-28 17:04:02,864:INFO:Initializing CatBoost Classifier
2024-11-28 17:04:02,864:INFO:Total runtime is 0.10851961374282836 minutes
2024-11-28 17:04:02,868:INFO:SubProcess create_model() called ==================================
2024-11-28 17:04:02,868:INFO:Initializing create_model()
2024-11-28 17:04:02,868:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA38C700>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8BC45BB20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:04:02,868:INFO:Checking exceptions
2024-11-28 17:04:02,868:INFO:Importing libraries
2024-11-28 17:04:02,869:INFO:Copying training dataset
2024-11-28 17:04:02,872:INFO:Defining folds
2024-11-28 17:04:02,872:INFO:Declaring metric variables
2024-11-28 17:04:02,875:INFO:Importing untrained model
2024-11-28 17:04:02,878:INFO:CatBoost Classifier Imported successfully
2024-11-28 17:04:02,886:INFO:Starting cross validation
2024-11-28 17:04:02,887:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:04:07,766:INFO:Calculating mean and std
2024-11-28 17:04:07,771:INFO:Creating metrics dataframe
2024-11-28 17:04:07,781:INFO:Uploading results into container
2024-11-28 17:04:07,783:INFO:Uploading model into container now
2024-11-28 17:04:07,786:INFO:_master_model_container: 15
2024-11-28 17:04:07,787:INFO:_display_container: 2
2024-11-28 17:04:07,787:INFO:<catboost.core.CatBoostClassifier object at 0x000002D8DA5A5F90>
2024-11-28 17:04:07,787:INFO:create_model() successfully completed......................................
2024-11-28 17:04:07,938:INFO:SubProcess create_model() end ==================================
2024-11-28 17:04:07,938:INFO:Creating metrics dataframe
2024-11-28 17:04:07,947:INFO:Initializing Dummy Classifier
2024-11-28 17:04:07,947:INFO:Total runtime is 0.19322977860768636 minutes
2024-11-28 17:04:07,951:INFO:SubProcess create_model() called ==================================
2024-11-28 17:04:07,952:INFO:Initializing create_model()
2024-11-28 17:04:07,952:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA38C700>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8BC45BB20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:04:07,952:INFO:Checking exceptions
2024-11-28 17:04:07,952:INFO:Importing libraries
2024-11-28 17:04:07,952:INFO:Copying training dataset
2024-11-28 17:04:07,956:INFO:Defining folds
2024-11-28 17:04:07,956:INFO:Declaring metric variables
2024-11-28 17:04:07,959:INFO:Importing untrained model
2024-11-28 17:04:07,963:INFO:Dummy Classifier Imported successfully
2024-11-28 17:04:07,970:INFO:Starting cross validation
2024-11-28 17:04:07,972:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:04:08,050:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:04:08,052:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:04:08,053:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:04:08,054:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:04:08,056:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:04:08,064:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:04:08,118:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:04:08,119:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:04:08,120:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:04:08,121:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:04:08,138:INFO:Calculating mean and std
2024-11-28 17:04:08,141:INFO:Creating metrics dataframe
2024-11-28 17:04:08,148:INFO:Uploading results into container
2024-11-28 17:04:08,148:INFO:Uploading model into container now
2024-11-28 17:04:08,149:INFO:_master_model_container: 16
2024-11-28 17:04:08,150:INFO:_display_container: 2
2024-11-28 17:04:08,150:INFO:DummyClassifier(constant=None, random_state=7045, strategy='prior')
2024-11-28 17:04:08,151:INFO:create_model() successfully completed......................................
2024-11-28 17:04:08,263:INFO:SubProcess create_model() end ==================================
2024-11-28 17:04:08,263:INFO:Creating metrics dataframe
2024-11-28 17:04:08,273:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-11-28 17:04:08,279:INFO:Initializing create_model()
2024-11-28 17:04:08,280:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA38C700>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=7045, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:04:08,280:INFO:Checking exceptions
2024-11-28 17:04:08,281:INFO:Importing libraries
2024-11-28 17:04:08,281:INFO:Copying training dataset
2024-11-28 17:04:08,286:INFO:Defining folds
2024-11-28 17:04:08,286:INFO:Declaring metric variables
2024-11-28 17:04:08,286:INFO:Importing untrained model
2024-11-28 17:04:08,286:INFO:Declaring custom model
2024-11-28 17:04:08,287:INFO:Random Forest Classifier Imported successfully
2024-11-28 17:04:08,288:INFO:Cross validation set to False
2024-11-28 17:04:08,288:INFO:Fitting Model
2024-11-28 17:04:08,449:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=7045, verbose=0,
                       warm_start=False)
2024-11-28 17:04:08,449:INFO:create_model() successfully completed......................................
2024-11-28 17:04:08,518:INFO:Initializing create_model()
2024-11-28 17:04:08,519:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA38C700>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=7045, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:04:08,519:INFO:Checking exceptions
2024-11-28 17:04:08,520:INFO:Importing libraries
2024-11-28 17:04:08,520:INFO:Copying training dataset
2024-11-28 17:04:08,526:INFO:Defining folds
2024-11-28 17:04:08,526:INFO:Declaring metric variables
2024-11-28 17:04:08,526:INFO:Importing untrained model
2024-11-28 17:04:08,526:INFO:Declaring custom model
2024-11-28 17:04:08,527:INFO:Gradient Boosting Classifier Imported successfully
2024-11-28 17:04:08,527:INFO:Cross validation set to False
2024-11-28 17:04:08,527:INFO:Fitting Model
2024-11-28 17:04:08,682:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=7045, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-11-28 17:04:08,683:INFO:create_model() successfully completed......................................
2024-11-28 17:04:08,752:INFO:Initializing create_model()
2024-11-28 17:04:08,753:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA38C700>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7045, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:04:08,753:INFO:Checking exceptions
2024-11-28 17:04:08,756:INFO:Importing libraries
2024-11-28 17:04:08,756:INFO:Copying training dataset
2024-11-28 17:04:08,759:INFO:Defining folds
2024-11-28 17:04:08,759:INFO:Declaring metric variables
2024-11-28 17:04:08,759:INFO:Importing untrained model
2024-11-28 17:04:08,759:INFO:Declaring custom model
2024-11-28 17:04:08,760:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-28 17:04:08,761:INFO:Cross validation set to False
2024-11-28 17:04:08,761:INFO:Fitting Model
2024-11-28 17:04:08,795:INFO:[LightGBM] [Info] Number of positive: 239, number of negative: 384
2024-11-28 17:04:08,795:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000099 seconds.
2024-11-28 17:04:08,795:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-11-28 17:04:08,796:INFO:[LightGBM] [Info] Total Bins 410
2024-11-28 17:04:08,796:INFO:[LightGBM] [Info] Number of data points in the train set: 623, number of used features: 11
2024-11-28 17:04:08,796:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383628 -> initscore=-0.474179
2024-11-28 17:04:08,796:INFO:[LightGBM] [Info] Start training from score -0.474179
2024-11-28 17:04:08,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:04:08,831:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7045, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-11-28 17:04:08,831:INFO:create_model() successfully completed......................................
2024-11-28 17:04:08,902:INFO:Initializing create_model()
2024-11-28 17:04:08,902:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA38C700>, estimator=<catboost.core.CatBoostClassifier object at 0x000002D8DA5A5F90>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:04:08,903:INFO:Checking exceptions
2024-11-28 17:04:08,904:INFO:Importing libraries
2024-11-28 17:04:08,904:INFO:Copying training dataset
2024-11-28 17:04:08,908:INFO:Defining folds
2024-11-28 17:04:08,908:INFO:Declaring metric variables
2024-11-28 17:04:08,908:INFO:Importing untrained model
2024-11-28 17:04:08,908:INFO:Declaring custom model
2024-11-28 17:04:08,908:INFO:CatBoost Classifier Imported successfully
2024-11-28 17:04:08,909:INFO:Cross validation set to False
2024-11-28 17:04:08,909:INFO:Fitting Model
2024-11-28 17:04:10,241:INFO:<catboost.core.CatBoostClassifier object at 0x000002D8D9F080D0>
2024-11-28 17:04:10,241:INFO:create_model() successfully completed......................................
2024-11-28 17:04:10,311:INFO:Initializing create_model()
2024-11-28 17:04:10,311:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA38C700>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:04:10,311:INFO:Checking exceptions
2024-11-28 17:04:10,313:INFO:Importing libraries
2024-11-28 17:04:10,313:INFO:Copying training dataset
2024-11-28 17:04:10,317:INFO:Defining folds
2024-11-28 17:04:10,317:INFO:Declaring metric variables
2024-11-28 17:04:10,317:INFO:Importing untrained model
2024-11-28 17:04:10,317:INFO:Declaring custom model
2024-11-28 17:04:10,319:INFO:Extreme Gradient Boosting Imported successfully
2024-11-28 17:04:10,320:INFO:Cross validation set to False
2024-11-28 17:04:10,320:INFO:Fitting Model
2024-11-28 17:04:10,388:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-11-28 17:04:10,388:INFO:create_model() successfully completed......................................
2024-11-28 17:04:10,457:INFO:Initializing create_model()
2024-11-28 17:04:10,457:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA38C700>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=7045, verbose=0,
                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:04:10,457:INFO:Checking exceptions
2024-11-28 17:04:10,459:INFO:Importing libraries
2024-11-28 17:04:10,459:INFO:Copying training dataset
2024-11-28 17:04:10,462:INFO:Defining folds
2024-11-28 17:04:10,462:INFO:Declaring metric variables
2024-11-28 17:04:10,462:INFO:Importing untrained model
2024-11-28 17:04:10,462:INFO:Declaring custom model
2024-11-28 17:04:10,463:INFO:Extra Trees Classifier Imported successfully
2024-11-28 17:04:10,464:INFO:Cross validation set to False
2024-11-28 17:04:10,464:INFO:Fitting Model
2024-11-28 17:04:10,615:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=7045, verbose=0,
                     warm_start=False)
2024-11-28 17:04:10,615:INFO:create_model() successfully completed......................................
2024-11-28 17:04:10,686:INFO:Initializing create_model()
2024-11-28 17:04:10,686:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA38C700>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7045, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:04:10,686:INFO:Checking exceptions
2024-11-28 17:04:10,688:INFO:Importing libraries
2024-11-28 17:04:10,688:INFO:Copying training dataset
2024-11-28 17:04:10,692:INFO:Defining folds
2024-11-28 17:04:10,692:INFO:Declaring metric variables
2024-11-28 17:04:10,692:INFO:Importing untrained model
2024-11-28 17:04:10,692:INFO:Declaring custom model
2024-11-28 17:04:10,693:INFO:Logistic Regression Imported successfully
2024-11-28 17:04:10,694:INFO:Cross validation set to False
2024-11-28 17:04:10,694:INFO:Fitting Model
2024-11-28 17:04:10,836:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:04:10,837:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7045, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-11-28 17:04:10,837:INFO:create_model() successfully completed......................................
2024-11-28 17:04:10,906:INFO:Initializing create_model()
2024-11-28 17:04:10,906:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA38C700>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=7045, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:04:10,906:INFO:Checking exceptions
2024-11-28 17:04:10,909:INFO:Importing libraries
2024-11-28 17:04:10,909:INFO:Copying training dataset
2024-11-28 17:04:10,912:INFO:Defining folds
2024-11-28 17:04:10,912:INFO:Declaring metric variables
2024-11-28 17:04:10,912:INFO:Importing untrained model
2024-11-28 17:04:10,913:INFO:Declaring custom model
2024-11-28 17:04:10,913:INFO:Ridge Classifier Imported successfully
2024-11-28 17:04:10,914:INFO:Cross validation set to False
2024-11-28 17:04:10,914:INFO:Fitting Model
2024-11-28 17:04:10,946:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=7045, solver='auto',
                tol=0.0001)
2024-11-28 17:04:10,946:INFO:create_model() successfully completed......................................
2024-11-28 17:04:11,015:INFO:Initializing create_model()
2024-11-28 17:04:11,015:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA38C700>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:04:11,016:INFO:Checking exceptions
2024-11-28 17:04:11,018:INFO:Importing libraries
2024-11-28 17:04:11,018:INFO:Copying training dataset
2024-11-28 17:04:11,022:INFO:Defining folds
2024-11-28 17:04:11,022:INFO:Declaring metric variables
2024-11-28 17:04:11,022:INFO:Importing untrained model
2024-11-28 17:04:11,022:INFO:Declaring custom model
2024-11-28 17:04:11,023:INFO:Linear Discriminant Analysis Imported successfully
2024-11-28 17:04:11,023:INFO:Cross validation set to False
2024-11-28 17:04:11,024:INFO:Fitting Model
2024-11-28 17:04:11,055:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-11-28 17:04:11,055:INFO:create_model() successfully completed......................................
2024-11-28 17:04:11,124:INFO:Initializing create_model()
2024-11-28 17:04:11,125:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA38C700>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=7045), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:04:11,125:INFO:Checking exceptions
2024-11-28 17:04:11,127:INFO:Importing libraries
2024-11-28 17:04:11,127:INFO:Copying training dataset
2024-11-28 17:04:11,131:INFO:Defining folds
2024-11-28 17:04:11,131:INFO:Declaring metric variables
2024-11-28 17:04:11,131:INFO:Importing untrained model
2024-11-28 17:04:11,131:INFO:Declaring custom model
2024-11-28 17:04:11,131:INFO:Ada Boost Classifier Imported successfully
2024-11-28 17:04:11,132:INFO:Cross validation set to False
2024-11-28 17:04:11,132:INFO:Fitting Model
2024-11-28 17:04:11,163:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:04:11,233:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=7045)
2024-11-28 17:04:11,233:INFO:create_model() successfully completed......................................
2024-11-28 17:04:11,303:INFO:Initializing create_model()
2024-11-28 17:04:11,303:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA38C700>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:04:11,303:INFO:Checking exceptions
2024-11-28 17:04:11,305:INFO:Importing libraries
2024-11-28 17:04:11,305:INFO:Copying training dataset
2024-11-28 17:04:11,308:INFO:Defining folds
2024-11-28 17:04:11,308:INFO:Declaring metric variables
2024-11-28 17:04:11,309:INFO:Importing untrained model
2024-11-28 17:04:11,309:INFO:Declaring custom model
2024-11-28 17:04:11,309:INFO:Naive Bayes Imported successfully
2024-11-28 17:04:11,310:INFO:Cross validation set to False
2024-11-28 17:04:11,310:INFO:Fitting Model
2024-11-28 17:04:11,341:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-11-28 17:04:11,341:INFO:create_model() successfully completed......................................
2024-11-28 17:04:11,411:INFO:Initializing create_model()
2024-11-28 17:04:11,411:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA38C700>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7045, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:04:11,411:INFO:Checking exceptions
2024-11-28 17:04:11,413:INFO:Importing libraries
2024-11-28 17:04:11,413:INFO:Copying training dataset
2024-11-28 17:04:11,416:INFO:Defining folds
2024-11-28 17:04:11,416:INFO:Declaring metric variables
2024-11-28 17:04:11,416:INFO:Importing untrained model
2024-11-28 17:04:11,416:INFO:Declaring custom model
2024-11-28 17:04:11,417:INFO:Decision Tree Classifier Imported successfully
2024-11-28 17:04:11,418:INFO:Cross validation set to False
2024-11-28 17:04:11,418:INFO:Fitting Model
2024-11-28 17:04:11,453:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7045, splitter='best')
2024-11-28 17:04:11,454:INFO:create_model() successfully completed......................................
2024-11-28 17:04:11,555:INFO:Initializing create_model()
2024-11-28 17:04:11,555:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA38C700>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:04:11,555:INFO:Checking exceptions
2024-11-28 17:04:11,556:INFO:Importing libraries
2024-11-28 17:04:11,556:INFO:Copying training dataset
2024-11-28 17:04:11,560:INFO:Defining folds
2024-11-28 17:04:11,560:INFO:Declaring metric variables
2024-11-28 17:04:11,560:INFO:Importing untrained model
2024-11-28 17:04:11,560:INFO:Declaring custom model
2024-11-28 17:04:11,561:INFO:Quadratic Discriminant Analysis Imported successfully
2024-11-28 17:04:11,562:INFO:Cross validation set to False
2024-11-28 17:04:11,562:INFO:Fitting Model
2024-11-28 17:04:11,593:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:04:11,593:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-11-28 17:04:11,594:INFO:create_model() successfully completed......................................
2024-11-28 17:04:11,663:INFO:Initializing create_model()
2024-11-28 17:04:11,663:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA38C700>, estimator=DummyClassifier(constant=None, random_state=7045, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:04:11,663:INFO:Checking exceptions
2024-11-28 17:04:11,665:INFO:Importing libraries
2024-11-28 17:04:11,666:INFO:Copying training dataset
2024-11-28 17:04:11,669:INFO:Defining folds
2024-11-28 17:04:11,670:INFO:Declaring metric variables
2024-11-28 17:04:11,670:INFO:Importing untrained model
2024-11-28 17:04:11,670:INFO:Declaring custom model
2024-11-28 17:04:11,670:INFO:Dummy Classifier Imported successfully
2024-11-28 17:04:11,671:INFO:Cross validation set to False
2024-11-28 17:04:11,671:INFO:Fitting Model
2024-11-28 17:04:11,702:INFO:DummyClassifier(constant=None, random_state=7045, strategy='prior')
2024-11-28 17:04:11,702:INFO:create_model() successfully completed......................................
2024-11-28 17:04:11,771:INFO:Initializing create_model()
2024-11-28 17:04:11,771:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA38C700>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:04:11,772:INFO:Checking exceptions
2024-11-28 17:04:11,774:INFO:Importing libraries
2024-11-28 17:04:11,774:INFO:Copying training dataset
2024-11-28 17:04:11,777:INFO:Defining folds
2024-11-28 17:04:11,777:INFO:Declaring metric variables
2024-11-28 17:04:11,777:INFO:Importing untrained model
2024-11-28 17:04:11,777:INFO:Declaring custom model
2024-11-28 17:04:11,778:INFO:K Neighbors Classifier Imported successfully
2024-11-28 17:04:11,779:INFO:Cross validation set to False
2024-11-28 17:04:11,779:INFO:Fitting Model
2024-11-28 17:04:11,812:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-11-28 17:04:11,812:INFO:create_model() successfully completed......................................
2024-11-28 17:04:11,882:INFO:Initializing create_model()
2024-11-28 17:04:11,882:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA38C700>, estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=7045, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:04:11,882:INFO:Checking exceptions
2024-11-28 17:04:11,885:INFO:Importing libraries
2024-11-28 17:04:11,885:INFO:Copying training dataset
2024-11-28 17:04:11,889:INFO:Defining folds
2024-11-28 17:04:11,889:INFO:Declaring metric variables
2024-11-28 17:04:11,889:INFO:Importing untrained model
2024-11-28 17:04:11,889:INFO:Declaring custom model
2024-11-28 17:04:11,889:INFO:SVM - Linear Kernel Imported successfully
2024-11-28 17:04:11,890:INFO:Cross validation set to False
2024-11-28 17:04:11,890:INFO:Fitting Model
2024-11-28 17:04:11,925:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=7045, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-11-28 17:04:11,925:INFO:create_model() successfully completed......................................
2024-11-28 17:04:12,007:INFO:_master_model_container: 16
2024-11-28 17:04:12,007:INFO:_display_container: 2
2024-11-28 17:04:12,010:INFO:[RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=7045, verbose=0,
                       warm_start=False), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=7045, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7045, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), <catboost.core.CatBoostClassifier object at 0x000002D8D9F080D0>, XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=7045, verbose=0,
                     warm_start=False), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7045, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=7045, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=7045), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7045, splitter='best'), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), DummyClassifier(constant=None, random_state=7045, strategy='prior'), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=7045, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)]
2024-11-28 17:04:12,010:INFO:compare_models() successfully completed......................................
2024-11-28 17:05:24,170:INFO:PyCaret ClassificationExperiment
2024-11-28 17:05:24,170:INFO:Logging name: clf-default-name
2024-11-28 17:05:24,170:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-11-28 17:05:24,170:INFO:version 3.3.2
2024-11-28 17:05:24,170:INFO:Initializing setup()
2024-11-28 17:05:24,170:INFO:self.USI: 8b2c
2024-11-28 17:05:24,170:INFO:self._variable_keys: {'exp_name_log', 'y_test', 'idx', 'y_train', 'log_plots_param', 'memory', 'pipeline', 'X', 'gpu_param', 'fold_generator', 'logging_param', 'n_jobs_param', 'exp_id', 'is_multiclass', 'fix_imbalance', '_available_plots', 'html_param', 'gpu_n_jobs_param', 'X_test', 'X_train', 'y', 'data', 'fold_shuffle_param', 'seed', 'fold_groups_param', '_ml_usecase', 'target_param', 'USI'}
2024-11-28 17:05:24,170:INFO:Checking environment
2024-11-28 17:05:24,170:INFO:python_version: 3.10.11
2024-11-28 17:05:24,171:INFO:python_build: ('tags/v3.10.11:7d4cc5a', 'Apr  5 2023 00:38:17')
2024-11-28 17:05:24,171:INFO:machine: AMD64
2024-11-28 17:05:24,171:INFO:platform: Windows-10-10.0.19045-SP0
2024-11-28 17:05:24,174:INFO:Memory: svmem(total=34216488960, available=20859854848, percent=39.0, used=13356634112, free=20859854848)
2024-11-28 17:05:24,175:INFO:Physical Core: 6
2024-11-28 17:05:24,175:INFO:Logical Core: 6
2024-11-28 17:05:24,175:INFO:Checking libraries
2024-11-28 17:05:24,175:INFO:System:
2024-11-28 17:05:24,175:INFO:    python: 3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]
2024-11-28 17:05:24,175:INFO:executable: c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\Scripts\python.exe
2024-11-28 17:05:24,175:INFO:   machine: Windows-10-10.0.19045-SP0
2024-11-28 17:05:24,175:INFO:PyCaret required dependencies:
2024-11-28 17:05:24,175:INFO:                 pip: 23.0.1
2024-11-28 17:05:24,175:INFO:          setuptools: 65.5.0
2024-11-28 17:05:24,175:INFO:             pycaret: 3.3.2
2024-11-28 17:05:24,175:INFO:             IPython: 8.29.0
2024-11-28 17:05:24,175:INFO:          ipywidgets: 8.1.5
2024-11-28 17:05:24,175:INFO:                tqdm: 4.67.1
2024-11-28 17:05:24,175:INFO:               numpy: 1.26.4
2024-11-28 17:05:24,175:INFO:              pandas: 2.1.4
2024-11-28 17:05:24,175:INFO:              jinja2: 3.1.4
2024-11-28 17:05:24,175:INFO:               scipy: 1.11.4
2024-11-28 17:05:24,175:INFO:              joblib: 1.3.2
2024-11-28 17:05:24,175:INFO:             sklearn: 1.4.2
2024-11-28 17:05:24,175:INFO:                pyod: 2.0.2
2024-11-28 17:05:24,175:INFO:            imblearn: 0.12.4
2024-11-28 17:05:24,175:INFO:   category_encoders: 2.6.4
2024-11-28 17:05:24,175:INFO:            lightgbm: 4.5.0
2024-11-28 17:05:24,176:INFO:               numba: 0.60.0
2024-11-28 17:05:24,176:INFO:            requests: 2.32.3
2024-11-28 17:05:24,176:INFO:          matplotlib: 3.7.5
2024-11-28 17:05:24,176:INFO:          scikitplot: 0.3.7
2024-11-28 17:05:24,176:INFO:         yellowbrick: 1.5
2024-11-28 17:05:24,176:INFO:              plotly: 5.24.1
2024-11-28 17:05:24,176:INFO:    plotly-resampler: Not installed
2024-11-28 17:05:24,176:INFO:             kaleido: 0.2.1
2024-11-28 17:05:24,176:INFO:           schemdraw: 0.15
2024-11-28 17:05:24,176:INFO:         statsmodels: 0.14.4
2024-11-28 17:05:24,176:INFO:              sktime: 0.26.0
2024-11-28 17:05:24,176:INFO:               tbats: 1.1.3
2024-11-28 17:05:24,176:INFO:            pmdarima: 2.0.4
2024-11-28 17:05:24,176:INFO:              psutil: 6.1.0
2024-11-28 17:05:24,176:INFO:          markupsafe: 3.0.2
2024-11-28 17:05:24,176:INFO:             pickle5: Not installed
2024-11-28 17:05:24,176:INFO:         cloudpickle: 3.1.0
2024-11-28 17:05:24,176:INFO:         deprecation: 2.1.0
2024-11-28 17:05:24,176:INFO:              xxhash: 3.5.0
2024-11-28 17:05:24,176:INFO:           wurlitzer: Not installed
2024-11-28 17:05:24,176:INFO:PyCaret optional dependencies:
2024-11-28 17:05:24,176:INFO:                shap: Not installed
2024-11-28 17:05:24,176:INFO:           interpret: Not installed
2024-11-28 17:05:24,176:INFO:                umap: Not installed
2024-11-28 17:05:24,176:INFO:     ydata_profiling: Not installed
2024-11-28 17:05:24,176:INFO:  explainerdashboard: Not installed
2024-11-28 17:05:24,176:INFO:             autoviz: Not installed
2024-11-28 17:05:24,176:INFO:           fairlearn: Not installed
2024-11-28 17:05:24,177:INFO:          deepchecks: Not installed
2024-11-28 17:05:24,177:INFO:             xgboost: 2.1.3
2024-11-28 17:05:24,177:INFO:            catboost: 1.2.7
2024-11-28 17:05:24,177:INFO:              kmodes: Not installed
2024-11-28 17:05:24,177:INFO:             mlxtend: 0.23.3
2024-11-28 17:05:24,177:INFO:       statsforecast: Not installed
2024-11-28 17:05:24,177:INFO:        tune_sklearn: Not installed
2024-11-28 17:05:24,177:INFO:                 ray: Not installed
2024-11-28 17:05:24,177:INFO:            hyperopt: Not installed
2024-11-28 17:05:24,177:INFO:              optuna: Not installed
2024-11-28 17:05:24,177:INFO:               skopt: Not installed
2024-11-28 17:05:24,177:INFO:              mlflow: Not installed
2024-11-28 17:05:24,177:INFO:              gradio: Not installed
2024-11-28 17:05:24,177:INFO:             fastapi: Not installed
2024-11-28 17:05:24,177:INFO:             uvicorn: Not installed
2024-11-28 17:05:24,177:INFO:              m2cgen: Not installed
2024-11-28 17:05:24,177:INFO:           evidently: Not installed
2024-11-28 17:05:24,177:INFO:               fugue: Not installed
2024-11-28 17:05:24,177:INFO:           streamlit: 1.39.0
2024-11-28 17:05:24,177:INFO:             prophet: Not installed
2024-11-28 17:05:24,177:INFO:None
2024-11-28 17:05:24,177:INFO:Set up data.
2024-11-28 17:05:24,181:INFO:Set up folding strategy.
2024-11-28 17:05:24,181:INFO:Set up train/test split.
2024-11-28 17:05:24,184:INFO:Set up index.
2024-11-28 17:05:24,185:INFO:Assigning column types.
2024-11-28 17:05:24,188:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-28 17:05:24,225:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-28 17:05:24,226:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-28 17:05:24,249:INFO:Soft dependency imported: xgboost: 2.1.3
2024-11-28 17:05:24,252:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-28 17:05:24,288:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-28 17:05:24,289:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-28 17:05:24,311:INFO:Soft dependency imported: xgboost: 2.1.3
2024-11-28 17:05:24,313:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-28 17:05:24,313:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-28 17:05:24,350:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-28 17:05:24,375:INFO:Soft dependency imported: xgboost: 2.1.3
2024-11-28 17:05:24,378:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-28 17:05:24,421:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-28 17:05:24,446:INFO:Soft dependency imported: xgboost: 2.1.3
2024-11-28 17:05:24,448:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-28 17:05:24,449:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-11-28 17:05:24,516:INFO:Soft dependency imported: xgboost: 2.1.3
2024-11-28 17:05:24,518:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-28 17:05:24,602:INFO:Soft dependency imported: xgboost: 2.1.3
2024-11-28 17:05:24,605:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-28 17:05:24,606:INFO:Preparing preprocessing pipeline...
2024-11-28 17:05:24,607:INFO:Set up simple imputation.
2024-11-28 17:05:24,609:INFO:Set up encoding of ordinal features.
2024-11-28 17:05:24,610:INFO:Set up encoding of categorical features.
2024-11-28 17:05:24,662:INFO:Finished creating preprocessing pipeline.
2024-11-28 17:05:24,676:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\tsai\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare',
                                             'FamilySize'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('...
                                                               mapping=[{'col': 'Sex',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['Embarked'],
                                    transformer=OneHotEncoder(cols=['Embarked'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-11-28 17:05:24,676:INFO:Creating final display dataframe.
2024-11-28 17:05:24,831:INFO:Setup _display_container:                     Description             Value
0                    Session id              1313
1                        Target          Survived
2                   Target type            Binary
3           Original data shape         (891, 10)
4        Transformed data shape         (891, 12)
5   Transformed train set shape         (623, 12)
6    Transformed test set shape         (268, 12)
7              Numeric features                 7
8          Categorical features                 2
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              8b2c
2024-11-28 17:05:24,897:INFO:Soft dependency imported: xgboost: 2.1.3
2024-11-28 17:05:24,899:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-28 17:05:24,959:INFO:Soft dependency imported: xgboost: 2.1.3
2024-11-28 17:05:24,962:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-28 17:05:24,963:INFO:setup() successfully completed in 0.79s...............
2024-11-28 17:05:24,964:INFO:Initializing compare_models()
2024-11-28 17:05:24,964:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA5A6F50>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=16, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA5A6F50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 16, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-11-28 17:05:24,964:INFO:Checking exceptions
2024-11-28 17:05:24,967:INFO:Preparing display monitor
2024-11-28 17:05:24,987:INFO:Initializing Logistic Regression
2024-11-28 17:05:24,987:INFO:Total runtime is 0.0 minutes
2024-11-28 17:05:24,991:INFO:SubProcess create_model() called ==================================
2024-11-28 17:05:24,992:INFO:Initializing create_model()
2024-11-28 17:05:24,992:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA5A6F50>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8D82CCDC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:05:24,992:INFO:Checking exceptions
2024-11-28 17:05:24,992:INFO:Importing libraries
2024-11-28 17:05:24,992:INFO:Copying training dataset
2024-11-28 17:05:24,998:INFO:Defining folds
2024-11-28 17:05:24,998:INFO:Declaring metric variables
2024-11-28 17:05:25,002:INFO:Importing untrained model
2024-11-28 17:05:25,006:INFO:Logistic Regression Imported successfully
2024-11-28 17:05:25,014:INFO:Starting cross validation
2024-11-28 17:05:25,016:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:05:25,221:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:05:25,226:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:05:25,228:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:05:25,230:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:05:25,230:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:05:25,247:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:05:25,398:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:05:25,404:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:05:25,407:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:05:25,408:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:05:25,440:INFO:Calculating mean and std
2024-11-28 17:05:25,440:INFO:Creating metrics dataframe
2024-11-28 17:05:25,442:INFO:Uploading results into container
2024-11-28 17:05:25,442:INFO:Uploading model into container now
2024-11-28 17:05:25,443:INFO:_master_model_container: 1
2024-11-28 17:05:25,443:INFO:_display_container: 2
2024-11-28 17:05:25,443:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1313, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-11-28 17:05:25,443:INFO:create_model() successfully completed......................................
2024-11-28 17:05:25,513:INFO:SubProcess create_model() end ==================================
2024-11-28 17:05:25,513:INFO:Creating metrics dataframe
2024-11-28 17:05:25,518:INFO:Initializing K Neighbors Classifier
2024-11-28 17:05:25,519:INFO:Total runtime is 0.008859634399414062 minutes
2024-11-28 17:05:25,522:INFO:SubProcess create_model() called ==================================
2024-11-28 17:05:25,522:INFO:Initializing create_model()
2024-11-28 17:05:25,522:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA5A6F50>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8D82CCDC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:05:25,522:INFO:Checking exceptions
2024-11-28 17:05:25,522:INFO:Importing libraries
2024-11-28 17:05:25,523:INFO:Copying training dataset
2024-11-28 17:05:25,526:INFO:Defining folds
2024-11-28 17:05:25,526:INFO:Declaring metric variables
2024-11-28 17:05:25,529:INFO:Importing untrained model
2024-11-28 17:05:25,531:INFO:K Neighbors Classifier Imported successfully
2024-11-28 17:05:25,539:INFO:Starting cross validation
2024-11-28 17:05:25,540:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:05:25,877:INFO:Calculating mean and std
2024-11-28 17:05:25,878:INFO:Creating metrics dataframe
2024-11-28 17:05:25,879:INFO:Uploading results into container
2024-11-28 17:05:25,880:INFO:Uploading model into container now
2024-11-28 17:05:25,880:INFO:_master_model_container: 2
2024-11-28 17:05:25,880:INFO:_display_container: 2
2024-11-28 17:05:25,880:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-11-28 17:05:25,881:INFO:create_model() successfully completed......................................
2024-11-28 17:05:25,952:INFO:SubProcess create_model() end ==================================
2024-11-28 17:05:25,953:INFO:Creating metrics dataframe
2024-11-28 17:05:25,960:INFO:Initializing Naive Bayes
2024-11-28 17:05:25,960:INFO:Total runtime is 0.016206832726796468 minutes
2024-11-28 17:05:25,963:INFO:SubProcess create_model() called ==================================
2024-11-28 17:05:25,964:INFO:Initializing create_model()
2024-11-28 17:05:25,964:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA5A6F50>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8D82CCDC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:05:25,964:INFO:Checking exceptions
2024-11-28 17:05:25,964:INFO:Importing libraries
2024-11-28 17:05:25,964:INFO:Copying training dataset
2024-11-28 17:05:25,970:INFO:Defining folds
2024-11-28 17:05:25,970:INFO:Declaring metric variables
2024-11-28 17:05:25,973:INFO:Importing untrained model
2024-11-28 17:05:25,977:INFO:Naive Bayes Imported successfully
2024-11-28 17:05:25,985:INFO:Starting cross validation
2024-11-28 17:05:25,988:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:05:26,156:INFO:Calculating mean and std
2024-11-28 17:05:26,158:INFO:Creating metrics dataframe
2024-11-28 17:05:26,164:INFO:Uploading results into container
2024-11-28 17:05:26,165:INFO:Uploading model into container now
2024-11-28 17:05:26,167:INFO:_master_model_container: 3
2024-11-28 17:05:26,167:INFO:_display_container: 2
2024-11-28 17:05:26,168:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-11-28 17:05:26,169:INFO:create_model() successfully completed......................................
2024-11-28 17:05:26,311:INFO:SubProcess create_model() end ==================================
2024-11-28 17:05:26,311:INFO:Creating metrics dataframe
2024-11-28 17:05:26,324:INFO:Initializing Decision Tree Classifier
2024-11-28 17:05:26,324:INFO:Total runtime is 0.022277748584747313 minutes
2024-11-28 17:05:26,329:INFO:SubProcess create_model() called ==================================
2024-11-28 17:05:26,330:INFO:Initializing create_model()
2024-11-28 17:05:26,330:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA5A6F50>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8D82CCDC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:05:26,330:INFO:Checking exceptions
2024-11-28 17:05:26,330:INFO:Importing libraries
2024-11-28 17:05:26,330:INFO:Copying training dataset
2024-11-28 17:05:26,335:INFO:Defining folds
2024-11-28 17:05:26,336:INFO:Declaring metric variables
2024-11-28 17:05:26,339:INFO:Importing untrained model
2024-11-28 17:05:26,342:INFO:Decision Tree Classifier Imported successfully
2024-11-28 17:05:26,354:INFO:Starting cross validation
2024-11-28 17:05:26,356:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:05:26,526:INFO:Calculating mean and std
2024-11-28 17:05:26,528:INFO:Creating metrics dataframe
2024-11-28 17:05:26,536:INFO:Uploading results into container
2024-11-28 17:05:26,537:INFO:Uploading model into container now
2024-11-28 17:05:26,538:INFO:_master_model_container: 4
2024-11-28 17:05:26,539:INFO:_display_container: 2
2024-11-28 17:05:26,540:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=1313, splitter='best')
2024-11-28 17:05:26,540:INFO:create_model() successfully completed......................................
2024-11-28 17:05:26,676:INFO:SubProcess create_model() end ==================================
2024-11-28 17:05:26,676:INFO:Creating metrics dataframe
2024-11-28 17:05:26,686:INFO:Initializing SVM - Linear Kernel
2024-11-28 17:05:26,686:INFO:Total runtime is 0.02831209897994995 minutes
2024-11-28 17:05:26,690:INFO:SubProcess create_model() called ==================================
2024-11-28 17:05:26,690:INFO:Initializing create_model()
2024-11-28 17:05:26,691:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA5A6F50>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8D82CCDC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:05:26,691:INFO:Checking exceptions
2024-11-28 17:05:26,691:INFO:Importing libraries
2024-11-28 17:05:26,691:INFO:Copying training dataset
2024-11-28 17:05:26,695:INFO:Defining folds
2024-11-28 17:05:26,695:INFO:Declaring metric variables
2024-11-28 17:05:26,699:INFO:Importing untrained model
2024-11-28 17:05:26,702:INFO:SVM - Linear Kernel Imported successfully
2024-11-28 17:05:26,710:INFO:Starting cross validation
2024-11-28 17:05:26,711:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:05:26,874:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:05:26,883:INFO:Calculating mean and std
2024-11-28 17:05:26,884:INFO:Creating metrics dataframe
2024-11-28 17:05:26,886:INFO:Uploading results into container
2024-11-28 17:05:26,887:INFO:Uploading model into container now
2024-11-28 17:05:26,887:INFO:_master_model_container: 5
2024-11-28 17:05:26,887:INFO:_display_container: 2
2024-11-28 17:05:26,888:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1313, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-11-28 17:05:26,888:INFO:create_model() successfully completed......................................
2024-11-28 17:05:26,953:INFO:SubProcess create_model() end ==================================
2024-11-28 17:05:26,953:INFO:Creating metrics dataframe
2024-11-28 17:05:26,959:INFO:Initializing Ridge Classifier
2024-11-28 17:05:26,959:INFO:Total runtime is 0.032851338386535645 minutes
2024-11-28 17:05:26,962:INFO:SubProcess create_model() called ==================================
2024-11-28 17:05:26,962:INFO:Initializing create_model()
2024-11-28 17:05:26,962:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA5A6F50>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8D82CCDC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:05:26,962:INFO:Checking exceptions
2024-11-28 17:05:26,962:INFO:Importing libraries
2024-11-28 17:05:26,962:INFO:Copying training dataset
2024-11-28 17:05:26,966:INFO:Defining folds
2024-11-28 17:05:26,967:INFO:Declaring metric variables
2024-11-28 17:05:26,970:INFO:Importing untrained model
2024-11-28 17:05:26,972:INFO:Ridge Classifier Imported successfully
2024-11-28 17:05:26,978:INFO:Starting cross validation
2024-11-28 17:05:26,980:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:05:27,166:INFO:Calculating mean and std
2024-11-28 17:05:27,170:INFO:Creating metrics dataframe
2024-11-28 17:05:27,178:INFO:Uploading results into container
2024-11-28 17:05:27,181:INFO:Uploading model into container now
2024-11-28 17:05:27,184:INFO:_master_model_container: 6
2024-11-28 17:05:27,185:INFO:_display_container: 2
2024-11-28 17:05:27,187:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1313, solver='auto',
                tol=0.0001)
2024-11-28 17:05:27,187:INFO:create_model() successfully completed......................................
2024-11-28 17:05:27,297:INFO:SubProcess create_model() end ==================================
2024-11-28 17:05:27,297:INFO:Creating metrics dataframe
2024-11-28 17:05:27,307:INFO:Initializing Random Forest Classifier
2024-11-28 17:05:27,307:INFO:Total runtime is 0.038660879929860434 minutes
2024-11-28 17:05:27,310:INFO:SubProcess create_model() called ==================================
2024-11-28 17:05:27,311:INFO:Initializing create_model()
2024-11-28 17:05:27,311:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA5A6F50>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8D82CCDC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:05:27,311:INFO:Checking exceptions
2024-11-28 17:05:27,311:INFO:Importing libraries
2024-11-28 17:05:27,311:INFO:Copying training dataset
2024-11-28 17:05:27,315:INFO:Defining folds
2024-11-28 17:05:27,315:INFO:Declaring metric variables
2024-11-28 17:05:27,319:INFO:Importing untrained model
2024-11-28 17:05:27,323:INFO:Random Forest Classifier Imported successfully
2024-11-28 17:05:27,329:INFO:Starting cross validation
2024-11-28 17:05:27,331:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:05:27,925:INFO:Calculating mean and std
2024-11-28 17:05:27,930:INFO:Creating metrics dataframe
2024-11-28 17:05:27,939:INFO:Uploading results into container
2024-11-28 17:05:27,941:INFO:Uploading model into container now
2024-11-28 17:05:27,943:INFO:_master_model_container: 7
2024-11-28 17:05:27,944:INFO:_display_container: 2
2024-11-28 17:05:27,946:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=1313, verbose=0,
                       warm_start=False)
2024-11-28 17:05:27,946:INFO:create_model() successfully completed......................................
2024-11-28 17:05:28,072:INFO:SubProcess create_model() end ==================================
2024-11-28 17:05:28,072:INFO:Creating metrics dataframe
2024-11-28 17:05:28,083:INFO:Initializing Quadratic Discriminant Analysis
2024-11-28 17:05:28,083:INFO:Total runtime is 0.05159848133722941 minutes
2024-11-28 17:05:28,087:INFO:SubProcess create_model() called ==================================
2024-11-28 17:05:28,088:INFO:Initializing create_model()
2024-11-28 17:05:28,088:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA5A6F50>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8D82CCDC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:05:28,088:INFO:Checking exceptions
2024-11-28 17:05:28,088:INFO:Importing libraries
2024-11-28 17:05:28,088:INFO:Copying training dataset
2024-11-28 17:05:28,093:INFO:Defining folds
2024-11-28 17:05:28,093:INFO:Declaring metric variables
2024-11-28 17:05:28,096:INFO:Importing untrained model
2024-11-28 17:05:28,101:INFO:Quadratic Discriminant Analysis Imported successfully
2024-11-28 17:05:28,107:INFO:Starting cross validation
2024-11-28 17:05:28,108:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:05:28,164:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:05:28,166:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:05:28,169:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:05:28,170:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:05:28,174:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:05:28,180:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:05:28,236:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:05:28,236:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:05:28,240:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:05:28,243:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:05:28,281:INFO:Calculating mean and std
2024-11-28 17:05:28,286:INFO:Creating metrics dataframe
2024-11-28 17:05:28,293:INFO:Uploading results into container
2024-11-28 17:05:28,295:INFO:Uploading model into container now
2024-11-28 17:05:28,296:INFO:_master_model_container: 8
2024-11-28 17:05:28,297:INFO:_display_container: 2
2024-11-28 17:05:28,298:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-11-28 17:05:28,298:INFO:create_model() successfully completed......................................
2024-11-28 17:05:28,415:INFO:SubProcess create_model() end ==================================
2024-11-28 17:05:28,415:INFO:Creating metrics dataframe
2024-11-28 17:05:28,422:INFO:Initializing Ada Boost Classifier
2024-11-28 17:05:28,422:INFO:Total runtime is 0.05723838011423747 minutes
2024-11-28 17:05:28,426:INFO:SubProcess create_model() called ==================================
2024-11-28 17:05:28,426:INFO:Initializing create_model()
2024-11-28 17:05:28,426:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA5A6F50>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8D82CCDC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:05:28,426:INFO:Checking exceptions
2024-11-28 17:05:28,426:INFO:Importing libraries
2024-11-28 17:05:28,426:INFO:Copying training dataset
2024-11-28 17:05:28,431:INFO:Defining folds
2024-11-28 17:05:28,431:INFO:Declaring metric variables
2024-11-28 17:05:28,433:INFO:Importing untrained model
2024-11-28 17:05:28,438:INFO:Ada Boost Classifier Imported successfully
2024-11-28 17:05:28,443:INFO:Starting cross validation
2024-11-28 17:05:28,445:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:05:28,501:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:05:28,502:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:05:28,502:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:05:28,504:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:05:28,505:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:05:28,510:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:05:28,671:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:05:28,673:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:05:28,678:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:05:28,694:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:05:28,869:INFO:Calculating mean and std
2024-11-28 17:05:28,870:INFO:Creating metrics dataframe
2024-11-28 17:05:28,872:INFO:Uploading results into container
2024-11-28 17:05:28,872:INFO:Uploading model into container now
2024-11-28 17:05:28,872:INFO:_master_model_container: 9
2024-11-28 17:05:28,872:INFO:_display_container: 2
2024-11-28 17:05:28,873:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=1313)
2024-11-28 17:05:28,873:INFO:create_model() successfully completed......................................
2024-11-28 17:05:28,939:INFO:SubProcess create_model() end ==================================
2024-11-28 17:05:28,939:INFO:Creating metrics dataframe
2024-11-28 17:05:28,948:INFO:Initializing Gradient Boosting Classifier
2024-11-28 17:05:28,948:INFO:Total runtime is 0.06600184837977092 minutes
2024-11-28 17:05:28,952:INFO:SubProcess create_model() called ==================================
2024-11-28 17:05:28,952:INFO:Initializing create_model()
2024-11-28 17:05:28,952:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA5A6F50>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8D82CCDC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:05:28,952:INFO:Checking exceptions
2024-11-28 17:05:28,952:INFO:Importing libraries
2024-11-28 17:05:28,952:INFO:Copying training dataset
2024-11-28 17:05:28,956:INFO:Defining folds
2024-11-28 17:05:28,956:INFO:Declaring metric variables
2024-11-28 17:05:28,959:INFO:Importing untrained model
2024-11-28 17:05:28,961:INFO:Gradient Boosting Classifier Imported successfully
2024-11-28 17:05:28,968:INFO:Starting cross validation
2024-11-28 17:05:28,969:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:05:29,489:INFO:Calculating mean and std
2024-11-28 17:05:29,490:INFO:Creating metrics dataframe
2024-11-28 17:05:29,492:INFO:Uploading results into container
2024-11-28 17:05:29,493:INFO:Uploading model into container now
2024-11-28 17:05:29,493:INFO:_master_model_container: 10
2024-11-28 17:05:29,493:INFO:_display_container: 2
2024-11-28 17:05:29,493:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1313, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-11-28 17:05:29,494:INFO:create_model() successfully completed......................................
2024-11-28 17:05:29,563:INFO:SubProcess create_model() end ==================================
2024-11-28 17:05:29,563:INFO:Creating metrics dataframe
2024-11-28 17:05:29,572:INFO:Initializing Linear Discriminant Analysis
2024-11-28 17:05:29,572:INFO:Total runtime is 0.07641597191492717 minutes
2024-11-28 17:05:29,575:INFO:SubProcess create_model() called ==================================
2024-11-28 17:05:29,576:INFO:Initializing create_model()
2024-11-28 17:05:29,576:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA5A6F50>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8D82CCDC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:05:29,576:INFO:Checking exceptions
2024-11-28 17:05:29,576:INFO:Importing libraries
2024-11-28 17:05:29,576:INFO:Copying training dataset
2024-11-28 17:05:29,580:INFO:Defining folds
2024-11-28 17:05:29,580:INFO:Declaring metric variables
2024-11-28 17:05:29,583:INFO:Importing untrained model
2024-11-28 17:05:29,586:INFO:Linear Discriminant Analysis Imported successfully
2024-11-28 17:05:29,593:INFO:Starting cross validation
2024-11-28 17:05:29,594:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:05:29,769:INFO:Calculating mean and std
2024-11-28 17:05:29,773:INFO:Creating metrics dataframe
2024-11-28 17:05:29,778:INFO:Uploading results into container
2024-11-28 17:05:29,780:INFO:Uploading model into container now
2024-11-28 17:05:29,781:INFO:_master_model_container: 11
2024-11-28 17:05:29,781:INFO:_display_container: 2
2024-11-28 17:05:29,782:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-11-28 17:05:29,782:INFO:create_model() successfully completed......................................
2024-11-28 17:05:29,921:INFO:SubProcess create_model() end ==================================
2024-11-28 17:05:29,921:INFO:Creating metrics dataframe
2024-11-28 17:05:29,943:INFO:Initializing Extra Trees Classifier
2024-11-28 17:05:29,944:INFO:Total runtime is 0.08260347843170167 minutes
2024-11-28 17:05:29,949:INFO:SubProcess create_model() called ==================================
2024-11-28 17:05:29,950:INFO:Initializing create_model()
2024-11-28 17:05:29,951:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA5A6F50>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8D82CCDC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:05:29,951:INFO:Checking exceptions
2024-11-28 17:05:29,951:INFO:Importing libraries
2024-11-28 17:05:29,951:INFO:Copying training dataset
2024-11-28 17:05:29,958:INFO:Defining folds
2024-11-28 17:05:29,958:INFO:Declaring metric variables
2024-11-28 17:05:29,963:INFO:Importing untrained model
2024-11-28 17:05:29,970:INFO:Extra Trees Classifier Imported successfully
2024-11-28 17:05:29,980:INFO:Starting cross validation
2024-11-28 17:05:29,982:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:05:30,766:INFO:Calculating mean and std
2024-11-28 17:05:30,772:INFO:Creating metrics dataframe
2024-11-28 17:05:30,780:INFO:Uploading results into container
2024-11-28 17:05:30,783:INFO:Uploading model into container now
2024-11-28 17:05:30,784:INFO:_master_model_container: 12
2024-11-28 17:05:30,785:INFO:_display_container: 2
2024-11-28 17:05:30,788:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=1313, verbose=0,
                     warm_start=False)
2024-11-28 17:05:30,789:INFO:create_model() successfully completed......................................
2024-11-28 17:05:30,900:INFO:SubProcess create_model() end ==================================
2024-11-28 17:05:30,900:INFO:Creating metrics dataframe
2024-11-28 17:05:30,909:INFO:Initializing Extreme Gradient Boosting
2024-11-28 17:05:30,909:INFO:Total runtime is 0.09869584242502849 minutes
2024-11-28 17:05:30,912:INFO:SubProcess create_model() called ==================================
2024-11-28 17:05:30,912:INFO:Initializing create_model()
2024-11-28 17:05:30,912:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA5A6F50>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8D82CCDC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:05:30,912:INFO:Checking exceptions
2024-11-28 17:05:30,912:INFO:Importing libraries
2024-11-28 17:05:30,912:INFO:Copying training dataset
2024-11-28 17:05:30,916:INFO:Defining folds
2024-11-28 17:05:30,916:INFO:Declaring metric variables
2024-11-28 17:05:30,919:INFO:Importing untrained model
2024-11-28 17:05:30,924:INFO:Extreme Gradient Boosting Imported successfully
2024-11-28 17:05:30,929:INFO:Starting cross validation
2024-11-28 17:05:30,930:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:05:31,213:INFO:Calculating mean and std
2024-11-28 17:05:31,214:INFO:Creating metrics dataframe
2024-11-28 17:05:31,216:INFO:Uploading results into container
2024-11-28 17:05:31,217:INFO:Uploading model into container now
2024-11-28 17:05:31,217:INFO:_master_model_container: 13
2024-11-28 17:05:31,217:INFO:_display_container: 2
2024-11-28 17:05:31,218:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-11-28 17:05:31,218:INFO:create_model() successfully completed......................................
2024-11-28 17:05:31,286:INFO:SubProcess create_model() end ==================================
2024-11-28 17:05:31,286:INFO:Creating metrics dataframe
2024-11-28 17:05:31,294:INFO:Initializing Light Gradient Boosting Machine
2024-11-28 17:05:31,294:INFO:Total runtime is 0.10511298576990764 minutes
2024-11-28 17:05:31,296:INFO:SubProcess create_model() called ==================================
2024-11-28 17:05:31,297:INFO:Initializing create_model()
2024-11-28 17:05:31,297:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA5A6F50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8D82CCDC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:05:31,297:INFO:Checking exceptions
2024-11-28 17:05:31,297:INFO:Importing libraries
2024-11-28 17:05:31,297:INFO:Copying training dataset
2024-11-28 17:05:31,302:INFO:Defining folds
2024-11-28 17:05:31,302:INFO:Declaring metric variables
2024-11-28 17:05:31,305:INFO:Importing untrained model
2024-11-28 17:05:31,308:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-28 17:05:31,314:INFO:Starting cross validation
2024-11-28 17:05:31,315:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:05:32,112:INFO:Calculating mean and std
2024-11-28 17:05:32,114:INFO:Creating metrics dataframe
2024-11-28 17:05:32,119:INFO:Uploading results into container
2024-11-28 17:05:32,121:INFO:Uploading model into container now
2024-11-28 17:05:32,122:INFO:_master_model_container: 14
2024-11-28 17:05:32,122:INFO:_display_container: 2
2024-11-28 17:05:32,124:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1313, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-11-28 17:05:32,124:INFO:create_model() successfully completed......................................
2024-11-28 17:05:32,210:INFO:SubProcess create_model() end ==================================
2024-11-28 17:05:32,210:INFO:Creating metrics dataframe
2024-11-28 17:05:32,221:INFO:Initializing CatBoost Classifier
2024-11-28 17:05:32,222:INFO:Total runtime is 0.12057165304819743 minutes
2024-11-28 17:05:32,226:INFO:SubProcess create_model() called ==================================
2024-11-28 17:05:32,226:INFO:Initializing create_model()
2024-11-28 17:05:32,226:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA5A6F50>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8D82CCDC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:05:32,226:INFO:Checking exceptions
2024-11-28 17:05:32,226:INFO:Importing libraries
2024-11-28 17:05:32,226:INFO:Copying training dataset
2024-11-28 17:05:32,232:INFO:Defining folds
2024-11-28 17:05:32,232:INFO:Declaring metric variables
2024-11-28 17:05:32,237:INFO:Importing untrained model
2024-11-28 17:05:32,242:INFO:CatBoost Classifier Imported successfully
2024-11-28 17:05:32,249:INFO:Starting cross validation
2024-11-28 17:05:32,255:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:05:38,259:INFO:Calculating mean and std
2024-11-28 17:05:38,260:INFO:Creating metrics dataframe
2024-11-28 17:05:38,262:INFO:Uploading results into container
2024-11-28 17:05:38,262:INFO:Uploading model into container now
2024-11-28 17:05:38,263:INFO:_master_model_container: 15
2024-11-28 17:05:38,263:INFO:_display_container: 2
2024-11-28 17:05:38,263:INFO:<catboost.core.CatBoostClassifier object at 0x000002D8D9E57A30>
2024-11-28 17:05:38,263:INFO:create_model() successfully completed......................................
2024-11-28 17:05:38,335:INFO:SubProcess create_model() end ==================================
2024-11-28 17:05:38,335:INFO:Creating metrics dataframe
2024-11-28 17:05:38,344:INFO:Initializing Dummy Classifier
2024-11-28 17:05:38,344:INFO:Total runtime is 0.2226152777671814 minutes
2024-11-28 17:05:38,347:INFO:SubProcess create_model() called ==================================
2024-11-28 17:05:38,348:INFO:Initializing create_model()
2024-11-28 17:05:38,348:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA5A6F50>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8D82CCDC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:05:38,348:INFO:Checking exceptions
2024-11-28 17:05:38,348:INFO:Importing libraries
2024-11-28 17:05:38,348:INFO:Copying training dataset
2024-11-28 17:05:38,352:INFO:Defining folds
2024-11-28 17:05:38,352:INFO:Declaring metric variables
2024-11-28 17:05:38,355:INFO:Importing untrained model
2024-11-28 17:05:38,358:INFO:Dummy Classifier Imported successfully
2024-11-28 17:05:38,364:INFO:Starting cross validation
2024-11-28 17:05:38,365:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:05:38,454:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:05:38,454:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:05:38,484:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:05:38,492:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:05:38,510:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:05:38,521:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:05:38,528:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:05:38,547:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:05:38,557:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:05:38,568:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:05:38,582:INFO:Calculating mean and std
2024-11-28 17:05:38,584:INFO:Creating metrics dataframe
2024-11-28 17:05:38,586:INFO:Uploading results into container
2024-11-28 17:05:38,587:INFO:Uploading model into container now
2024-11-28 17:05:38,587:INFO:_master_model_container: 16
2024-11-28 17:05:38,587:INFO:_display_container: 2
2024-11-28 17:05:38,587:INFO:DummyClassifier(constant=None, random_state=1313, strategy='prior')
2024-11-28 17:05:38,587:INFO:create_model() successfully completed......................................
2024-11-28 17:05:38,676:INFO:SubProcess create_model() end ==================================
2024-11-28 17:05:38,676:INFO:Creating metrics dataframe
2024-11-28 17:05:38,688:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-11-28 17:05:38,698:INFO:Initializing create_model()
2024-11-28 17:05:38,698:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA5A6F50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1313, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:05:38,698:INFO:Checking exceptions
2024-11-28 17:05:38,700:INFO:Importing libraries
2024-11-28 17:05:38,700:INFO:Copying training dataset
2024-11-28 17:05:38,704:INFO:Defining folds
2024-11-28 17:05:38,704:INFO:Declaring metric variables
2024-11-28 17:05:38,705:INFO:Importing untrained model
2024-11-28 17:05:38,705:INFO:Declaring custom model
2024-11-28 17:05:38,705:INFO:Gradient Boosting Classifier Imported successfully
2024-11-28 17:05:38,707:INFO:Cross validation set to False
2024-11-28 17:05:38,707:INFO:Fitting Model
2024-11-28 17:05:38,926:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1313, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-11-28 17:05:38,926:INFO:create_model() successfully completed......................................
2024-11-28 17:05:39,014:INFO:Initializing create_model()
2024-11-28 17:05:39,014:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA5A6F50>, estimator=<catboost.core.CatBoostClassifier object at 0x000002D8D9E57A30>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:05:39,015:INFO:Checking exceptions
2024-11-28 17:05:39,018:INFO:Importing libraries
2024-11-28 17:05:39,018:INFO:Copying training dataset
2024-11-28 17:05:39,021:INFO:Defining folds
2024-11-28 17:05:39,022:INFO:Declaring metric variables
2024-11-28 17:05:39,022:INFO:Importing untrained model
2024-11-28 17:05:39,022:INFO:Declaring custom model
2024-11-28 17:05:39,022:INFO:CatBoost Classifier Imported successfully
2024-11-28 17:05:39,023:INFO:Cross validation set to False
2024-11-28 17:05:39,023:INFO:Fitting Model
2024-11-28 17:05:40,480:INFO:<catboost.core.CatBoostClassifier object at 0x000002D8D9C27D00>
2024-11-28 17:05:40,480:INFO:create_model() successfully completed......................................
2024-11-28 17:05:40,551:INFO:Initializing create_model()
2024-11-28 17:05:40,551:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA5A6F50>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=1313, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:05:40,551:INFO:Checking exceptions
2024-11-28 17:05:40,552:INFO:Importing libraries
2024-11-28 17:05:40,552:INFO:Copying training dataset
2024-11-28 17:05:40,556:INFO:Defining folds
2024-11-28 17:05:40,556:INFO:Declaring metric variables
2024-11-28 17:05:40,556:INFO:Importing untrained model
2024-11-28 17:05:40,556:INFO:Declaring custom model
2024-11-28 17:05:40,557:INFO:Random Forest Classifier Imported successfully
2024-11-28 17:05:40,558:INFO:Cross validation set to False
2024-11-28 17:05:40,558:INFO:Fitting Model
2024-11-28 17:05:40,717:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=1313, verbose=0,
                       warm_start=False)
2024-11-28 17:05:40,717:INFO:create_model() successfully completed......................................
2024-11-28 17:05:40,790:INFO:Initializing create_model()
2024-11-28 17:05:40,790:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA5A6F50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1313, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:05:40,790:INFO:Checking exceptions
2024-11-28 17:05:40,793:INFO:Importing libraries
2024-11-28 17:05:40,793:INFO:Copying training dataset
2024-11-28 17:05:40,796:INFO:Defining folds
2024-11-28 17:05:40,796:INFO:Declaring metric variables
2024-11-28 17:05:40,797:INFO:Importing untrained model
2024-11-28 17:05:40,797:INFO:Declaring custom model
2024-11-28 17:05:40,797:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-28 17:05:40,798:INFO:Cross validation set to False
2024-11-28 17:05:40,798:INFO:Fitting Model
2024-11-28 17:05:40,837:INFO:[LightGBM] [Info] Number of positive: 239, number of negative: 384
2024-11-28 17:05:40,837:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000102 seconds.
2024-11-28 17:05:40,837:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-11-28 17:05:40,837:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-11-28 17:05:40,837:INFO:[LightGBM] [Info] Total Bins 411
2024-11-28 17:05:40,837:INFO:[LightGBM] [Info] Number of data points in the train set: 623, number of used features: 11
2024-11-28 17:05:40,837:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383628 -> initscore=-0.474179
2024-11-28 17:05:40,837:INFO:[LightGBM] [Info] Start training from score -0.474179
2024-11-28 17:05:40,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:05:40,895:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1313, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-11-28 17:05:40,895:INFO:create_model() successfully completed......................................
2024-11-28 17:05:40,974:INFO:Initializing create_model()
2024-11-28 17:05:40,975:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA5A6F50>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1313, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:05:40,975:INFO:Checking exceptions
2024-11-28 17:05:40,977:INFO:Importing libraries
2024-11-28 17:05:40,977:INFO:Copying training dataset
2024-11-28 17:05:40,980:INFO:Defining folds
2024-11-28 17:05:40,980:INFO:Declaring metric variables
2024-11-28 17:05:40,980:INFO:Importing untrained model
2024-11-28 17:05:40,981:INFO:Declaring custom model
2024-11-28 17:05:40,981:INFO:Ridge Classifier Imported successfully
2024-11-28 17:05:40,982:INFO:Cross validation set to False
2024-11-28 17:05:40,982:INFO:Fitting Model
2024-11-28 17:05:41,020:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1313, solver='auto',
                tol=0.0001)
2024-11-28 17:05:41,020:INFO:create_model() successfully completed......................................
2024-11-28 17:05:41,106:INFO:Initializing create_model()
2024-11-28 17:05:41,106:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA5A6F50>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:05:41,107:INFO:Checking exceptions
2024-11-28 17:05:41,108:INFO:Importing libraries
2024-11-28 17:05:41,109:INFO:Copying training dataset
2024-11-28 17:05:41,112:INFO:Defining folds
2024-11-28 17:05:41,112:INFO:Declaring metric variables
2024-11-28 17:05:41,112:INFO:Importing untrained model
2024-11-28 17:05:41,112:INFO:Declaring custom model
2024-11-28 17:05:41,113:INFO:Extreme Gradient Boosting Imported successfully
2024-11-28 17:05:41,115:INFO:Cross validation set to False
2024-11-28 17:05:41,115:INFO:Fitting Model
2024-11-28 17:05:41,233:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-11-28 17:05:41,233:INFO:create_model() successfully completed......................................
2024-11-28 17:05:41,310:INFO:Initializing create_model()
2024-11-28 17:05:41,311:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA5A6F50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1313, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:05:41,311:INFO:Checking exceptions
2024-11-28 17:05:41,313:INFO:Importing libraries
2024-11-28 17:05:41,313:INFO:Copying training dataset
2024-11-28 17:05:41,319:INFO:Defining folds
2024-11-28 17:05:41,319:INFO:Declaring metric variables
2024-11-28 17:05:41,319:INFO:Importing untrained model
2024-11-28 17:05:41,319:INFO:Declaring custom model
2024-11-28 17:05:41,320:INFO:Logistic Regression Imported successfully
2024-11-28 17:05:41,321:INFO:Cross validation set to False
2024-11-28 17:05:41,321:INFO:Fitting Model
2024-11-28 17:05:41,496:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:05:41,497:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1313, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-11-28 17:05:41,497:INFO:create_model() successfully completed......................................
2024-11-28 17:05:41,575:INFO:Initializing create_model()
2024-11-28 17:05:41,575:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA5A6F50>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:05:41,575:INFO:Checking exceptions
2024-11-28 17:05:41,577:INFO:Importing libraries
2024-11-28 17:05:41,577:INFO:Copying training dataset
2024-11-28 17:05:41,580:INFO:Defining folds
2024-11-28 17:05:41,580:INFO:Declaring metric variables
2024-11-28 17:05:41,581:INFO:Importing untrained model
2024-11-28 17:05:41,581:INFO:Declaring custom model
2024-11-28 17:05:41,581:INFO:Linear Discriminant Analysis Imported successfully
2024-11-28 17:05:41,582:INFO:Cross validation set to False
2024-11-28 17:05:41,582:INFO:Fitting Model
2024-11-28 17:05:41,623:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-11-28 17:05:41,623:INFO:create_model() successfully completed......................................
2024-11-28 17:05:41,705:INFO:Initializing create_model()
2024-11-28 17:05:41,705:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA5A6F50>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=1313, verbose=0,
                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:05:41,705:INFO:Checking exceptions
2024-11-28 17:05:41,707:INFO:Importing libraries
2024-11-28 17:05:41,707:INFO:Copying training dataset
2024-11-28 17:05:41,711:INFO:Defining folds
2024-11-28 17:05:41,711:INFO:Declaring metric variables
2024-11-28 17:05:41,711:INFO:Importing untrained model
2024-11-28 17:05:41,711:INFO:Declaring custom model
2024-11-28 17:05:41,712:INFO:Extra Trees Classifier Imported successfully
2024-11-28 17:05:41,713:INFO:Cross validation set to False
2024-11-28 17:05:41,713:INFO:Fitting Model
2024-11-28 17:05:41,847:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=1313, verbose=0,
                     warm_start=False)
2024-11-28 17:05:41,847:INFO:create_model() successfully completed......................................
2024-11-28 17:05:41,929:INFO:Initializing create_model()
2024-11-28 17:05:41,929:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA5A6F50>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=1313), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:05:41,929:INFO:Checking exceptions
2024-11-28 17:05:41,931:INFO:Importing libraries
2024-11-28 17:05:41,931:INFO:Copying training dataset
2024-11-28 17:05:41,937:INFO:Defining folds
2024-11-28 17:05:41,937:INFO:Declaring metric variables
2024-11-28 17:05:41,937:INFO:Importing untrained model
2024-11-28 17:05:41,938:INFO:Declaring custom model
2024-11-28 17:05:41,938:INFO:Ada Boost Classifier Imported successfully
2024-11-28 17:05:41,939:INFO:Cross validation set to False
2024-11-28 17:05:41,939:INFO:Fitting Model
2024-11-28 17:05:41,976:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:05:42,054:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=1313)
2024-11-28 17:05:42,054:INFO:create_model() successfully completed......................................
2024-11-28 17:05:42,128:INFO:Initializing create_model()
2024-11-28 17:05:42,128:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA5A6F50>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:05:42,128:INFO:Checking exceptions
2024-11-28 17:05:42,130:INFO:Importing libraries
2024-11-28 17:05:42,130:INFO:Copying training dataset
2024-11-28 17:05:42,135:INFO:Defining folds
2024-11-28 17:05:42,135:INFO:Declaring metric variables
2024-11-28 17:05:42,135:INFO:Importing untrained model
2024-11-28 17:05:42,135:INFO:Declaring custom model
2024-11-28 17:05:42,136:INFO:Naive Bayes Imported successfully
2024-11-28 17:05:42,136:INFO:Cross validation set to False
2024-11-28 17:05:42,137:INFO:Fitting Model
2024-11-28 17:05:42,174:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-11-28 17:05:42,174:INFO:create_model() successfully completed......................................
2024-11-28 17:05:42,244:INFO:Initializing create_model()
2024-11-28 17:05:42,245:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA5A6F50>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=1313, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:05:42,245:INFO:Checking exceptions
2024-11-28 17:05:42,247:INFO:Importing libraries
2024-11-28 17:05:42,247:INFO:Copying training dataset
2024-11-28 17:05:42,252:INFO:Defining folds
2024-11-28 17:05:42,252:INFO:Declaring metric variables
2024-11-28 17:05:42,253:INFO:Importing untrained model
2024-11-28 17:05:42,253:INFO:Declaring custom model
2024-11-28 17:05:42,253:INFO:Decision Tree Classifier Imported successfully
2024-11-28 17:05:42,254:INFO:Cross validation set to False
2024-11-28 17:05:42,254:INFO:Fitting Model
2024-11-28 17:05:42,292:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=1313, splitter='best')
2024-11-28 17:05:42,292:INFO:create_model() successfully completed......................................
2024-11-28 17:05:42,361:INFO:Initializing create_model()
2024-11-28 17:05:42,362:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA5A6F50>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:05:42,362:INFO:Checking exceptions
2024-11-28 17:05:42,365:INFO:Importing libraries
2024-11-28 17:05:42,365:INFO:Copying training dataset
2024-11-28 17:05:42,371:INFO:Defining folds
2024-11-28 17:05:42,371:INFO:Declaring metric variables
2024-11-28 17:05:42,371:INFO:Importing untrained model
2024-11-28 17:05:42,371:INFO:Declaring custom model
2024-11-28 17:05:42,372:INFO:Quadratic Discriminant Analysis Imported successfully
2024-11-28 17:05:42,373:INFO:Cross validation set to False
2024-11-28 17:05:42,373:INFO:Fitting Model
2024-11-28 17:05:42,406:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:05:42,407:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-11-28 17:05:42,407:INFO:create_model() successfully completed......................................
2024-11-28 17:05:42,481:INFO:Initializing create_model()
2024-11-28 17:05:42,481:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA5A6F50>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:05:42,482:INFO:Checking exceptions
2024-11-28 17:05:42,485:INFO:Importing libraries
2024-11-28 17:05:42,485:INFO:Copying training dataset
2024-11-28 17:05:42,488:INFO:Defining folds
2024-11-28 17:05:42,488:INFO:Declaring metric variables
2024-11-28 17:05:42,488:INFO:Importing untrained model
2024-11-28 17:05:42,488:INFO:Declaring custom model
2024-11-28 17:05:42,489:INFO:K Neighbors Classifier Imported successfully
2024-11-28 17:05:42,490:INFO:Cross validation set to False
2024-11-28 17:05:42,490:INFO:Fitting Model
2024-11-28 17:05:42,524:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-11-28 17:05:42,524:INFO:create_model() successfully completed......................................
2024-11-28 17:05:42,595:INFO:Initializing create_model()
2024-11-28 17:05:42,595:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA5A6F50>, estimator=DummyClassifier(constant=None, random_state=1313, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:05:42,595:INFO:Checking exceptions
2024-11-28 17:05:42,598:INFO:Importing libraries
2024-11-28 17:05:42,598:INFO:Copying training dataset
2024-11-28 17:05:42,602:INFO:Defining folds
2024-11-28 17:05:42,602:INFO:Declaring metric variables
2024-11-28 17:05:42,602:INFO:Importing untrained model
2024-11-28 17:05:42,602:INFO:Declaring custom model
2024-11-28 17:05:42,603:INFO:Dummy Classifier Imported successfully
2024-11-28 17:05:42,604:INFO:Cross validation set to False
2024-11-28 17:05:42,604:INFO:Fitting Model
2024-11-28 17:05:42,639:INFO:DummyClassifier(constant=None, random_state=1313, strategy='prior')
2024-11-28 17:05:42,639:INFO:create_model() successfully completed......................................
2024-11-28 17:05:42,726:INFO:Initializing create_model()
2024-11-28 17:05:42,726:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA5A6F50>, estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1313, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:05:42,727:INFO:Checking exceptions
2024-11-28 17:05:42,728:INFO:Importing libraries
2024-11-28 17:05:42,729:INFO:Copying training dataset
2024-11-28 17:05:42,732:INFO:Defining folds
2024-11-28 17:05:42,732:INFO:Declaring metric variables
2024-11-28 17:05:42,732:INFO:Importing untrained model
2024-11-28 17:05:42,733:INFO:Declaring custom model
2024-11-28 17:05:42,734:INFO:SVM - Linear Kernel Imported successfully
2024-11-28 17:05:42,736:INFO:Cross validation set to False
2024-11-28 17:05:42,736:INFO:Fitting Model
2024-11-28 17:05:42,774:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1313, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-11-28 17:05:42,774:INFO:create_model() successfully completed......................................
2024-11-28 17:05:42,858:INFO:_master_model_container: 16
2024-11-28 17:05:42,858:INFO:_display_container: 2
2024-11-28 17:05:42,861:INFO:[GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1313, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), <catboost.core.CatBoostClassifier object at 0x000002D8D9C27D00>, RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=1313, verbose=0,
                       warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1313, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1313, solver='auto',
                tol=0.0001), XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1313, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=1313, verbose=0,
                     warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=1313), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=1313, splitter='best'), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), DummyClassifier(constant=None, random_state=1313, strategy='prior'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1313, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)]
2024-11-28 17:05:42,861:INFO:compare_models() successfully completed......................................
2024-11-28 17:05:42,894:INFO:Initializing tune_model()
2024-11-28 17:05:42,894:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1313, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA5A6F50>)
2024-11-28 17:05:42,895:INFO:Checking exceptions
2024-11-28 17:05:42,911:INFO:Copying training dataset
2024-11-28 17:05:42,916:INFO:Checking base model
2024-11-28 17:05:42,916:INFO:Base model : Gradient Boosting Classifier
2024-11-28 17:05:42,920:INFO:Declaring metric variables
2024-11-28 17:05:42,924:INFO:Defining Hyperparameters
2024-11-28 17:05:43,000:INFO:Tuning with n_jobs=-1
2024-11-28 17:05:43,000:INFO:Initializing RandomizedSearchCV
2024-11-28 17:05:47,287:INFO:best_params: {'actual_estimator__subsample': 0.45, 'actual_estimator__n_estimators': 180, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.001, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 2, 'actual_estimator__learning_rate': 0.1}
2024-11-28 17:05:47,288:INFO:Hyperparameter search completed
2024-11-28 17:05:47,288:INFO:SubProcess create_model() called ==================================
2024-11-28 17:05:47,288:INFO:Initializing create_model()
2024-11-28 17:05:47,289:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA5A6F50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1313, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002D8D7B055D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.45, 'n_estimators': 180, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.001, 'max_features': 'sqrt', 'max_depth': 2, 'learning_rate': 0.1})
2024-11-28 17:05:47,289:INFO:Checking exceptions
2024-11-28 17:05:47,289:INFO:Importing libraries
2024-11-28 17:05:47,289:INFO:Copying training dataset
2024-11-28 17:05:47,293:INFO:Defining folds
2024-11-28 17:05:47,293:INFO:Declaring metric variables
2024-11-28 17:05:47,296:INFO:Importing untrained model
2024-11-28 17:05:47,296:INFO:Declaring custom model
2024-11-28 17:05:47,299:INFO:Gradient Boosting Classifier Imported successfully
2024-11-28 17:05:47,305:INFO:Starting cross validation
2024-11-28 17:05:47,306:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:05:47,798:INFO:Calculating mean and std
2024-11-28 17:05:47,799:INFO:Creating metrics dataframe
2024-11-28 17:05:47,804:INFO:Finalizing model
2024-11-28 17:05:47,976:INFO:Uploading results into container
2024-11-28 17:05:47,977:INFO:Uploading model into container now
2024-11-28 17:05:47,977:INFO:_master_model_container: 17
2024-11-28 17:05:47,977:INFO:_display_container: 3
2024-11-28 17:05:47,978:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=2,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.001, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=180, n_iter_no_change=None,
                           random_state=1313, subsample=0.45, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-11-28 17:05:47,978:INFO:create_model() successfully completed......................................
2024-11-28 17:05:48,045:INFO:SubProcess create_model() end ==================================
2024-11-28 17:05:48,045:INFO:choose_better activated
2024-11-28 17:05:48,048:INFO:SubProcess create_model() called ==================================
2024-11-28 17:05:48,048:INFO:Initializing create_model()
2024-11-28 17:05:48,048:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA5A6F50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1313, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:05:48,048:INFO:Checking exceptions
2024-11-28 17:05:48,050:INFO:Importing libraries
2024-11-28 17:05:48,050:INFO:Copying training dataset
2024-11-28 17:05:48,054:INFO:Defining folds
2024-11-28 17:05:48,054:INFO:Declaring metric variables
2024-11-28 17:05:48,054:INFO:Importing untrained model
2024-11-28 17:05:48,054:INFO:Declaring custom model
2024-11-28 17:05:48,055:INFO:Gradient Boosting Classifier Imported successfully
2024-11-28 17:05:48,055:INFO:Starting cross validation
2024-11-28 17:05:48,056:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:05:48,479:INFO:Calculating mean and std
2024-11-28 17:05:48,479:INFO:Creating metrics dataframe
2024-11-28 17:05:48,481:INFO:Finalizing model
2024-11-28 17:05:48,638:INFO:Uploading results into container
2024-11-28 17:05:48,638:INFO:Uploading model into container now
2024-11-28 17:05:48,639:INFO:_master_model_container: 18
2024-11-28 17:05:48,639:INFO:_display_container: 4
2024-11-28 17:05:48,639:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1313, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-11-28 17:05:48,639:INFO:create_model() successfully completed......................................
2024-11-28 17:05:48,703:INFO:SubProcess create_model() end ==================================
2024-11-28 17:05:48,703:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1313, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.8235
2024-11-28 17:05:48,704:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=2,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.001, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=180, n_iter_no_change=None,
                           random_state=1313, subsample=0.45, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.8236
2024-11-28 17:05:48,704:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=2,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.001, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=180, n_iter_no_change=None,
                           random_state=1313, subsample=0.45, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2024-11-28 17:05:48,704:INFO:choose_better completed
2024-11-28 17:05:48,712:INFO:_master_model_container: 18
2024-11-28 17:05:48,712:INFO:_display_container: 3
2024-11-28 17:05:48,713:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=2,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.001, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=180, n_iter_no_change=None,
                           random_state=1313, subsample=0.45, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-11-28 17:05:48,713:INFO:tune_model() successfully completed......................................
2024-11-28 17:05:48,781:INFO:Initializing evaluate_model()
2024-11-28 17:05:48,781:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA5A6F50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=2,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.001, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=180, n_iter_no_change=None,
                           random_state=1313, subsample=0.45, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-11-28 17:05:48,791:INFO:Initializing plot_model()
2024-11-28 17:05:48,791:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=2,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.001, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=180, n_iter_no_change=None,
                           random_state=1313, subsample=0.45, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA5A6F50>, system=True)
2024-11-28 17:05:48,791:INFO:Checking exceptions
2024-11-28 17:05:48,794:INFO:Preloading libraries
2024-11-28 17:05:48,806:INFO:Copying training dataset
2024-11-28 17:05:48,806:INFO:Plot type: pipeline
2024-11-28 17:05:48,981:INFO:Visual Rendered Successfully
2024-11-28 17:05:49,046:INFO:plot_model() successfully completed......................................
2024-11-28 17:05:49,050:INFO:Initializing finalize_model()
2024-11-28 17:05:49,050:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA5A6F50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=2,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.001, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=180, n_iter_no_change=None,
                           random_state=1313, subsample=0.45, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-11-28 17:05:49,051:INFO:Finalizing GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=2,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.001, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=180, n_iter_no_change=None,
                           random_state=1313, subsample=0.45, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-11-28 17:05:49,054:INFO:Initializing create_model()
2024-11-28 17:05:49,054:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA5A6F50>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=2,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.001, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=180, n_iter_no_change=None,
                           random_state=1313, subsample=0.45, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:05:49,054:INFO:Checking exceptions
2024-11-28 17:05:49,055:INFO:Importing libraries
2024-11-28 17:05:49,055:INFO:Copying training dataset
2024-11-28 17:05:49,056:INFO:Defining folds
2024-11-28 17:05:49,056:INFO:Declaring metric variables
2024-11-28 17:05:49,056:INFO:Importing untrained model
2024-11-28 17:05:49,056:INFO:Declaring custom model
2024-11-28 17:05:49,056:INFO:Gradient Boosting Classifier Imported successfully
2024-11-28 17:05:49,057:INFO:Cross validation set to False
2024-11-28 17:05:49,057:INFO:Fitting Model
2024-11-28 17:05:49,276:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare',
                                             'FamilySize'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=2, max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.001,
                                            min_samples_leaf=2,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=180,
                                            n_iter_no_change=None,
                                            random_state=1313, subsample=0.45,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2024-11-28 17:05:49,276:INFO:create_model() successfully completed......................................
2024-11-28 17:05:49,344:INFO:_master_model_container: 18
2024-11-28 17:05:49,344:INFO:_display_container: 3
2024-11-28 17:05:49,358:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare',
                                             'FamilySize'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=2, max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.001,
                                            min_samples_leaf=2,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=180,
                                            n_iter_no_change=None,
                                            random_state=1313, subsample=0.45,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2024-11-28 17:05:49,359:INFO:finalize_model() successfully completed......................................
2024-11-28 17:05:49,437:INFO:Initializing predict_model()
2024-11-28 17:05:49,437:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA5A6F50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare',
                                             'FamilySize'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=2, max_features='sqrt',
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.001,
                                            min_samples_leaf=2,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=180,
                                            n_iter_no_change=None,
                                            random_state=1313, subsample=0.45,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002D8DA3D44C0>)
2024-11-28 17:05:49,437:INFO:Checking exceptions
2024-11-28 17:05:49,437:INFO:Preloading libraries
2024-11-28 17:05:49,439:INFO:Set up data.
2024-11-28 17:05:49,442:INFO:Set up index.
2024-11-28 17:06:56,884:INFO:Initializing plot_model()
2024-11-28 17:06:56,884:INFO:plot_model(plot=parameter, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=2,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.001, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=180, n_iter_no_change=None,
                           random_state=1313, subsample=0.45, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA5A6F50>, system=True)
2024-11-28 17:06:56,884:INFO:Checking exceptions
2024-11-28 17:06:56,887:INFO:Preloading libraries
2024-11-28 17:06:56,898:INFO:Copying training dataset
2024-11-28 17:06:56,898:INFO:Plot type: parameter
2024-11-28 17:06:56,901:INFO:Visual Rendered Successfully
2024-11-28 17:06:56,966:INFO:plot_model() successfully completed......................................
2024-11-28 17:06:58,559:INFO:Initializing plot_model()
2024-11-28 17:06:58,560:INFO:plot_model(plot=calibration, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=2,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.001, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=180, n_iter_no_change=None,
                           random_state=1313, subsample=0.45, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA5A6F50>, system=True)
2024-11-28 17:06:58,560:INFO:Checking exceptions
2024-11-28 17:06:58,563:INFO:Preloading libraries
2024-11-28 17:06:58,573:INFO:Copying training dataset
2024-11-28 17:06:58,573:INFO:Plot type: calibration
2024-11-28 17:06:58,584:INFO:Scoring test/hold-out set
2024-11-28 17:06:58,794:INFO:Visual Rendered Successfully
2024-11-28 17:06:58,861:INFO:plot_model() successfully completed......................................
2024-11-28 17:06:59,689:INFO:Initializing plot_model()
2024-11-28 17:06:59,690:INFO:plot_model(plot=vc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=2,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.001, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=180, n_iter_no_change=None,
                           random_state=1313, subsample=0.45, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA5A6F50>, system=True)
2024-11-28 17:06:59,690:INFO:Checking exceptions
2024-11-28 17:06:59,693:INFO:Preloading libraries
2024-11-28 17:06:59,704:INFO:Copying training dataset
2024-11-28 17:06:59,704:INFO:Plot type: vc
2024-11-28 17:06:59,705:INFO:Determining param_name
2024-11-28 17:06:59,705:INFO:param_name: max_depth
2024-11-28 17:06:59,853:INFO:Fitting Model
2024-11-28 17:07:06,083:INFO:Visual Rendered Successfully
2024-11-28 17:07:06,148:INFO:plot_model() successfully completed......................................
2024-11-28 17:07:06,193:INFO:Initializing plot_model()
2024-11-28 17:07:06,193:INFO:plot_model(plot=auc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=2,
                           max_features='sqrt', max_leaf_nodes=None,
                           min_impurity_decrease=0.001, min_samples_leaf=2,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=180, n_iter_no_change=None,
                           random_state=1313, subsample=0.45, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002D8DA5A6F50>, system=True)
2024-11-28 17:07:06,193:INFO:Checking exceptions
2024-11-28 17:07:06,196:INFO:Preloading libraries
2024-11-28 17:07:06,206:INFO:Copying training dataset
2024-11-28 17:07:06,206:INFO:Plot type: auc
2024-11-28 17:07:06,357:INFO:Fitting Model
2024-11-28 17:07:06,358:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingClassifier was fitted with feature names
  warnings.warn(

2024-11-28 17:07:06,358:INFO:Scoring test/hold-out set
2024-11-28 17:07:06,544:INFO:Visual Rendered Successfully
2024-11-28 17:07:06,620:INFO:plot_model() successfully completed......................................
2024-11-28 17:20:25,795:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-28 17:20:25,795:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-28 17:20:25,795:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-28 17:20:25,795:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-28 17:20:26,222:INFO:PyCaret ClassificationExperiment
2024-11-28 17:20:26,223:INFO:Logging name: clf-default-name
2024-11-28 17:20:26,223:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-11-28 17:20:26,223:INFO:version 3.3.2
2024-11-28 17:20:26,223:INFO:Initializing setup()
2024-11-28 17:20:26,223:INFO:self.USI: 66a9
2024-11-28 17:20:26,223:INFO:self._variable_keys: {'fold_groups_param', '_available_plots', 'gpu_param', 'y', 'fold_generator', 'X_train', 'exp_name_log', 'n_jobs_param', 'exp_id', 'y_test', 'X_test', 'X', 'logging_param', 'gpu_n_jobs_param', 'USI', 'data', 'seed', 'memory', 'fold_shuffle_param', 'html_param', 'log_plots_param', 'fix_imbalance', 'pipeline', 'target_param', 'y_train', 'is_multiclass', '_ml_usecase', 'idx'}
2024-11-28 17:20:26,223:INFO:Checking environment
2024-11-28 17:20:26,223:INFO:python_version: 3.10.11
2024-11-28 17:20:26,223:INFO:python_build: ('tags/v3.10.11:7d4cc5a', 'Apr  5 2023 00:38:17')
2024-11-28 17:20:26,223:INFO:machine: AMD64
2024-11-28 17:20:26,223:INFO:platform: Windows-10-10.0.19045-SP0
2024-11-28 17:20:26,227:INFO:Memory: svmem(total=34216488960, available=20471664640, percent=40.2, used=13744824320, free=20471664640)
2024-11-28 17:20:26,227:INFO:Physical Core: 6
2024-11-28 17:20:26,227:INFO:Logical Core: 6
2024-11-28 17:20:26,227:INFO:Checking libraries
2024-11-28 17:20:26,227:INFO:System:
2024-11-28 17:20:26,227:INFO:    python: 3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]
2024-11-28 17:20:26,227:INFO:executable: c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\Scripts\python.exe
2024-11-28 17:20:26,227:INFO:   machine: Windows-10-10.0.19045-SP0
2024-11-28 17:20:26,227:INFO:PyCaret required dependencies:
2024-11-28 17:20:26,266:INFO:                 pip: 23.0.1
2024-11-28 17:20:26,266:INFO:          setuptools: 65.5.0
2024-11-28 17:20:26,267:INFO:             pycaret: 3.3.2
2024-11-28 17:20:26,267:INFO:             IPython: 8.29.0
2024-11-28 17:20:26,267:INFO:          ipywidgets: 8.1.5
2024-11-28 17:20:26,267:INFO:                tqdm: 4.67.1
2024-11-28 17:20:26,267:INFO:               numpy: 1.26.4
2024-11-28 17:20:26,267:INFO:              pandas: 2.1.4
2024-11-28 17:20:26,267:INFO:              jinja2: 3.1.4
2024-11-28 17:20:26,267:INFO:               scipy: 1.11.4
2024-11-28 17:20:26,267:INFO:              joblib: 1.3.2
2024-11-28 17:20:26,267:INFO:             sklearn: 1.4.2
2024-11-28 17:20:26,267:INFO:                pyod: 2.0.2
2024-11-28 17:20:26,267:INFO:            imblearn: 0.12.4
2024-11-28 17:20:26,267:INFO:   category_encoders: 2.6.4
2024-11-28 17:20:26,267:INFO:            lightgbm: 4.5.0
2024-11-28 17:20:26,267:INFO:               numba: 0.60.0
2024-11-28 17:20:26,267:INFO:            requests: 2.32.3
2024-11-28 17:20:26,267:INFO:          matplotlib: 3.7.5
2024-11-28 17:20:26,267:INFO:          scikitplot: 0.3.7
2024-11-28 17:20:26,267:INFO:         yellowbrick: 1.5
2024-11-28 17:20:26,267:INFO:              plotly: 5.24.1
2024-11-28 17:20:26,267:INFO:    plotly-resampler: Not installed
2024-11-28 17:20:26,267:INFO:             kaleido: 0.2.1
2024-11-28 17:20:26,267:INFO:           schemdraw: 0.15
2024-11-28 17:20:26,267:INFO:         statsmodels: 0.14.4
2024-11-28 17:20:26,267:INFO:              sktime: 0.26.0
2024-11-28 17:20:26,267:INFO:               tbats: 1.1.3
2024-11-28 17:20:26,267:INFO:            pmdarima: 2.0.4
2024-11-28 17:20:26,267:INFO:              psutil: 6.1.0
2024-11-28 17:20:26,268:INFO:          markupsafe: 3.0.2
2024-11-28 17:20:26,268:INFO:             pickle5: Not installed
2024-11-28 17:20:26,268:INFO:         cloudpickle: 3.1.0
2024-11-28 17:20:26,268:INFO:         deprecation: 2.1.0
2024-11-28 17:20:26,268:INFO:              xxhash: 3.5.0
2024-11-28 17:20:26,268:INFO:           wurlitzer: Not installed
2024-11-28 17:20:26,268:INFO:PyCaret optional dependencies:
2024-11-28 17:20:26,302:INFO:                shap: Not installed
2024-11-28 17:20:26,302:INFO:           interpret: Not installed
2024-11-28 17:20:26,302:INFO:                umap: Not installed
2024-11-28 17:20:26,303:INFO:     ydata_profiling: Not installed
2024-11-28 17:20:26,303:INFO:  explainerdashboard: Not installed
2024-11-28 17:20:26,303:INFO:             autoviz: Not installed
2024-11-28 17:20:26,303:INFO:           fairlearn: Not installed
2024-11-28 17:20:26,303:INFO:          deepchecks: Not installed
2024-11-28 17:20:26,303:INFO:             xgboost: 2.1.3
2024-11-28 17:20:26,303:INFO:            catboost: 1.2.7
2024-11-28 17:20:26,303:INFO:              kmodes: Not installed
2024-11-28 17:20:26,303:INFO:             mlxtend: 0.23.3
2024-11-28 17:20:26,303:INFO:       statsforecast: Not installed
2024-11-28 17:20:26,303:INFO:        tune_sklearn: Not installed
2024-11-28 17:20:26,303:INFO:                 ray: Not installed
2024-11-28 17:20:26,303:INFO:            hyperopt: Not installed
2024-11-28 17:20:26,303:INFO:              optuna: Not installed
2024-11-28 17:20:26,303:INFO:               skopt: Not installed
2024-11-28 17:20:26,303:INFO:              mlflow: Not installed
2024-11-28 17:20:26,303:INFO:              gradio: Not installed
2024-11-28 17:20:26,303:INFO:             fastapi: Not installed
2024-11-28 17:20:26,303:INFO:             uvicorn: Not installed
2024-11-28 17:20:26,303:INFO:              m2cgen: Not installed
2024-11-28 17:20:26,303:INFO:           evidently: Not installed
2024-11-28 17:20:26,303:INFO:               fugue: Not installed
2024-11-28 17:20:26,303:INFO:           streamlit: 1.39.0
2024-11-28 17:20:26,304:INFO:             prophet: Not installed
2024-11-28 17:20:26,304:INFO:None
2024-11-28 17:20:26,304:INFO:Set up data.
2024-11-28 17:20:26,308:INFO:Set up folding strategy.
2024-11-28 17:20:26,308:INFO:Set up train/test split.
2024-11-28 17:20:26,314:INFO:Set up index.
2024-11-28 17:20:26,314:INFO:Assigning column types.
2024-11-28 17:20:26,317:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-28 17:20:26,355:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-28 17:20:26,358:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-28 17:20:26,388:INFO:Soft dependency imported: xgboost: 2.1.3
2024-11-28 17:20:26,390:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-28 17:20:26,446:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-28 17:20:26,447:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-28 17:20:26,471:INFO:Soft dependency imported: xgboost: 2.1.3
2024-11-28 17:20:26,473:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-28 17:20:26,474:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-28 17:20:26,516:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-28 17:20:26,540:INFO:Soft dependency imported: xgboost: 2.1.3
2024-11-28 17:20:26,542:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-28 17:20:26,582:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-28 17:20:26,605:INFO:Soft dependency imported: xgboost: 2.1.3
2024-11-28 17:20:26,607:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-28 17:20:26,608:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-11-28 17:20:26,670:INFO:Soft dependency imported: xgboost: 2.1.3
2024-11-28 17:20:26,672:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-28 17:20:26,734:INFO:Soft dependency imported: xgboost: 2.1.3
2024-11-28 17:20:26,737:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-28 17:20:26,739:INFO:Preparing preprocessing pipeline...
2024-11-28 17:20:26,739:INFO:Set up simple imputation.
2024-11-28 17:20:26,742:INFO:Set up encoding of ordinal features.
2024-11-28 17:20:26,743:INFO:Set up encoding of categorical features.
2024-11-28 17:20:26,797:INFO:Finished creating preprocessing pipeline.
2024-11-28 17:20:26,812:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\tsai\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare',
                                             'FamilySize'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('...
                                                               mapping=[{'col': 'Sex',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['Embarked'],
                                    transformer=OneHotEncoder(cols=['Embarked'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-11-28 17:20:26,813:INFO:Creating final display dataframe.
2024-11-28 17:20:26,975:INFO:Setup _display_container:                     Description             Value
0                    Session id              4503
1                        Target          Survived
2                   Target type            Binary
3           Original data shape         (891, 10)
4        Transformed data shape         (891, 12)
5   Transformed train set shape         (623, 12)
6    Transformed test set shape         (268, 12)
7              Numeric features                 7
8          Categorical features                 2
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              66a9
2024-11-28 17:20:27,045:INFO:Soft dependency imported: xgboost: 2.1.3
2024-11-28 17:20:27,047:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-28 17:20:27,112:INFO:Soft dependency imported: xgboost: 2.1.3
2024-11-28 17:20:27,115:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-28 17:20:27,116:INFO:setup() successfully completed in 0.9s...............
2024-11-28 17:20:27,116:INFO:Initializing compare_models()
2024-11-28 17:20:27,116:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4ADA37640>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=16, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001E4ADA37640>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 16, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-11-28 17:20:27,116:INFO:Checking exceptions
2024-11-28 17:20:27,119:INFO:Preparing display monitor
2024-11-28 17:20:27,139:INFO:Initializing Logistic Regression
2024-11-28 17:20:27,139:INFO:Total runtime is 0.0 minutes
2024-11-28 17:20:27,142:INFO:SubProcess create_model() called ==================================
2024-11-28 17:20:27,143:INFO:Initializing create_model()
2024-11-28 17:20:27,143:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4ADA37640>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4C8FA5420>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:27,143:INFO:Checking exceptions
2024-11-28 17:20:27,143:INFO:Importing libraries
2024-11-28 17:20:27,143:INFO:Copying training dataset
2024-11-28 17:20:27,149:INFO:Defining folds
2024-11-28 17:20:27,149:INFO:Declaring metric variables
2024-11-28 17:20:27,152:INFO:Importing untrained model
2024-11-28 17:20:27,155:INFO:Logistic Regression Imported successfully
2024-11-28 17:20:27,162:INFO:Starting cross validation
2024-11-28 17:20:27,164:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:20:31,112:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:20:31,157:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:20:31,163:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:20:31,228:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:20:31,234:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:20:31,338:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:20:31,393:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:20:31,448:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:20:31,478:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:20:31,521:INFO:Calculating mean and std
2024-11-28 17:20:31,522:INFO:Creating metrics dataframe
2024-11-28 17:20:31,524:INFO:Uploading results into container
2024-11-28 17:20:31,525:INFO:Uploading model into container now
2024-11-28 17:20:31,526:INFO:_master_model_container: 1
2024-11-28 17:20:31,526:INFO:_display_container: 2
2024-11-28 17:20:31,527:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4503, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-11-28 17:20:31,527:INFO:create_model() successfully completed......................................
2024-11-28 17:20:31,592:INFO:SubProcess create_model() end ==================================
2024-11-28 17:20:31,592:INFO:Creating metrics dataframe
2024-11-28 17:20:31,597:INFO:Initializing K Neighbors Classifier
2024-11-28 17:20:31,598:INFO:Total runtime is 0.07430965503056844 minutes
2024-11-28 17:20:31,600:INFO:SubProcess create_model() called ==================================
2024-11-28 17:20:31,601:INFO:Initializing create_model()
2024-11-28 17:20:31,601:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4ADA37640>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4C8FA5420>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:31,601:INFO:Checking exceptions
2024-11-28 17:20:31,601:INFO:Importing libraries
2024-11-28 17:20:31,601:INFO:Copying training dataset
2024-11-28 17:20:31,605:INFO:Defining folds
2024-11-28 17:20:31,605:INFO:Declaring metric variables
2024-11-28 17:20:31,607:INFO:Importing untrained model
2024-11-28 17:20:31,610:INFO:K Neighbors Classifier Imported successfully
2024-11-28 17:20:31,630:INFO:Starting cross validation
2024-11-28 17:20:31,632:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:20:31,942:INFO:Calculating mean and std
2024-11-28 17:20:31,943:INFO:Creating metrics dataframe
2024-11-28 17:20:31,946:INFO:Uploading results into container
2024-11-28 17:20:31,947:INFO:Uploading model into container now
2024-11-28 17:20:31,947:INFO:_master_model_container: 2
2024-11-28 17:20:31,947:INFO:_display_container: 2
2024-11-28 17:20:31,948:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-11-28 17:20:31,948:INFO:create_model() successfully completed......................................
2024-11-28 17:20:32,008:INFO:SubProcess create_model() end ==================================
2024-11-28 17:20:32,008:INFO:Creating metrics dataframe
2024-11-28 17:20:32,014:INFO:Initializing Naive Bayes
2024-11-28 17:20:32,014:INFO:Total runtime is 0.08124114274978637 minutes
2024-11-28 17:20:32,017:INFO:SubProcess create_model() called ==================================
2024-11-28 17:20:32,017:INFO:Initializing create_model()
2024-11-28 17:20:32,017:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4ADA37640>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4C8FA5420>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:32,017:INFO:Checking exceptions
2024-11-28 17:20:32,017:INFO:Importing libraries
2024-11-28 17:20:32,017:INFO:Copying training dataset
2024-11-28 17:20:32,021:INFO:Defining folds
2024-11-28 17:20:32,021:INFO:Declaring metric variables
2024-11-28 17:20:32,024:INFO:Importing untrained model
2024-11-28 17:20:32,028:INFO:Naive Bayes Imported successfully
2024-11-28 17:20:32,035:INFO:Starting cross validation
2024-11-28 17:20:32,037:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:20:32,222:INFO:Calculating mean and std
2024-11-28 17:20:32,223:INFO:Creating metrics dataframe
2024-11-28 17:20:32,225:INFO:Uploading results into container
2024-11-28 17:20:32,226:INFO:Uploading model into container now
2024-11-28 17:20:32,226:INFO:_master_model_container: 3
2024-11-28 17:20:32,226:INFO:_display_container: 2
2024-11-28 17:20:32,227:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-11-28 17:20:32,227:INFO:create_model() successfully completed......................................
2024-11-28 17:20:32,285:INFO:SubProcess create_model() end ==================================
2024-11-28 17:20:32,285:INFO:Creating metrics dataframe
2024-11-28 17:20:32,293:INFO:Initializing Decision Tree Classifier
2024-11-28 17:20:32,293:INFO:Total runtime is 0.08589536746342977 minutes
2024-11-28 17:20:32,296:INFO:SubProcess create_model() called ==================================
2024-11-28 17:20:32,297:INFO:Initializing create_model()
2024-11-28 17:20:32,297:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4ADA37640>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4C8FA5420>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:32,297:INFO:Checking exceptions
2024-11-28 17:20:32,297:INFO:Importing libraries
2024-11-28 17:20:32,297:INFO:Copying training dataset
2024-11-28 17:20:32,301:INFO:Defining folds
2024-11-28 17:20:32,301:INFO:Declaring metric variables
2024-11-28 17:20:32,304:INFO:Importing untrained model
2024-11-28 17:20:32,307:INFO:Decision Tree Classifier Imported successfully
2024-11-28 17:20:32,314:INFO:Starting cross validation
2024-11-28 17:20:32,315:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:20:32,532:INFO:Calculating mean and std
2024-11-28 17:20:32,533:INFO:Creating metrics dataframe
2024-11-28 17:20:32,535:INFO:Uploading results into container
2024-11-28 17:20:32,536:INFO:Uploading model into container now
2024-11-28 17:20:32,536:INFO:_master_model_container: 4
2024-11-28 17:20:32,536:INFO:_display_container: 2
2024-11-28 17:20:32,537:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=4503, splitter='best')
2024-11-28 17:20:32,537:INFO:create_model() successfully completed......................................
2024-11-28 17:20:32,596:INFO:SubProcess create_model() end ==================================
2024-11-28 17:20:32,596:INFO:Creating metrics dataframe
2024-11-28 17:20:32,602:INFO:Initializing SVM - Linear Kernel
2024-11-28 17:20:32,602:INFO:Total runtime is 0.09104870955149333 minutes
2024-11-28 17:20:32,605:INFO:SubProcess create_model() called ==================================
2024-11-28 17:20:32,605:INFO:Initializing create_model()
2024-11-28 17:20:32,605:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4ADA37640>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4C8FA5420>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:32,605:INFO:Checking exceptions
2024-11-28 17:20:32,605:INFO:Importing libraries
2024-11-28 17:20:32,605:INFO:Copying training dataset
2024-11-28 17:20:32,610:INFO:Defining folds
2024-11-28 17:20:32,610:INFO:Declaring metric variables
2024-11-28 17:20:32,612:INFO:Importing untrained model
2024-11-28 17:20:32,616:INFO:SVM - Linear Kernel Imported successfully
2024-11-28 17:20:32,621:INFO:Starting cross validation
2024-11-28 17:20:32,622:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:20:32,803:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:20:32,826:INFO:Calculating mean and std
2024-11-28 17:20:32,827:INFO:Creating metrics dataframe
2024-11-28 17:20:32,833:INFO:Uploading results into container
2024-11-28 17:20:32,834:INFO:Uploading model into container now
2024-11-28 17:20:32,834:INFO:_master_model_container: 5
2024-11-28 17:20:32,834:INFO:_display_container: 2
2024-11-28 17:20:32,835:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=4503, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-11-28 17:20:32,835:INFO:create_model() successfully completed......................................
2024-11-28 17:20:32,897:INFO:SubProcess create_model() end ==================================
2024-11-28 17:20:32,897:INFO:Creating metrics dataframe
2024-11-28 17:20:32,903:INFO:Initializing Ridge Classifier
2024-11-28 17:20:32,903:INFO:Total runtime is 0.09606813192367554 minutes
2024-11-28 17:20:32,906:INFO:SubProcess create_model() called ==================================
2024-11-28 17:20:32,907:INFO:Initializing create_model()
2024-11-28 17:20:32,907:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4ADA37640>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4C8FA5420>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:32,907:INFO:Checking exceptions
2024-11-28 17:20:32,907:INFO:Importing libraries
2024-11-28 17:20:32,907:INFO:Copying training dataset
2024-11-28 17:20:32,911:INFO:Defining folds
2024-11-28 17:20:32,912:INFO:Declaring metric variables
2024-11-28 17:20:32,914:INFO:Importing untrained model
2024-11-28 17:20:32,918:INFO:Ridge Classifier Imported successfully
2024-11-28 17:20:32,924:INFO:Starting cross validation
2024-11-28 17:20:32,927:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:20:33,122:INFO:Calculating mean and std
2024-11-28 17:20:33,123:INFO:Creating metrics dataframe
2024-11-28 17:20:33,126:INFO:Uploading results into container
2024-11-28 17:20:33,127:INFO:Uploading model into container now
2024-11-28 17:20:33,127:INFO:_master_model_container: 6
2024-11-28 17:20:33,127:INFO:_display_container: 2
2024-11-28 17:20:33,128:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=4503, solver='auto',
                tol=0.0001)
2024-11-28 17:20:33,128:INFO:create_model() successfully completed......................................
2024-11-28 17:20:33,198:INFO:SubProcess create_model() end ==================================
2024-11-28 17:20:33,198:INFO:Creating metrics dataframe
2024-11-28 17:20:33,206:INFO:Initializing Random Forest Classifier
2024-11-28 17:20:33,206:INFO:Total runtime is 0.10112128655115764 minutes
2024-11-28 17:20:33,212:INFO:SubProcess create_model() called ==================================
2024-11-28 17:20:33,212:INFO:Initializing create_model()
2024-11-28 17:20:33,212:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4ADA37640>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4C8FA5420>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:33,213:INFO:Checking exceptions
2024-11-28 17:20:33,213:INFO:Importing libraries
2024-11-28 17:20:33,213:INFO:Copying training dataset
2024-11-28 17:20:33,217:INFO:Defining folds
2024-11-28 17:20:33,217:INFO:Declaring metric variables
2024-11-28 17:20:33,220:INFO:Importing untrained model
2024-11-28 17:20:33,225:INFO:Random Forest Classifier Imported successfully
2024-11-28 17:20:33,236:INFO:Starting cross validation
2024-11-28 17:20:33,238:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:20:33,926:INFO:Calculating mean and std
2024-11-28 17:20:33,926:INFO:Creating metrics dataframe
2024-11-28 17:20:33,929:INFO:Uploading results into container
2024-11-28 17:20:33,929:INFO:Uploading model into container now
2024-11-28 17:20:33,929:INFO:_master_model_container: 7
2024-11-28 17:20:33,930:INFO:_display_container: 2
2024-11-28 17:20:33,930:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=4503, verbose=0,
                       warm_start=False)
2024-11-28 17:20:33,930:INFO:create_model() successfully completed......................................
2024-11-28 17:20:33,989:INFO:SubProcess create_model() end ==================================
2024-11-28 17:20:33,989:INFO:Creating metrics dataframe
2024-11-28 17:20:33,996:INFO:Initializing Quadratic Discriminant Analysis
2024-11-28 17:20:33,996:INFO:Total runtime is 0.1142820437749227 minutes
2024-11-28 17:20:33,999:INFO:SubProcess create_model() called ==================================
2024-11-28 17:20:33,999:INFO:Initializing create_model()
2024-11-28 17:20:34,000:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4ADA37640>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4C8FA5420>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:34,000:INFO:Checking exceptions
2024-11-28 17:20:34,000:INFO:Importing libraries
2024-11-28 17:20:34,000:INFO:Copying training dataset
2024-11-28 17:20:34,004:INFO:Defining folds
2024-11-28 17:20:34,004:INFO:Declaring metric variables
2024-11-28 17:20:34,007:INFO:Importing untrained model
2024-11-28 17:20:34,010:INFO:Quadratic Discriminant Analysis Imported successfully
2024-11-28 17:20:34,016:INFO:Starting cross validation
2024-11-28 17:20:34,017:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:20:34,074:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:20:34,076:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:20:34,077:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:20:34,078:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:20:34,079:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:20:34,085:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:20:34,150:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:20:34,150:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:20:34,151:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:20:34,152:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:20:34,190:INFO:Calculating mean and std
2024-11-28 17:20:34,191:INFO:Creating metrics dataframe
2024-11-28 17:20:34,193:INFO:Uploading results into container
2024-11-28 17:20:34,194:INFO:Uploading model into container now
2024-11-28 17:20:34,194:INFO:_master_model_container: 8
2024-11-28 17:20:34,194:INFO:_display_container: 2
2024-11-28 17:20:34,195:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-11-28 17:20:34,195:INFO:create_model() successfully completed......................................
2024-11-28 17:20:34,256:INFO:SubProcess create_model() end ==================================
2024-11-28 17:20:34,256:INFO:Creating metrics dataframe
2024-11-28 17:20:34,263:INFO:Initializing Ada Boost Classifier
2024-11-28 17:20:34,263:INFO:Total runtime is 0.11873632272084554 minutes
2024-11-28 17:20:34,266:INFO:SubProcess create_model() called ==================================
2024-11-28 17:20:34,267:INFO:Initializing create_model()
2024-11-28 17:20:34,267:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4ADA37640>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4C8FA5420>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:34,267:INFO:Checking exceptions
2024-11-28 17:20:34,267:INFO:Importing libraries
2024-11-28 17:20:34,267:INFO:Copying training dataset
2024-11-28 17:20:34,271:INFO:Defining folds
2024-11-28 17:20:34,271:INFO:Declaring metric variables
2024-11-28 17:20:34,274:INFO:Importing untrained model
2024-11-28 17:20:34,278:INFO:Ada Boost Classifier Imported successfully
2024-11-28 17:20:34,284:INFO:Starting cross validation
2024-11-28 17:20:34,285:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:20:34,341:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:20:34,346:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:20:34,348:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:20:34,350:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:20:34,378:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:20:34,381:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:20:34,503:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:20:34,517:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:20:34,524:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:20:34,549:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:20:34,672:INFO:Calculating mean and std
2024-11-28 17:20:34,673:INFO:Creating metrics dataframe
2024-11-28 17:20:34,675:INFO:Uploading results into container
2024-11-28 17:20:34,676:INFO:Uploading model into container now
2024-11-28 17:20:34,676:INFO:_master_model_container: 9
2024-11-28 17:20:34,676:INFO:_display_container: 2
2024-11-28 17:20:34,676:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=4503)
2024-11-28 17:20:34,676:INFO:create_model() successfully completed......................................
2024-11-28 17:20:34,737:INFO:SubProcess create_model() end ==================================
2024-11-28 17:20:34,737:INFO:Creating metrics dataframe
2024-11-28 17:20:34,745:INFO:Initializing Gradient Boosting Classifier
2024-11-28 17:20:34,745:INFO:Total runtime is 0.1267648458480835 minutes
2024-11-28 17:20:34,749:INFO:SubProcess create_model() called ==================================
2024-11-28 17:20:34,749:INFO:Initializing create_model()
2024-11-28 17:20:34,749:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4ADA37640>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4C8FA5420>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:34,749:INFO:Checking exceptions
2024-11-28 17:20:34,749:INFO:Importing libraries
2024-11-28 17:20:34,749:INFO:Copying training dataset
2024-11-28 17:20:34,753:INFO:Defining folds
2024-11-28 17:20:34,753:INFO:Declaring metric variables
2024-11-28 17:20:34,756:INFO:Importing untrained model
2024-11-28 17:20:34,759:INFO:Gradient Boosting Classifier Imported successfully
2024-11-28 17:20:34,765:INFO:Starting cross validation
2024-11-28 17:20:34,766:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:20:35,277:INFO:Calculating mean and std
2024-11-28 17:20:35,277:INFO:Creating metrics dataframe
2024-11-28 17:20:35,279:INFO:Uploading results into container
2024-11-28 17:20:35,280:INFO:Uploading model into container now
2024-11-28 17:20:35,280:INFO:_master_model_container: 10
2024-11-28 17:20:35,280:INFO:_display_container: 2
2024-11-28 17:20:35,281:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4503, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-11-28 17:20:35,281:INFO:create_model() successfully completed......................................
2024-11-28 17:20:35,339:INFO:SubProcess create_model() end ==================================
2024-11-28 17:20:35,339:INFO:Creating metrics dataframe
2024-11-28 17:20:35,347:INFO:Initializing Linear Discriminant Analysis
2024-11-28 17:20:35,347:INFO:Total runtime is 0.13680474758148195 minutes
2024-11-28 17:20:35,350:INFO:SubProcess create_model() called ==================================
2024-11-28 17:20:35,350:INFO:Initializing create_model()
2024-11-28 17:20:35,350:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4ADA37640>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4C8FA5420>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:35,350:INFO:Checking exceptions
2024-11-28 17:20:35,350:INFO:Importing libraries
2024-11-28 17:20:35,350:INFO:Copying training dataset
2024-11-28 17:20:35,354:INFO:Defining folds
2024-11-28 17:20:35,354:INFO:Declaring metric variables
2024-11-28 17:20:35,357:INFO:Importing untrained model
2024-11-28 17:20:35,361:INFO:Linear Discriminant Analysis Imported successfully
2024-11-28 17:20:35,398:INFO:Starting cross validation
2024-11-28 17:20:35,399:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:20:35,570:INFO:Calculating mean and std
2024-11-28 17:20:35,574:INFO:Creating metrics dataframe
2024-11-28 17:20:35,579:INFO:Uploading results into container
2024-11-28 17:20:35,580:INFO:Uploading model into container now
2024-11-28 17:20:35,581:INFO:_master_model_container: 11
2024-11-28 17:20:35,581:INFO:_display_container: 2
2024-11-28 17:20:35,582:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-11-28 17:20:35,582:INFO:create_model() successfully completed......................................
2024-11-28 17:20:35,661:INFO:SubProcess create_model() end ==================================
2024-11-28 17:20:35,661:INFO:Creating metrics dataframe
2024-11-28 17:20:35,669:INFO:Initializing Extra Trees Classifier
2024-11-28 17:20:35,669:INFO:Total runtime is 0.1421605110168457 minutes
2024-11-28 17:20:35,671:INFO:SubProcess create_model() called ==================================
2024-11-28 17:20:35,672:INFO:Initializing create_model()
2024-11-28 17:20:35,672:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4ADA37640>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4C8FA5420>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:35,672:INFO:Checking exceptions
2024-11-28 17:20:35,672:INFO:Importing libraries
2024-11-28 17:20:35,672:INFO:Copying training dataset
2024-11-28 17:20:35,678:INFO:Defining folds
2024-11-28 17:20:35,678:INFO:Declaring metric variables
2024-11-28 17:20:35,682:INFO:Importing untrained model
2024-11-28 17:20:35,685:INFO:Extra Trees Classifier Imported successfully
2024-11-28 17:20:35,693:INFO:Starting cross validation
2024-11-28 17:20:35,695:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:20:36,315:INFO:Calculating mean and std
2024-11-28 17:20:36,320:INFO:Creating metrics dataframe
2024-11-28 17:20:36,328:INFO:Uploading results into container
2024-11-28 17:20:36,331:INFO:Uploading model into container now
2024-11-28 17:20:36,333:INFO:_master_model_container: 12
2024-11-28 17:20:36,333:INFO:_display_container: 2
2024-11-28 17:20:36,335:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=4503, verbose=0,
                     warm_start=False)
2024-11-28 17:20:36,335:INFO:create_model() successfully completed......................................
2024-11-28 17:20:36,450:INFO:SubProcess create_model() end ==================================
2024-11-28 17:20:36,450:INFO:Creating metrics dataframe
2024-11-28 17:20:36,458:INFO:Initializing Extreme Gradient Boosting
2024-11-28 17:20:36,458:INFO:Total runtime is 0.15530920028686523 minutes
2024-11-28 17:20:36,462:INFO:SubProcess create_model() called ==================================
2024-11-28 17:20:36,462:INFO:Initializing create_model()
2024-11-28 17:20:36,462:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4ADA37640>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4C8FA5420>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:36,462:INFO:Checking exceptions
2024-11-28 17:20:36,462:INFO:Importing libraries
2024-11-28 17:20:36,462:INFO:Copying training dataset
2024-11-28 17:20:36,467:INFO:Defining folds
2024-11-28 17:20:36,467:INFO:Declaring metric variables
2024-11-28 17:20:36,470:INFO:Importing untrained model
2024-11-28 17:20:36,473:INFO:Extreme Gradient Boosting Imported successfully
2024-11-28 17:20:36,480:INFO:Starting cross validation
2024-11-28 17:20:36,480:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:20:37,290:INFO:Calculating mean and std
2024-11-28 17:20:37,294:INFO:Creating metrics dataframe
2024-11-28 17:20:37,302:INFO:Uploading results into container
2024-11-28 17:20:37,304:INFO:Uploading model into container now
2024-11-28 17:20:37,305:INFO:_master_model_container: 13
2024-11-28 17:20:37,306:INFO:_display_container: 2
2024-11-28 17:20:37,309:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-11-28 17:20:37,310:INFO:create_model() successfully completed......................................
2024-11-28 17:20:37,473:INFO:SubProcess create_model() end ==================================
2024-11-28 17:20:37,473:INFO:Creating metrics dataframe
2024-11-28 17:20:37,488:INFO:Initializing Light Gradient Boosting Machine
2024-11-28 17:20:37,488:INFO:Total runtime is 0.17248273690541585 minutes
2024-11-28 17:20:37,493:INFO:SubProcess create_model() called ==================================
2024-11-28 17:20:37,493:INFO:Initializing create_model()
2024-11-28 17:20:37,493:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4ADA37640>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4C8FA5420>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:37,493:INFO:Checking exceptions
2024-11-28 17:20:37,493:INFO:Importing libraries
2024-11-28 17:20:37,493:INFO:Copying training dataset
2024-11-28 17:20:37,499:INFO:Defining folds
2024-11-28 17:20:37,499:INFO:Declaring metric variables
2024-11-28 17:20:37,502:INFO:Importing untrained model
2024-11-28 17:20:37,507:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-28 17:20:37,513:INFO:Starting cross validation
2024-11-28 17:20:37,514:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:20:38,156:INFO:Calculating mean and std
2024-11-28 17:20:38,157:INFO:Creating metrics dataframe
2024-11-28 17:20:38,160:INFO:Uploading results into container
2024-11-28 17:20:38,161:INFO:Uploading model into container now
2024-11-28 17:20:38,161:INFO:_master_model_container: 14
2024-11-28 17:20:38,161:INFO:_display_container: 2
2024-11-28 17:20:38,161:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4503, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-11-28 17:20:38,161:INFO:create_model() successfully completed......................................
2024-11-28 17:20:38,219:INFO:SubProcess create_model() end ==================================
2024-11-28 17:20:38,219:INFO:Creating metrics dataframe
2024-11-28 17:20:38,228:INFO:Initializing CatBoost Classifier
2024-11-28 17:20:38,228:INFO:Total runtime is 0.18481588761011758 minutes
2024-11-28 17:20:38,231:INFO:SubProcess create_model() called ==================================
2024-11-28 17:20:38,231:INFO:Initializing create_model()
2024-11-28 17:20:38,231:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4ADA37640>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4C8FA5420>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:38,231:INFO:Checking exceptions
2024-11-28 17:20:38,231:INFO:Importing libraries
2024-11-28 17:20:38,231:INFO:Copying training dataset
2024-11-28 17:20:38,235:INFO:Defining folds
2024-11-28 17:20:38,235:INFO:Declaring metric variables
2024-11-28 17:20:38,238:INFO:Importing untrained model
2024-11-28 17:20:38,240:INFO:CatBoost Classifier Imported successfully
2024-11-28 17:20:38,247:INFO:Starting cross validation
2024-11-28 17:20:38,248:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:20:44,040:INFO:Calculating mean and std
2024-11-28 17:20:44,045:INFO:Creating metrics dataframe
2024-11-28 17:20:44,050:INFO:Uploading results into container
2024-11-28 17:20:44,051:INFO:Uploading model into container now
2024-11-28 17:20:44,052:INFO:_master_model_container: 15
2024-11-28 17:20:44,052:INFO:_display_container: 2
2024-11-28 17:20:44,052:INFO:<catboost.core.CatBoostClassifier object at 0x000001E4CAD90AF0>
2024-11-28 17:20:44,053:INFO:create_model() successfully completed......................................
2024-11-28 17:20:44,145:INFO:SubProcess create_model() end ==================================
2024-11-28 17:20:44,146:INFO:Creating metrics dataframe
2024-11-28 17:20:44,156:INFO:Initializing Dummy Classifier
2024-11-28 17:20:44,156:INFO:Total runtime is 0.2836119929949442 minutes
2024-11-28 17:20:44,160:INFO:SubProcess create_model() called ==================================
2024-11-28 17:20:44,160:INFO:Initializing create_model()
2024-11-28 17:20:44,160:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4ADA37640>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4C8FA5420>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:44,160:INFO:Checking exceptions
2024-11-28 17:20:44,160:INFO:Importing libraries
2024-11-28 17:20:44,160:INFO:Copying training dataset
2024-11-28 17:20:44,165:INFO:Defining folds
2024-11-28 17:20:44,166:INFO:Declaring metric variables
2024-11-28 17:20:44,168:INFO:Importing untrained model
2024-11-28 17:20:44,172:INFO:Dummy Classifier Imported successfully
2024-11-28 17:20:44,179:INFO:Starting cross validation
2024-11-28 17:20:44,180:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:20:44,259:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:20:44,259:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:20:44,260:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:20:44,266:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:20:44,268:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:20:44,269:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:20:44,323:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:20:44,329:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:20:44,331:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:20:44,335:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:20:44,349:INFO:Calculating mean and std
2024-11-28 17:20:44,353:INFO:Creating metrics dataframe
2024-11-28 17:20:44,362:INFO:Uploading results into container
2024-11-28 17:20:44,364:INFO:Uploading model into container now
2024-11-28 17:20:44,366:INFO:_master_model_container: 16
2024-11-28 17:20:44,366:INFO:_display_container: 2
2024-11-28 17:20:44,367:INFO:DummyClassifier(constant=None, random_state=4503, strategy='prior')
2024-11-28 17:20:44,367:INFO:create_model() successfully completed......................................
2024-11-28 17:20:44,465:INFO:SubProcess create_model() end ==================================
2024-11-28 17:20:44,465:INFO:Creating metrics dataframe
2024-11-28 17:20:44,476:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-11-28 17:20:44,483:INFO:Initializing create_model()
2024-11-28 17:20:44,483:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4ADA37640>, estimator=<catboost.core.CatBoostClassifier object at 0x000001E4CAD90AF0>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:44,483:INFO:Checking exceptions
2024-11-28 17:20:44,485:INFO:Importing libraries
2024-11-28 17:20:44,486:INFO:Copying training dataset
2024-11-28 17:20:44,490:INFO:Defining folds
2024-11-28 17:20:44,490:INFO:Declaring metric variables
2024-11-28 17:20:44,490:INFO:Importing untrained model
2024-11-28 17:20:44,490:INFO:Declaring custom model
2024-11-28 17:20:44,491:INFO:CatBoost Classifier Imported successfully
2024-11-28 17:20:44,492:INFO:Cross validation set to False
2024-11-28 17:20:44,492:INFO:Fitting Model
2024-11-28 17:20:46,025:INFO:<catboost.core.CatBoostClassifier object at 0x000001E4CA9A05E0>
2024-11-28 17:20:46,025:INFO:create_model() successfully completed......................................
2024-11-28 17:20:46,087:INFO:Initializing create_model()
2024-11-28 17:20:46,088:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4ADA37640>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4503, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:46,088:INFO:Checking exceptions
2024-11-28 17:20:46,090:INFO:Importing libraries
2024-11-28 17:20:46,090:INFO:Copying training dataset
2024-11-28 17:20:46,094:INFO:Defining folds
2024-11-28 17:20:46,094:INFO:Declaring metric variables
2024-11-28 17:20:46,094:INFO:Importing untrained model
2024-11-28 17:20:46,094:INFO:Declaring custom model
2024-11-28 17:20:46,094:INFO:Gradient Boosting Classifier Imported successfully
2024-11-28 17:20:46,095:INFO:Cross validation set to False
2024-11-28 17:20:46,095:INFO:Fitting Model
2024-11-28 17:20:46,258:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4503, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-11-28 17:20:46,258:INFO:create_model() successfully completed......................................
2024-11-28 17:20:46,320:INFO:Initializing create_model()
2024-11-28 17:20:46,320:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4ADA37640>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=4503, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:46,320:INFO:Checking exceptions
2024-11-28 17:20:46,322:INFO:Importing libraries
2024-11-28 17:20:46,322:INFO:Copying training dataset
2024-11-28 17:20:46,327:INFO:Defining folds
2024-11-28 17:20:46,327:INFO:Declaring metric variables
2024-11-28 17:20:46,327:INFO:Importing untrained model
2024-11-28 17:20:46,327:INFO:Declaring custom model
2024-11-28 17:20:46,328:INFO:Random Forest Classifier Imported successfully
2024-11-28 17:20:46,329:INFO:Cross validation set to False
2024-11-28 17:20:46,329:INFO:Fitting Model
2024-11-28 17:20:46,488:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=4503, verbose=0,
                       warm_start=False)
2024-11-28 17:20:46,488:INFO:create_model() successfully completed......................................
2024-11-28 17:20:46,551:INFO:Initializing create_model()
2024-11-28 17:20:46,551:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4ADA37640>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:46,551:INFO:Checking exceptions
2024-11-28 17:20:46,553:INFO:Importing libraries
2024-11-28 17:20:46,553:INFO:Copying training dataset
2024-11-28 17:20:46,557:INFO:Defining folds
2024-11-28 17:20:46,557:INFO:Declaring metric variables
2024-11-28 17:20:46,557:INFO:Importing untrained model
2024-11-28 17:20:46,557:INFO:Declaring custom model
2024-11-28 17:20:46,558:INFO:Linear Discriminant Analysis Imported successfully
2024-11-28 17:20:46,559:INFO:Cross validation set to False
2024-11-28 17:20:46,559:INFO:Fitting Model
2024-11-28 17:20:46,593:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-11-28 17:20:46,593:INFO:create_model() successfully completed......................................
2024-11-28 17:20:46,656:INFO:Initializing create_model()
2024-11-28 17:20:46,656:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4ADA37640>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=4503), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:46,656:INFO:Checking exceptions
2024-11-28 17:20:46,659:INFO:Importing libraries
2024-11-28 17:20:46,659:INFO:Copying training dataset
2024-11-28 17:20:46,663:INFO:Defining folds
2024-11-28 17:20:46,663:INFO:Declaring metric variables
2024-11-28 17:20:46,663:INFO:Importing untrained model
2024-11-28 17:20:46,663:INFO:Declaring custom model
2024-11-28 17:20:46,663:INFO:Ada Boost Classifier Imported successfully
2024-11-28 17:20:46,664:INFO:Cross validation set to False
2024-11-28 17:20:46,664:INFO:Fitting Model
2024-11-28 17:20:46,697:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:20:46,767:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=4503)
2024-11-28 17:20:46,767:INFO:create_model() successfully completed......................................
2024-11-28 17:20:46,830:INFO:Initializing create_model()
2024-11-28 17:20:46,830:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4ADA37640>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4503, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:46,831:INFO:Checking exceptions
2024-11-28 17:20:46,833:INFO:Importing libraries
2024-11-28 17:20:46,833:INFO:Copying training dataset
2024-11-28 17:20:46,836:INFO:Defining folds
2024-11-28 17:20:46,836:INFO:Declaring metric variables
2024-11-28 17:20:46,836:INFO:Importing untrained model
2024-11-28 17:20:46,837:INFO:Declaring custom model
2024-11-28 17:20:46,837:INFO:Logistic Regression Imported successfully
2024-11-28 17:20:46,838:INFO:Cross validation set to False
2024-11-28 17:20:46,838:INFO:Fitting Model
2024-11-28 17:20:46,988:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4503, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-11-28 17:20:46,989:INFO:create_model() successfully completed......................................
2024-11-28 17:20:47,051:INFO:Initializing create_model()
2024-11-28 17:20:47,051:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4ADA37640>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=4503, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:47,052:INFO:Checking exceptions
2024-11-28 17:20:47,054:INFO:Importing libraries
2024-11-28 17:20:47,054:INFO:Copying training dataset
2024-11-28 17:20:47,057:INFO:Defining folds
2024-11-28 17:20:47,057:INFO:Declaring metric variables
2024-11-28 17:20:47,057:INFO:Importing untrained model
2024-11-28 17:20:47,057:INFO:Declaring custom model
2024-11-28 17:20:47,058:INFO:Ridge Classifier Imported successfully
2024-11-28 17:20:47,059:INFO:Cross validation set to False
2024-11-28 17:20:47,059:INFO:Fitting Model
2024-11-28 17:20:47,093:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=4503, solver='auto',
                tol=0.0001)
2024-11-28 17:20:47,093:INFO:create_model() successfully completed......................................
2024-11-28 17:20:47,155:INFO:Initializing create_model()
2024-11-28 17:20:47,156:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4ADA37640>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4503, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:47,156:INFO:Checking exceptions
2024-11-28 17:20:47,158:INFO:Importing libraries
2024-11-28 17:20:47,158:INFO:Copying training dataset
2024-11-28 17:20:47,162:INFO:Defining folds
2024-11-28 17:20:47,162:INFO:Declaring metric variables
2024-11-28 17:20:47,162:INFO:Importing untrained model
2024-11-28 17:20:47,162:INFO:Declaring custom model
2024-11-28 17:20:47,163:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-28 17:20:47,164:INFO:Cross validation set to False
2024-11-28 17:20:47,164:INFO:Fitting Model
2024-11-28 17:20:47,199:INFO:[LightGBM] [Info] Number of positive: 239, number of negative: 384
2024-11-28 17:20:47,200:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000087 seconds.
2024-11-28 17:20:47,200:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-11-28 17:20:47,200:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-11-28 17:20:47,200:INFO:[LightGBM] [Info] Total Bins 409
2024-11-28 17:20:47,200:INFO:[LightGBM] [Info] Number of data points in the train set: 623, number of used features: 11
2024-11-28 17:20:47,200:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383628 -> initscore=-0.474179
2024-11-28 17:20:47,200:INFO:[LightGBM] [Info] Start training from score -0.474179
2024-11-28 17:20:47,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:47,235:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4503, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-11-28 17:20:47,235:INFO:create_model() successfully completed......................................
2024-11-28 17:20:47,301:INFO:Initializing create_model()
2024-11-28 17:20:47,301:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4ADA37640>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=4503, verbose=0,
                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:47,301:INFO:Checking exceptions
2024-11-28 17:20:47,303:INFO:Importing libraries
2024-11-28 17:20:47,303:INFO:Copying training dataset
2024-11-28 17:20:47,306:INFO:Defining folds
2024-11-28 17:20:47,306:INFO:Declaring metric variables
2024-11-28 17:20:47,306:INFO:Importing untrained model
2024-11-28 17:20:47,307:INFO:Declaring custom model
2024-11-28 17:20:47,307:INFO:Extra Trees Classifier Imported successfully
2024-11-28 17:20:47,309:INFO:Cross validation set to False
2024-11-28 17:20:47,309:INFO:Fitting Model
2024-11-28 17:20:47,433:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=4503, verbose=0,
                     warm_start=False)
2024-11-28 17:20:47,433:INFO:create_model() successfully completed......................................
2024-11-28 17:20:47,496:INFO:Initializing create_model()
2024-11-28 17:20:47,496:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4ADA37640>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:47,497:INFO:Checking exceptions
2024-11-28 17:20:47,498:INFO:Importing libraries
2024-11-28 17:20:47,498:INFO:Copying training dataset
2024-11-28 17:20:47,502:INFO:Defining folds
2024-11-28 17:20:47,502:INFO:Declaring metric variables
2024-11-28 17:20:47,502:INFO:Importing untrained model
2024-11-28 17:20:47,502:INFO:Declaring custom model
2024-11-28 17:20:47,503:INFO:Extreme Gradient Boosting Imported successfully
2024-11-28 17:20:47,504:INFO:Cross validation set to False
2024-11-28 17:20:47,504:INFO:Fitting Model
2024-11-28 17:20:47,718:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-11-28 17:20:47,718:INFO:create_model() successfully completed......................................
2024-11-28 17:20:47,780:INFO:Initializing create_model()
2024-11-28 17:20:47,781:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4ADA37640>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:47,781:INFO:Checking exceptions
2024-11-28 17:20:47,783:INFO:Importing libraries
2024-11-28 17:20:47,783:INFO:Copying training dataset
2024-11-28 17:20:47,787:INFO:Defining folds
2024-11-28 17:20:47,787:INFO:Declaring metric variables
2024-11-28 17:20:47,787:INFO:Importing untrained model
2024-11-28 17:20:47,787:INFO:Declaring custom model
2024-11-28 17:20:47,787:INFO:Naive Bayes Imported successfully
2024-11-28 17:20:47,788:INFO:Cross validation set to False
2024-11-28 17:20:47,788:INFO:Fitting Model
2024-11-28 17:20:47,823:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-11-28 17:20:47,823:INFO:create_model() successfully completed......................................
2024-11-28 17:20:47,887:INFO:Initializing create_model()
2024-11-28 17:20:47,887:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4ADA37640>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=4503, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:47,887:INFO:Checking exceptions
2024-11-28 17:20:47,889:INFO:Importing libraries
2024-11-28 17:20:47,889:INFO:Copying training dataset
2024-11-28 17:20:47,893:INFO:Defining folds
2024-11-28 17:20:47,894:INFO:Declaring metric variables
2024-11-28 17:20:47,894:INFO:Importing untrained model
2024-11-28 17:20:47,894:INFO:Declaring custom model
2024-11-28 17:20:47,894:INFO:Decision Tree Classifier Imported successfully
2024-11-28 17:20:47,895:INFO:Cross validation set to False
2024-11-28 17:20:47,895:INFO:Fitting Model
2024-11-28 17:20:47,929:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=4503, splitter='best')
2024-11-28 17:20:47,929:INFO:create_model() successfully completed......................................
2024-11-28 17:20:47,990:INFO:Initializing create_model()
2024-11-28 17:20:47,990:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4ADA37640>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:47,990:INFO:Checking exceptions
2024-11-28 17:20:47,992:INFO:Importing libraries
2024-11-28 17:20:47,993:INFO:Copying training dataset
2024-11-28 17:20:47,997:INFO:Defining folds
2024-11-28 17:20:47,997:INFO:Declaring metric variables
2024-11-28 17:20:47,997:INFO:Importing untrained model
2024-11-28 17:20:47,997:INFO:Declaring custom model
2024-11-28 17:20:47,997:INFO:Quadratic Discriminant Analysis Imported successfully
2024-11-28 17:20:47,998:INFO:Cross validation set to False
2024-11-28 17:20:47,998:INFO:Fitting Model
2024-11-28 17:20:48,030:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:20:48,030:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-11-28 17:20:48,031:INFO:create_model() successfully completed......................................
2024-11-28 17:20:48,091:INFO:Initializing create_model()
2024-11-28 17:20:48,091:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4ADA37640>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:48,091:INFO:Checking exceptions
2024-11-28 17:20:48,093:INFO:Importing libraries
2024-11-28 17:20:48,093:INFO:Copying training dataset
2024-11-28 17:20:48,098:INFO:Defining folds
2024-11-28 17:20:48,098:INFO:Declaring metric variables
2024-11-28 17:20:48,099:INFO:Importing untrained model
2024-11-28 17:20:48,099:INFO:Declaring custom model
2024-11-28 17:20:48,099:INFO:K Neighbors Classifier Imported successfully
2024-11-28 17:20:48,100:INFO:Cross validation set to False
2024-11-28 17:20:48,100:INFO:Fitting Model
2024-11-28 17:20:48,133:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-11-28 17:20:48,133:INFO:create_model() successfully completed......................................
2024-11-28 17:20:48,194:INFO:Initializing create_model()
2024-11-28 17:20:48,194:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4ADA37640>, estimator=DummyClassifier(constant=None, random_state=4503, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:48,194:INFO:Checking exceptions
2024-11-28 17:20:48,196:INFO:Importing libraries
2024-11-28 17:20:48,196:INFO:Copying training dataset
2024-11-28 17:20:48,200:INFO:Defining folds
2024-11-28 17:20:48,200:INFO:Declaring metric variables
2024-11-28 17:20:48,200:INFO:Importing untrained model
2024-11-28 17:20:48,200:INFO:Declaring custom model
2024-11-28 17:20:48,201:INFO:Dummy Classifier Imported successfully
2024-11-28 17:20:48,202:INFO:Cross validation set to False
2024-11-28 17:20:48,202:INFO:Fitting Model
2024-11-28 17:20:48,233:INFO:DummyClassifier(constant=None, random_state=4503, strategy='prior')
2024-11-28 17:20:48,233:INFO:create_model() successfully completed......................................
2024-11-28 17:20:48,294:INFO:Initializing create_model()
2024-11-28 17:20:48,294:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4ADA37640>, estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=4503, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:48,294:INFO:Checking exceptions
2024-11-28 17:20:48,296:INFO:Importing libraries
2024-11-28 17:20:48,296:INFO:Copying training dataset
2024-11-28 17:20:48,299:INFO:Defining folds
2024-11-28 17:20:48,300:INFO:Declaring metric variables
2024-11-28 17:20:48,300:INFO:Importing untrained model
2024-11-28 17:20:48,300:INFO:Declaring custom model
2024-11-28 17:20:48,300:INFO:SVM - Linear Kernel Imported successfully
2024-11-28 17:20:48,301:INFO:Cross validation set to False
2024-11-28 17:20:48,301:INFO:Fitting Model
2024-11-28 17:20:48,336:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=4503, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-11-28 17:20:48,336:INFO:create_model() successfully completed......................................
2024-11-28 17:20:48,410:INFO:_master_model_container: 16
2024-11-28 17:20:48,410:INFO:_display_container: 2
2024-11-28 17:20:48,413:INFO:[<catboost.core.CatBoostClassifier object at 0x000001E4CA9A05E0>, GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=4503, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=4503, verbose=0,
                       warm_start=False), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=4503), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=4503, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=4503, solver='auto',
                tol=0.0001), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4503, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=4503, verbose=0,
                     warm_start=False), XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=4503, splitter='best'), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), DummyClassifier(constant=None, random_state=4503, strategy='prior'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=4503, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)]
2024-11-28 17:20:48,413:INFO:compare_models() successfully completed......................................
2024-11-28 17:20:48,459:INFO:Initializing tune_model()
2024-11-28 17:20:48,459:INFO:tune_model(estimator=<catboost.core.CatBoostClassifier object at 0x000001E4CA9A05E0>, fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4ADA37640>)
2024-11-28 17:20:48,459:INFO:Checking exceptions
2024-11-28 17:20:48,498:INFO:Copying training dataset
2024-11-28 17:20:48,501:INFO:Checking base model
2024-11-28 17:20:48,501:INFO:Base model : CatBoost Classifier
2024-11-28 17:20:48,504:INFO:Declaring metric variables
2024-11-28 17:20:48,507:INFO:Defining Hyperparameters
2024-11-28 17:20:48,568:INFO:Tuning with n_jobs=-1
2024-11-28 17:20:48,568:INFO:Initializing RandomizedSearchCV
2024-11-28 17:21:13,024:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\model_selection\_validation.py:547: FitFailedWarning: 
10 fits failed out of a total of 100.
The score on these train-test partitions for these parameters will be set to nan.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\model_selection\_validation.py", line 895, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\pycaret\internal\pipeline.py", line 278, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\joblib\memory.py", line 353, in __call__
    return self.func(*args, **kwargs)
  File "c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\pycaret\internal\pipeline.py", line 69, in _fit_one
    transformer.fit(*args)
  File "c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\catboost\core.py", line 5245, in fit
    self._fit(X, y, cat_features, text_features, embedding_features, None, graph, sample_weight, None, None, None, None, baseline, use_best_model,
  File "c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\catboost\core.py", line 2395, in _fit
    train_params = self._prepare_train_params(
  File "c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\catboost\core.py", line 2321, in _prepare_train_params
    _check_train_params(params)
  File "_catboost.pyx", line 6583, in _catboost._check_train_params
  File "_catboost.pyx", line 6605, in _catboost._check_train_params
_catboost.CatBoostError: catboost/private/libs/options/boosting_options.cpp:79: Learning rate should be non-zero

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2024-11-28 17:21:13,061:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\model_selection\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.78799283 0.80245776 0.80245776 0.8218894  0.81216078 0.81374808
 0.81536098 0.80248336        nan 0.82178699]
  warnings.warn(

2024-11-28 17:21:13,062:INFO:best_params: {'actual_estimator__random_strength': 0.8, 'actual_estimator__n_estimators': 40, 'actual_estimator__l2_leaf_reg': 4, 'actual_estimator__eta': 0.15, 'actual_estimator__depth': 11}
2024-11-28 17:21:13,064:INFO:Hyperparameter search completed
2024-11-28 17:21:13,064:INFO:SubProcess create_model() called ==================================
2024-11-28 17:21:13,064:INFO:Initializing create_model()
2024-11-28 17:21:13,065:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4ADA37640>, estimator=<catboost.core.CatBoostClassifier object at 0x000001E4CA89F7F0>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4ADA6E320>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'random_strength': 0.8, 'n_estimators': 40, 'l2_leaf_reg': 4, 'eta': 0.15, 'depth': 11})
2024-11-28 17:21:13,065:INFO:Checking exceptions
2024-11-28 17:21:13,065:INFO:Importing libraries
2024-11-28 17:21:13,065:INFO:Copying training dataset
2024-11-28 17:21:13,073:INFO:Defining folds
2024-11-28 17:21:13,073:INFO:Declaring metric variables
2024-11-28 17:21:13,076:INFO:Importing untrained model
2024-11-28 17:21:13,076:INFO:Declaring custom model
2024-11-28 17:21:13,080:INFO:CatBoost Classifier Imported successfully
2024-11-28 17:21:13,085:INFO:Starting cross validation
2024-11-28 17:21:13,087:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:21:15,579:INFO:Calculating mean and std
2024-11-28 17:21:15,584:INFO:Creating metrics dataframe
2024-11-28 17:21:15,605:INFO:Finalizing model
2024-11-28 17:21:16,197:INFO:Uploading results into container
2024-11-28 17:21:16,198:INFO:Uploading model into container now
2024-11-28 17:21:16,198:INFO:_master_model_container: 17
2024-11-28 17:21:16,198:INFO:_display_container: 3
2024-11-28 17:21:16,198:INFO:<catboost.core.CatBoostClassifier object at 0x000001E4ADA37940>
2024-11-28 17:21:16,199:INFO:create_model() successfully completed......................................
2024-11-28 17:21:16,255:INFO:SubProcess create_model() end ==================================
2024-11-28 17:21:16,255:INFO:choose_better activated
2024-11-28 17:21:16,258:INFO:SubProcess create_model() called ==================================
2024-11-28 17:21:16,258:INFO:Initializing create_model()
2024-11-28 17:21:16,258:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4ADA37640>, estimator=<catboost.core.CatBoostClassifier object at 0x000001E4CA9A05E0>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:21:16,258:INFO:Checking exceptions
2024-11-28 17:21:16,261:INFO:Importing libraries
2024-11-28 17:21:16,261:INFO:Copying training dataset
2024-11-28 17:21:16,263:INFO:Defining folds
2024-11-28 17:21:16,264:INFO:Declaring metric variables
2024-11-28 17:21:16,264:INFO:Importing untrained model
2024-11-28 17:21:16,264:INFO:Declaring custom model
2024-11-28 17:21:16,264:INFO:CatBoost Classifier Imported successfully
2024-11-28 17:21:16,264:INFO:Starting cross validation
2024-11-28 17:21:16,265:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:21:21,753:INFO:Calculating mean and std
2024-11-28 17:21:21,755:INFO:Creating metrics dataframe
2024-11-28 17:21:21,762:INFO:Finalizing model
2024-11-28 17:21:23,245:INFO:Uploading results into container
2024-11-28 17:21:23,246:INFO:Uploading model into container now
2024-11-28 17:21:23,246:INFO:_master_model_container: 18
2024-11-28 17:21:23,246:INFO:_display_container: 4
2024-11-28 17:21:23,246:INFO:<catboost.core.CatBoostClassifier object at 0x000001E4CA8E6A40>
2024-11-28 17:21:23,246:INFO:create_model() successfully completed......................................
2024-11-28 17:21:23,302:INFO:SubProcess create_model() end ==================================
2024-11-28 17:21:23,302:INFO:<catboost.core.CatBoostClassifier object at 0x000001E4CA8E6A40> result for Accuracy is 0.8234
2024-11-28 17:21:23,302:INFO:<catboost.core.CatBoostClassifier object at 0x000001E4ADA37940> result for Accuracy is 0.8219
2024-11-28 17:21:23,303:INFO:<catboost.core.CatBoostClassifier object at 0x000001E4CA8E6A40> is best model
2024-11-28 17:21:23,303:INFO:choose_better completed
2024-11-28 17:21:23,303:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-11-28 17:21:23,311:INFO:_master_model_container: 18
2024-11-28 17:21:23,311:INFO:_display_container: 3
2024-11-28 17:21:23,311:INFO:<catboost.core.CatBoostClassifier object at 0x000001E4CA8E6A40>
2024-11-28 17:21:23,312:INFO:tune_model() successfully completed......................................
2024-11-28 17:21:23,374:INFO:Initializing evaluate_model()
2024-11-28 17:21:23,374:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4ADA37640>, estimator=<catboost.core.CatBoostClassifier object at 0x000001E4CA8E6A40>, fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-11-28 17:21:23,386:INFO:Initializing plot_model()
2024-11-28 17:21:23,386:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=<catboost.core.CatBoostClassifier object at 0x000001E4CA8E6A40>, feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4ADA37640>, system=True)
2024-11-28 17:21:23,386:INFO:Checking exceptions
2024-11-28 17:21:23,387:INFO:Preloading libraries
2024-11-28 17:21:23,390:INFO:Copying training dataset
2024-11-28 17:21:23,391:INFO:Plot type: pipeline
2024-11-28 17:21:23,535:INFO:Visual Rendered Successfully
2024-11-28 17:21:23,596:INFO:plot_model() successfully completed......................................
2024-11-28 17:21:23,599:INFO:Initializing finalize_model()
2024-11-28 17:21:23,599:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4ADA37640>, estimator=<catboost.core.CatBoostClassifier object at 0x000001E4CA8E6A40>, fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-11-28 17:21:23,599:INFO:Finalizing <catboost.core.CatBoostClassifier object at 0x000001E4CA8E6A40>
2024-11-28 17:21:23,602:INFO:Initializing create_model()
2024-11-28 17:21:23,602:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4ADA37640>, estimator=<catboost.core.CatBoostClassifier object at 0x000001E4CA8E6A40>, fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:21:23,603:INFO:Checking exceptions
2024-11-28 17:21:23,604:INFO:Importing libraries
2024-11-28 17:21:23,604:INFO:Copying training dataset
2024-11-28 17:21:23,604:INFO:Defining folds
2024-11-28 17:21:23,604:INFO:Declaring metric variables
2024-11-28 17:21:23,605:INFO:Importing untrained model
2024-11-28 17:21:23,605:INFO:Declaring custom model
2024-11-28 17:21:23,605:INFO:CatBoost Classifier Imported successfully
2024-11-28 17:21:23,606:INFO:Cross validation set to False
2024-11-28 17:21:23,606:INFO:Fitting Model
2024-11-28 17:21:25,072:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare',
                                             'FamilySize'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper...
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['Embarked'],
                                    transformer=OneHotEncoder(cols=['Embarked'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('actual_estimator',
                 <catboost.core.CatBoostClassifier object at 0x000001E4CAE49870>)],
         verbose=False)
2024-11-28 17:21:25,072:INFO:create_model() successfully completed......................................
2024-11-28 17:21:25,131:INFO:_master_model_container: 18
2024-11-28 17:21:25,131:INFO:_display_container: 3
2024-11-28 17:21:25,145:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare',
                                             'FamilySize'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper...
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['Embarked'],
                                    transformer=OneHotEncoder(cols=['Embarked'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('actual_estimator',
                 <catboost.core.CatBoostClassifier object at 0x000001E4CAE49870>)],
         verbose=False)
2024-11-28 17:21:25,145:INFO:finalize_model() successfully completed......................................
2024-11-28 17:21:25,216:INFO:Initializing predict_model()
2024-11-28 17:21:25,216:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4ADA37640>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare',
                                             'FamilySize'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper...
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['Embarked'],
                                    transformer=OneHotEncoder(cols=['Embarked'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('actual_estimator',
                 <catboost.core.CatBoostClassifier object at 0x000001E4CAE49870>)],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E4DE83F370>)
2024-11-28 17:21:25,216:INFO:Checking exceptions
2024-11-28 17:21:25,216:INFO:Preloading libraries
2024-11-28 17:21:25,218:INFO:Set up data.
2024-11-28 17:21:25,220:INFO:Set up index.
