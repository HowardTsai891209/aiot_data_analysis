2024-11-28 17:19:56,328:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-28 17:19:56,328:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-28 17:19:56,328:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-28 17:19:56,328:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-28 17:19:56,827:INFO:PyCaret ClassificationExperiment
2024-11-28 17:19:56,828:INFO:Logging name: clf-default-name
2024-11-28 17:19:56,828:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-11-28 17:19:56,828:INFO:version 3.3.2
2024-11-28 17:19:56,828:INFO:Initializing setup()
2024-11-28 17:19:56,828:INFO:self.USI: 34c6
2024-11-28 17:19:56,828:INFO:self._variable_keys: {'exp_name_log', 'y_train', 'logging_param', 'y_test', 'is_multiclass', 'X_train', 'USI', 'fold_groups_param', 'data', '_ml_usecase', 'exp_id', 'target_param', 'fold_shuffle_param', 'html_param', 'X', 'memory', 'y', 'X_test', 'pipeline', 'fix_imbalance', '_available_plots', 'gpu_n_jobs_param', 'log_plots_param', 'idx', 'fold_generator', 'seed', 'n_jobs_param', 'gpu_param'}
2024-11-28 17:19:56,828:INFO:Checking environment
2024-11-28 17:19:56,828:INFO:python_version: 3.10.11
2024-11-28 17:19:56,828:INFO:python_build: ('tags/v3.10.11:7d4cc5a', 'Apr  5 2023 00:38:17')
2024-11-28 17:19:56,828:INFO:machine: AMD64
2024-11-28 17:19:56,828:INFO:platform: Windows-10-10.0.19045-SP0
2024-11-28 17:19:56,831:INFO:Memory: svmem(total=34216488960, available=22115512320, percent=35.4, used=12100976640, free=22115512320)
2024-11-28 17:19:56,831:INFO:Physical Core: 6
2024-11-28 17:19:56,831:INFO:Logical Core: 6
2024-11-28 17:19:56,831:INFO:Checking libraries
2024-11-28 17:19:56,831:INFO:System:
2024-11-28 17:19:56,831:INFO:    python: 3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]
2024-11-28 17:19:56,831:INFO:executable: c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\Scripts\python.exe
2024-11-28 17:19:56,831:INFO:   machine: Windows-10-10.0.19045-SP0
2024-11-28 17:19:56,831:INFO:PyCaret required dependencies:
2024-11-28 17:19:56,870:INFO:                 pip: 23.0.1
2024-11-28 17:19:56,870:INFO:          setuptools: 65.5.0
2024-11-28 17:19:56,870:INFO:             pycaret: 3.3.2
2024-11-28 17:19:56,870:INFO:             IPython: 8.29.0
2024-11-28 17:19:56,870:INFO:          ipywidgets: 8.1.5
2024-11-28 17:19:56,870:INFO:                tqdm: 4.67.1
2024-11-28 17:19:56,870:INFO:               numpy: 1.26.4
2024-11-28 17:19:56,870:INFO:              pandas: 2.1.4
2024-11-28 17:19:56,870:INFO:              jinja2: 3.1.4
2024-11-28 17:19:56,870:INFO:               scipy: 1.11.4
2024-11-28 17:19:56,870:INFO:              joblib: 1.3.2
2024-11-28 17:19:56,870:INFO:             sklearn: 1.4.2
2024-11-28 17:19:56,870:INFO:                pyod: 2.0.2
2024-11-28 17:19:56,871:INFO:            imblearn: 0.12.4
2024-11-28 17:19:56,871:INFO:   category_encoders: 2.6.4
2024-11-28 17:19:56,871:INFO:            lightgbm: 4.5.0
2024-11-28 17:19:56,871:INFO:               numba: 0.60.0
2024-11-28 17:19:56,871:INFO:            requests: 2.32.3
2024-11-28 17:19:56,871:INFO:          matplotlib: 3.7.5
2024-11-28 17:19:56,871:INFO:          scikitplot: 0.3.7
2024-11-28 17:19:56,871:INFO:         yellowbrick: 1.5
2024-11-28 17:19:56,871:INFO:              plotly: 5.24.1
2024-11-28 17:19:56,871:INFO:    plotly-resampler: Not installed
2024-11-28 17:19:56,871:INFO:             kaleido: 0.2.1
2024-11-28 17:19:56,871:INFO:           schemdraw: 0.15
2024-11-28 17:19:56,871:INFO:         statsmodels: 0.14.4
2024-11-28 17:19:56,871:INFO:              sktime: 0.26.0
2024-11-28 17:19:56,871:INFO:               tbats: 1.1.3
2024-11-28 17:19:56,871:INFO:            pmdarima: 2.0.4
2024-11-28 17:19:56,871:INFO:              psutil: 6.1.0
2024-11-28 17:19:56,871:INFO:          markupsafe: 3.0.2
2024-11-28 17:19:56,871:INFO:             pickle5: Not installed
2024-11-28 17:19:56,871:INFO:         cloudpickle: 3.1.0
2024-11-28 17:19:56,871:INFO:         deprecation: 2.1.0
2024-11-28 17:19:56,871:INFO:              xxhash: 3.5.0
2024-11-28 17:19:56,871:INFO:           wurlitzer: Not installed
2024-11-28 17:19:56,871:INFO:PyCaret optional dependencies:
2024-11-28 17:19:56,905:INFO:                shap: Not installed
2024-11-28 17:19:56,905:INFO:           interpret: Not installed
2024-11-28 17:19:56,905:INFO:                umap: Not installed
2024-11-28 17:19:56,905:INFO:     ydata_profiling: Not installed
2024-11-28 17:19:56,905:INFO:  explainerdashboard: Not installed
2024-11-28 17:19:56,905:INFO:             autoviz: Not installed
2024-11-28 17:19:56,905:INFO:           fairlearn: Not installed
2024-11-28 17:19:56,905:INFO:          deepchecks: Not installed
2024-11-28 17:19:56,905:INFO:             xgboost: 2.1.3
2024-11-28 17:19:56,905:INFO:            catboost: 1.2.7
2024-11-28 17:19:56,905:INFO:              kmodes: Not installed
2024-11-28 17:19:56,905:INFO:             mlxtend: 0.23.3
2024-11-28 17:19:56,905:INFO:       statsforecast: Not installed
2024-11-28 17:19:56,905:INFO:        tune_sklearn: Not installed
2024-11-28 17:19:56,905:INFO:                 ray: Not installed
2024-11-28 17:19:56,905:INFO:            hyperopt: Not installed
2024-11-28 17:19:56,905:INFO:              optuna: Not installed
2024-11-28 17:19:56,905:INFO:               skopt: Not installed
2024-11-28 17:19:56,905:INFO:              mlflow: Not installed
2024-11-28 17:19:56,905:INFO:              gradio: Not installed
2024-11-28 17:19:56,905:INFO:             fastapi: Not installed
2024-11-28 17:19:56,905:INFO:             uvicorn: Not installed
2024-11-28 17:19:56,905:INFO:              m2cgen: Not installed
2024-11-28 17:19:56,905:INFO:           evidently: Not installed
2024-11-28 17:19:56,905:INFO:               fugue: Not installed
2024-11-28 17:19:56,906:INFO:           streamlit: 1.39.0
2024-11-28 17:19:56,906:INFO:             prophet: Not installed
2024-11-28 17:19:56,906:INFO:None
2024-11-28 17:19:56,906:INFO:Set up data.
2024-11-28 17:19:56,910:INFO:Set up folding strategy.
2024-11-28 17:19:56,911:INFO:Set up train/test split.
2024-11-28 17:19:56,917:INFO:Set up index.
2024-11-28 17:19:56,917:INFO:Assigning column types.
2024-11-28 17:19:56,920:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-28 17:19:56,963:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-28 17:19:56,967:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-28 17:19:56,999:INFO:Soft dependency imported: xgboost: 2.1.3
2024-11-28 17:19:57,002:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-28 17:19:57,061:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-28 17:19:57,062:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-28 17:19:57,086:INFO:Soft dependency imported: xgboost: 2.1.3
2024-11-28 17:19:57,088:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-28 17:19:57,089:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-28 17:19:57,130:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-28 17:19:57,154:INFO:Soft dependency imported: xgboost: 2.1.3
2024-11-28 17:19:57,156:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-28 17:19:57,196:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-28 17:19:57,220:INFO:Soft dependency imported: xgboost: 2.1.3
2024-11-28 17:19:57,222:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-28 17:19:57,223:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-11-28 17:19:57,285:INFO:Soft dependency imported: xgboost: 2.1.3
2024-11-28 17:19:57,287:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-28 17:19:57,351:INFO:Soft dependency imported: xgboost: 2.1.3
2024-11-28 17:19:57,353:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-28 17:19:57,355:INFO:Preparing preprocessing pipeline...
2024-11-28 17:19:57,356:INFO:Set up simple imputation.
2024-11-28 17:19:57,358:INFO:Set up encoding of ordinal features.
2024-11-28 17:19:57,359:INFO:Set up encoding of categorical features.
2024-11-28 17:19:57,414:INFO:Finished creating preprocessing pipeline.
2024-11-28 17:19:57,430:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\tsai\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare',
                                             'FamilySize', 'IsAlone'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='m...
                                                               mapping=[{'col': 'Sex',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['Embarked'],
                                    transformer=OneHotEncoder(cols=['Embarked'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-11-28 17:19:57,430:INFO:Creating final display dataframe.
2024-11-28 17:19:57,597:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          Survived
2                   Target type            Binary
3           Original data shape         (891, 11)
4        Transformed data shape         (891, 13)
5   Transformed train set shape         (623, 13)
6    Transformed test set shape         (268, 13)
7              Numeric features                 8
8          Categorical features                 2
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              34c6
2024-11-28 17:19:57,668:INFO:Soft dependency imported: xgboost: 2.1.3
2024-11-28 17:19:57,671:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-28 17:19:57,733:INFO:Soft dependency imported: xgboost: 2.1.3
2024-11-28 17:19:57,735:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-28 17:19:57,736:INFO:setup() successfully completed in 0.91s...............
2024-11-28 17:19:57,737:INFO:Initializing compare_models()
2024-11-28 17:19:57,737:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001899CF0ABC0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=16, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001899CF0ABC0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 16, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-11-28 17:19:57,737:INFO:Checking exceptions
2024-11-28 17:19:57,739:INFO:Preparing display monitor
2024-11-28 17:19:57,761:INFO:Initializing Logistic Regression
2024-11-28 17:19:57,761:INFO:Total runtime is 0.0 minutes
2024-11-28 17:19:57,764:INFO:SubProcess create_model() called ==================================
2024-11-28 17:19:57,765:INFO:Initializing create_model()
2024-11-28 17:19:57,765:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001899CF0ABC0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000189BA2AFAF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:19:57,765:INFO:Checking exceptions
2024-11-28 17:19:57,765:INFO:Importing libraries
2024-11-28 17:19:57,765:INFO:Copying training dataset
2024-11-28 17:19:57,770:INFO:Defining folds
2024-11-28 17:19:57,770:INFO:Declaring metric variables
2024-11-28 17:19:57,773:INFO:Importing untrained model
2024-11-28 17:19:57,776:INFO:Logistic Regression Imported successfully
2024-11-28 17:19:57,783:INFO:Starting cross validation
2024-11-28 17:19:57,784:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:20:01,137:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:20:01,163:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:20:01,186:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:20:01,256:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:20:01,348:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:20:01,405:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:20:01,450:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:20:01,456:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:20:01,506:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:20:01,509:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:20:01,550:INFO:Calculating mean and std
2024-11-28 17:20:01,551:INFO:Creating metrics dataframe
2024-11-28 17:20:01,553:INFO:Uploading results into container
2024-11-28 17:20:01,554:INFO:Uploading model into container now
2024-11-28 17:20:01,554:INFO:_master_model_container: 1
2024-11-28 17:20:01,554:INFO:_display_container: 2
2024-11-28 17:20:01,555:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-11-28 17:20:01,555:INFO:create_model() successfully completed......................................
2024-11-28 17:20:01,617:INFO:SubProcess create_model() end ==================================
2024-11-28 17:20:01,618:INFO:Creating metrics dataframe
2024-11-28 17:20:01,623:INFO:Initializing K Neighbors Classifier
2024-11-28 17:20:01,623:INFO:Total runtime is 0.06436109145482381 minutes
2024-11-28 17:20:01,625:INFO:SubProcess create_model() called ==================================
2024-11-28 17:20:01,626:INFO:Initializing create_model()
2024-11-28 17:20:01,626:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001899CF0ABC0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000189BA2AFAF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:01,626:INFO:Checking exceptions
2024-11-28 17:20:01,626:INFO:Importing libraries
2024-11-28 17:20:01,626:INFO:Copying training dataset
2024-11-28 17:20:01,630:INFO:Defining folds
2024-11-28 17:20:01,630:INFO:Declaring metric variables
2024-11-28 17:20:01,632:INFO:Importing untrained model
2024-11-28 17:20:01,635:INFO:K Neighbors Classifier Imported successfully
2024-11-28 17:20:01,640:INFO:Starting cross validation
2024-11-28 17:20:01,642:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:20:01,984:INFO:Calculating mean and std
2024-11-28 17:20:01,986:INFO:Creating metrics dataframe
2024-11-28 17:20:01,990:INFO:Uploading results into container
2024-11-28 17:20:01,991:INFO:Uploading model into container now
2024-11-28 17:20:01,991:INFO:_master_model_container: 2
2024-11-28 17:20:01,991:INFO:_display_container: 2
2024-11-28 17:20:01,992:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-11-28 17:20:01,992:INFO:create_model() successfully completed......................................
2024-11-28 17:20:02,053:INFO:SubProcess create_model() end ==================================
2024-11-28 17:20:02,053:INFO:Creating metrics dataframe
2024-11-28 17:20:02,059:INFO:Initializing Naive Bayes
2024-11-28 17:20:02,059:INFO:Total runtime is 0.0716377337773641 minutes
2024-11-28 17:20:02,062:INFO:SubProcess create_model() called ==================================
2024-11-28 17:20:02,062:INFO:Initializing create_model()
2024-11-28 17:20:02,062:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001899CF0ABC0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000189BA2AFAF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:02,063:INFO:Checking exceptions
2024-11-28 17:20:02,063:INFO:Importing libraries
2024-11-28 17:20:02,063:INFO:Copying training dataset
2024-11-28 17:20:02,067:INFO:Defining folds
2024-11-28 17:20:02,067:INFO:Declaring metric variables
2024-11-28 17:20:02,069:INFO:Importing untrained model
2024-11-28 17:20:02,071:INFO:Naive Bayes Imported successfully
2024-11-28 17:20:02,079:INFO:Starting cross validation
2024-11-28 17:20:02,081:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:20:02,312:INFO:Calculating mean and std
2024-11-28 17:20:02,316:INFO:Creating metrics dataframe
2024-11-28 17:20:02,323:INFO:Uploading results into container
2024-11-28 17:20:02,325:INFO:Uploading model into container now
2024-11-28 17:20:02,326:INFO:_master_model_container: 3
2024-11-28 17:20:02,327:INFO:_display_container: 2
2024-11-28 17:20:02,328:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-11-28 17:20:02,329:INFO:create_model() successfully completed......................................
2024-11-28 17:20:02,432:INFO:SubProcess create_model() end ==================================
2024-11-28 17:20:02,432:INFO:Creating metrics dataframe
2024-11-28 17:20:02,447:INFO:Initializing Decision Tree Classifier
2024-11-28 17:20:02,447:INFO:Total runtime is 0.0781023661295573 minutes
2024-11-28 17:20:02,450:INFO:SubProcess create_model() called ==================================
2024-11-28 17:20:02,450:INFO:Initializing create_model()
2024-11-28 17:20:02,450:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001899CF0ABC0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000189BA2AFAF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:02,450:INFO:Checking exceptions
2024-11-28 17:20:02,451:INFO:Importing libraries
2024-11-28 17:20:02,451:INFO:Copying training dataset
2024-11-28 17:20:02,455:INFO:Defining folds
2024-11-28 17:20:02,456:INFO:Declaring metric variables
2024-11-28 17:20:02,460:INFO:Importing untrained model
2024-11-28 17:20:02,463:INFO:Decision Tree Classifier Imported successfully
2024-11-28 17:20:02,471:INFO:Starting cross validation
2024-11-28 17:20:02,473:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:20:02,670:INFO:Calculating mean and std
2024-11-28 17:20:02,671:INFO:Creating metrics dataframe
2024-11-28 17:20:02,673:INFO:Uploading results into container
2024-11-28 17:20:02,673:INFO:Uploading model into container now
2024-11-28 17:20:02,674:INFO:_master_model_container: 4
2024-11-28 17:20:02,674:INFO:_display_container: 2
2024-11-28 17:20:02,674:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2024-11-28 17:20:02,674:INFO:create_model() successfully completed......................................
2024-11-28 17:20:02,750:INFO:SubProcess create_model() end ==================================
2024-11-28 17:20:02,750:INFO:Creating metrics dataframe
2024-11-28 17:20:02,757:INFO:Initializing SVM - Linear Kernel
2024-11-28 17:20:02,757:INFO:Total runtime is 0.08327184915542604 minutes
2024-11-28 17:20:02,761:INFO:SubProcess create_model() called ==================================
2024-11-28 17:20:02,761:INFO:Initializing create_model()
2024-11-28 17:20:02,761:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001899CF0ABC0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000189BA2AFAF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:02,761:INFO:Checking exceptions
2024-11-28 17:20:02,761:INFO:Importing libraries
2024-11-28 17:20:02,761:INFO:Copying training dataset
2024-11-28 17:20:02,766:INFO:Defining folds
2024-11-28 17:20:02,767:INFO:Declaring metric variables
2024-11-28 17:20:02,769:INFO:Importing untrained model
2024-11-28 17:20:02,773:INFO:SVM - Linear Kernel Imported successfully
2024-11-28 17:20:02,781:INFO:Starting cross validation
2024-11-28 17:20:02,782:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:20:03,013:INFO:Calculating mean and std
2024-11-28 17:20:03,015:INFO:Creating metrics dataframe
2024-11-28 17:20:03,025:INFO:Uploading results into container
2024-11-28 17:20:03,029:INFO:Uploading model into container now
2024-11-28 17:20:03,030:INFO:_master_model_container: 5
2024-11-28 17:20:03,031:INFO:_display_container: 2
2024-11-28 17:20:03,032:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-11-28 17:20:03,033:INFO:create_model() successfully completed......................................
2024-11-28 17:20:03,126:INFO:SubProcess create_model() end ==================================
2024-11-28 17:20:03,127:INFO:Creating metrics dataframe
2024-11-28 17:20:03,133:INFO:Initializing Ridge Classifier
2024-11-28 17:20:03,133:INFO:Total runtime is 0.08952866395314536 minutes
2024-11-28 17:20:03,136:INFO:SubProcess create_model() called ==================================
2024-11-28 17:20:03,137:INFO:Initializing create_model()
2024-11-28 17:20:03,137:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001899CF0ABC0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000189BA2AFAF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:03,137:INFO:Checking exceptions
2024-11-28 17:20:03,137:INFO:Importing libraries
2024-11-28 17:20:03,137:INFO:Copying training dataset
2024-11-28 17:20:03,142:INFO:Defining folds
2024-11-28 17:20:03,142:INFO:Declaring metric variables
2024-11-28 17:20:03,145:INFO:Importing untrained model
2024-11-28 17:20:03,148:INFO:Ridge Classifier Imported successfully
2024-11-28 17:20:03,157:INFO:Starting cross validation
2024-11-28 17:20:03,158:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:20:03,371:INFO:Calculating mean and std
2024-11-28 17:20:03,373:INFO:Creating metrics dataframe
2024-11-28 17:20:03,382:INFO:Uploading results into container
2024-11-28 17:20:03,384:INFO:Uploading model into container now
2024-11-28 17:20:03,386:INFO:_master_model_container: 6
2024-11-28 17:20:03,387:INFO:_display_container: 2
2024-11-28 17:20:03,388:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-11-28 17:20:03,389:INFO:create_model() successfully completed......................................
2024-11-28 17:20:03,501:INFO:SubProcess create_model() end ==================================
2024-11-28 17:20:03,501:INFO:Creating metrics dataframe
2024-11-28 17:20:03,510:INFO:Initializing Random Forest Classifier
2024-11-28 17:20:03,510:INFO:Total runtime is 0.09582051436106366 minutes
2024-11-28 17:20:03,514:INFO:SubProcess create_model() called ==================================
2024-11-28 17:20:03,515:INFO:Initializing create_model()
2024-11-28 17:20:03,515:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001899CF0ABC0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000189BA2AFAF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:03,515:INFO:Checking exceptions
2024-11-28 17:20:03,515:INFO:Importing libraries
2024-11-28 17:20:03,515:INFO:Copying training dataset
2024-11-28 17:20:03,520:INFO:Defining folds
2024-11-28 17:20:03,520:INFO:Declaring metric variables
2024-11-28 17:20:03,523:INFO:Importing untrained model
2024-11-28 17:20:03,528:INFO:Random Forest Classifier Imported successfully
2024-11-28 17:20:03,536:INFO:Starting cross validation
2024-11-28 17:20:03,537:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:20:04,250:INFO:Calculating mean and std
2024-11-28 17:20:04,250:INFO:Creating metrics dataframe
2024-11-28 17:20:04,252:INFO:Uploading results into container
2024-11-28 17:20:04,253:INFO:Uploading model into container now
2024-11-28 17:20:04,253:INFO:_master_model_container: 7
2024-11-28 17:20:04,253:INFO:_display_container: 2
2024-11-28 17:20:04,253:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-11-28 17:20:04,254:INFO:create_model() successfully completed......................................
2024-11-28 17:20:04,312:INFO:SubProcess create_model() end ==================================
2024-11-28 17:20:04,312:INFO:Creating metrics dataframe
2024-11-28 17:20:04,319:INFO:Initializing Quadratic Discriminant Analysis
2024-11-28 17:20:04,319:INFO:Total runtime is 0.10930047829945884 minutes
2024-11-28 17:20:04,322:INFO:SubProcess create_model() called ==================================
2024-11-28 17:20:04,323:INFO:Initializing create_model()
2024-11-28 17:20:04,323:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001899CF0ABC0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000189BA2AFAF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:04,323:INFO:Checking exceptions
2024-11-28 17:20:04,323:INFO:Importing libraries
2024-11-28 17:20:04,323:INFO:Copying training dataset
2024-11-28 17:20:04,327:INFO:Defining folds
2024-11-28 17:20:04,328:INFO:Declaring metric variables
2024-11-28 17:20:04,330:INFO:Importing untrained model
2024-11-28 17:20:04,333:INFO:Quadratic Discriminant Analysis Imported successfully
2024-11-28 17:20:04,339:INFO:Starting cross validation
2024-11-28 17:20:04,340:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:20:04,401:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:20:04,401:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:20:04,403:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:20:04,405:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:20:04,419:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:20:04,477:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:20:04,477:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:20:04,481:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:20:04,486:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:20:04,530:INFO:Calculating mean and std
2024-11-28 17:20:04,533:INFO:Creating metrics dataframe
2024-11-28 17:20:04,538:INFO:Uploading results into container
2024-11-28 17:20:04,539:INFO:Uploading model into container now
2024-11-28 17:20:04,540:INFO:_master_model_container: 8
2024-11-28 17:20:04,540:INFO:_display_container: 2
2024-11-28 17:20:04,541:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-11-28 17:20:04,541:INFO:create_model() successfully completed......................................
2024-11-28 17:20:04,645:INFO:SubProcess create_model() end ==================================
2024-11-28 17:20:04,645:INFO:Creating metrics dataframe
2024-11-28 17:20:04,654:INFO:Initializing Ada Boost Classifier
2024-11-28 17:20:04,654:INFO:Total runtime is 0.11488857269287112 minutes
2024-11-28 17:20:04,657:INFO:SubProcess create_model() called ==================================
2024-11-28 17:20:04,658:INFO:Initializing create_model()
2024-11-28 17:20:04,658:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001899CF0ABC0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000189BA2AFAF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:04,658:INFO:Checking exceptions
2024-11-28 17:20:04,659:INFO:Importing libraries
2024-11-28 17:20:04,659:INFO:Copying training dataset
2024-11-28 17:20:04,663:INFO:Defining folds
2024-11-28 17:20:04,664:INFO:Declaring metric variables
2024-11-28 17:20:04,666:INFO:Importing untrained model
2024-11-28 17:20:04,670:INFO:Ada Boost Classifier Imported successfully
2024-11-28 17:20:04,676:INFO:Starting cross validation
2024-11-28 17:20:04,677:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:20:04,725:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:20:04,732:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:20:04,733:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:20:04,734:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:20:04,738:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:20:04,739:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:20:04,897:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:20:04,897:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:20:04,897:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:20:04,899:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:20:05,024:INFO:Calculating mean and std
2024-11-28 17:20:05,028:INFO:Creating metrics dataframe
2024-11-28 17:20:05,033:INFO:Uploading results into container
2024-11-28 17:20:05,035:INFO:Uploading model into container now
2024-11-28 17:20:05,036:INFO:_master_model_container: 9
2024-11-28 17:20:05,037:INFO:_display_container: 2
2024-11-28 17:20:05,038:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2024-11-28 17:20:05,039:INFO:create_model() successfully completed......................................
2024-11-28 17:20:05,137:INFO:SubProcess create_model() end ==================================
2024-11-28 17:20:05,137:INFO:Creating metrics dataframe
2024-11-28 17:20:05,150:INFO:Initializing Gradient Boosting Classifier
2024-11-28 17:20:05,151:INFO:Total runtime is 0.12316307226816815 minutes
2024-11-28 17:20:05,155:INFO:SubProcess create_model() called ==================================
2024-11-28 17:20:05,155:INFO:Initializing create_model()
2024-11-28 17:20:05,155:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001899CF0ABC0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000189BA2AFAF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:05,155:INFO:Checking exceptions
2024-11-28 17:20:05,155:INFO:Importing libraries
2024-11-28 17:20:05,155:INFO:Copying training dataset
2024-11-28 17:20:05,161:INFO:Defining folds
2024-11-28 17:20:05,161:INFO:Declaring metric variables
2024-11-28 17:20:05,165:INFO:Importing untrained model
2024-11-28 17:20:05,168:INFO:Gradient Boosting Classifier Imported successfully
2024-11-28 17:20:05,174:INFO:Starting cross validation
2024-11-28 17:20:05,175:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:20:05,610:INFO:Calculating mean and std
2024-11-28 17:20:05,611:INFO:Creating metrics dataframe
2024-11-28 17:20:05,613:INFO:Uploading results into container
2024-11-28 17:20:05,613:INFO:Uploading model into container now
2024-11-28 17:20:05,613:INFO:_master_model_container: 10
2024-11-28 17:20:05,614:INFO:_display_container: 2
2024-11-28 17:20:05,614:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-11-28 17:20:05,614:INFO:create_model() successfully completed......................................
2024-11-28 17:20:05,672:INFO:SubProcess create_model() end ==================================
2024-11-28 17:20:05,672:INFO:Creating metrics dataframe
2024-11-28 17:20:05,680:INFO:Initializing Linear Discriminant Analysis
2024-11-28 17:20:05,680:INFO:Total runtime is 0.13198636770248415 minutes
2024-11-28 17:20:05,682:INFO:SubProcess create_model() called ==================================
2024-11-28 17:20:05,683:INFO:Initializing create_model()
2024-11-28 17:20:05,683:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001899CF0ABC0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000189BA2AFAF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:05,683:INFO:Checking exceptions
2024-11-28 17:20:05,683:INFO:Importing libraries
2024-11-28 17:20:05,683:INFO:Copying training dataset
2024-11-28 17:20:05,687:INFO:Defining folds
2024-11-28 17:20:05,687:INFO:Declaring metric variables
2024-11-28 17:20:05,689:INFO:Importing untrained model
2024-11-28 17:20:05,692:INFO:Linear Discriminant Analysis Imported successfully
2024-11-28 17:20:05,699:INFO:Starting cross validation
2024-11-28 17:20:05,700:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:20:05,890:INFO:Calculating mean and std
2024-11-28 17:20:05,894:INFO:Creating metrics dataframe
2024-11-28 17:20:05,899:INFO:Uploading results into container
2024-11-28 17:20:05,901:INFO:Uploading model into container now
2024-11-28 17:20:05,902:INFO:_master_model_container: 11
2024-11-28 17:20:05,902:INFO:_display_container: 2
2024-11-28 17:20:05,903:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-11-28 17:20:05,903:INFO:create_model() successfully completed......................................
2024-11-28 17:20:06,006:INFO:SubProcess create_model() end ==================================
2024-11-28 17:20:06,006:INFO:Creating metrics dataframe
2024-11-28 17:20:06,015:INFO:Initializing Extra Trees Classifier
2024-11-28 17:20:06,015:INFO:Total runtime is 0.1375730832417806 minutes
2024-11-28 17:20:06,018:INFO:SubProcess create_model() called ==================================
2024-11-28 17:20:06,018:INFO:Initializing create_model()
2024-11-28 17:20:06,019:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001899CF0ABC0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000189BA2AFAF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:06,019:INFO:Checking exceptions
2024-11-28 17:20:06,019:INFO:Importing libraries
2024-11-28 17:20:06,019:INFO:Copying training dataset
2024-11-28 17:20:06,023:INFO:Defining folds
2024-11-28 17:20:06,023:INFO:Declaring metric variables
2024-11-28 17:20:06,027:INFO:Importing untrained model
2024-11-28 17:20:06,030:INFO:Extra Trees Classifier Imported successfully
2024-11-28 17:20:06,036:INFO:Starting cross validation
2024-11-28 17:20:06,037:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:20:06,599:INFO:Calculating mean and std
2024-11-28 17:20:06,600:INFO:Creating metrics dataframe
2024-11-28 17:20:06,603:INFO:Uploading results into container
2024-11-28 17:20:06,603:INFO:Uploading model into container now
2024-11-28 17:20:06,604:INFO:_master_model_container: 12
2024-11-28 17:20:06,604:INFO:_display_container: 2
2024-11-28 17:20:06,604:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-11-28 17:20:06,605:INFO:create_model() successfully completed......................................
2024-11-28 17:20:06,671:INFO:SubProcess create_model() end ==================================
2024-11-28 17:20:06,671:INFO:Creating metrics dataframe
2024-11-28 17:20:06,681:INFO:Initializing Extreme Gradient Boosting
2024-11-28 17:20:06,681:INFO:Total runtime is 0.14866984287897747 minutes
2024-11-28 17:20:06,685:INFO:SubProcess create_model() called ==================================
2024-11-28 17:20:06,685:INFO:Initializing create_model()
2024-11-28 17:20:06,685:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001899CF0ABC0>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000189BA2AFAF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:06,685:INFO:Checking exceptions
2024-11-28 17:20:06,685:INFO:Importing libraries
2024-11-28 17:20:06,685:INFO:Copying training dataset
2024-11-28 17:20:06,689:INFO:Defining folds
2024-11-28 17:20:06,689:INFO:Declaring metric variables
2024-11-28 17:20:06,692:INFO:Importing untrained model
2024-11-28 17:20:06,698:INFO:Extreme Gradient Boosting Imported successfully
2024-11-28 17:20:06,704:INFO:Starting cross validation
2024-11-28 17:20:06,706:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:20:07,423:INFO:Calculating mean and std
2024-11-28 17:20:07,428:INFO:Creating metrics dataframe
2024-11-28 17:20:07,436:INFO:Uploading results into container
2024-11-28 17:20:07,438:INFO:Uploading model into container now
2024-11-28 17:20:07,440:INFO:_master_model_container: 13
2024-11-28 17:20:07,440:INFO:_display_container: 2
2024-11-28 17:20:07,446:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-11-28 17:20:07,448:INFO:create_model() successfully completed......................................
2024-11-28 17:20:07,577:INFO:SubProcess create_model() end ==================================
2024-11-28 17:20:07,577:INFO:Creating metrics dataframe
2024-11-28 17:20:07,587:INFO:Initializing Light Gradient Boosting Machine
2024-11-28 17:20:07,587:INFO:Total runtime is 0.16377012729644777 minutes
2024-11-28 17:20:07,590:INFO:SubProcess create_model() called ==================================
2024-11-28 17:20:07,590:INFO:Initializing create_model()
2024-11-28 17:20:07,590:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001899CF0ABC0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000189BA2AFAF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:07,590:INFO:Checking exceptions
2024-11-28 17:20:07,590:INFO:Importing libraries
2024-11-28 17:20:07,590:INFO:Copying training dataset
2024-11-28 17:20:07,595:INFO:Defining folds
2024-11-28 17:20:07,596:INFO:Declaring metric variables
2024-11-28 17:20:07,598:INFO:Importing untrained model
2024-11-28 17:20:07,602:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-28 17:20:07,609:INFO:Starting cross validation
2024-11-28 17:20:07,610:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:20:08,272:INFO:Calculating mean and std
2024-11-28 17:20:08,273:INFO:Creating metrics dataframe
2024-11-28 17:20:08,277:INFO:Uploading results into container
2024-11-28 17:20:08,277:INFO:Uploading model into container now
2024-11-28 17:20:08,277:INFO:_master_model_container: 14
2024-11-28 17:20:08,277:INFO:_display_container: 2
2024-11-28 17:20:08,278:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-11-28 17:20:08,278:INFO:create_model() successfully completed......................................
2024-11-28 17:20:08,336:INFO:SubProcess create_model() end ==================================
2024-11-28 17:20:08,336:INFO:Creating metrics dataframe
2024-11-28 17:20:08,345:INFO:Initializing CatBoost Classifier
2024-11-28 17:20:08,345:INFO:Total runtime is 0.17640165487925213 minutes
2024-11-28 17:20:08,348:INFO:SubProcess create_model() called ==================================
2024-11-28 17:20:08,348:INFO:Initializing create_model()
2024-11-28 17:20:08,348:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001899CF0ABC0>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000189BA2AFAF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:08,348:INFO:Checking exceptions
2024-11-28 17:20:08,348:INFO:Importing libraries
2024-11-28 17:20:08,348:INFO:Copying training dataset
2024-11-28 17:20:08,352:INFO:Defining folds
2024-11-28 17:20:08,353:INFO:Declaring metric variables
2024-11-28 17:20:08,383:INFO:Importing untrained model
2024-11-28 17:20:08,387:INFO:CatBoost Classifier Imported successfully
2024-11-28 17:20:08,404:INFO:Starting cross validation
2024-11-28 17:20:08,406:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:20:14,162:INFO:Calculating mean and std
2024-11-28 17:20:14,164:INFO:Creating metrics dataframe
2024-11-28 17:20:14,170:INFO:Uploading results into container
2024-11-28 17:20:14,171:INFO:Uploading model into container now
2024-11-28 17:20:14,173:INFO:_master_model_container: 15
2024-11-28 17:20:14,173:INFO:_display_container: 2
2024-11-28 17:20:14,174:INFO:<catboost.core.CatBoostClassifier object at 0x00000189B9E08D00>
2024-11-28 17:20:14,174:INFO:create_model() successfully completed......................................
2024-11-28 17:20:14,295:INFO:SubProcess create_model() end ==================================
2024-11-28 17:20:14,295:INFO:Creating metrics dataframe
2024-11-28 17:20:14,312:INFO:Initializing Dummy Classifier
2024-11-28 17:20:14,313:INFO:Total runtime is 0.27586278915405277 minutes
2024-11-28 17:20:14,318:INFO:SubProcess create_model() called ==================================
2024-11-28 17:20:14,319:INFO:Initializing create_model()
2024-11-28 17:20:14,319:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001899CF0ABC0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000189BA2AFAF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:14,319:INFO:Checking exceptions
2024-11-28 17:20:14,319:INFO:Importing libraries
2024-11-28 17:20:14,319:INFO:Copying training dataset
2024-11-28 17:20:14,328:INFO:Defining folds
2024-11-28 17:20:14,329:INFO:Declaring metric variables
2024-11-28 17:20:14,336:INFO:Importing untrained model
2024-11-28 17:20:14,341:INFO:Dummy Classifier Imported successfully
2024-11-28 17:20:14,351:INFO:Starting cross validation
2024-11-28 17:20:14,352:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:20:14,435:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:20:14,437:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:20:14,437:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:20:14,439:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:20:14,451:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:20:14,494:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:20:14,502:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:20:14,507:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:20:14,511:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:20:14,512:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:20:14,519:INFO:Calculating mean and std
2024-11-28 17:20:14,520:INFO:Creating metrics dataframe
2024-11-28 17:20:14,522:INFO:Uploading results into container
2024-11-28 17:20:14,523:INFO:Uploading model into container now
2024-11-28 17:20:14,523:INFO:_master_model_container: 16
2024-11-28 17:20:14,523:INFO:_display_container: 2
2024-11-28 17:20:14,524:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-11-28 17:20:14,524:INFO:create_model() successfully completed......................................
2024-11-28 17:20:14,583:INFO:SubProcess create_model() end ==================================
2024-11-28 17:20:14,583:INFO:Creating metrics dataframe
2024-11-28 17:20:14,592:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-11-28 17:20:14,599:INFO:Initializing create_model()
2024-11-28 17:20:14,599:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001899CF0ABC0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:14,600:INFO:Checking exceptions
2024-11-28 17:20:14,601:INFO:Importing libraries
2024-11-28 17:20:14,601:INFO:Copying training dataset
2024-11-28 17:20:14,605:INFO:Defining folds
2024-11-28 17:20:14,605:INFO:Declaring metric variables
2024-11-28 17:20:14,605:INFO:Importing untrained model
2024-11-28 17:20:14,605:INFO:Declaring custom model
2024-11-28 17:20:14,606:INFO:Random Forest Classifier Imported successfully
2024-11-28 17:20:14,607:INFO:Cross validation set to False
2024-11-28 17:20:14,607:INFO:Fitting Model
2024-11-28 17:20:14,768:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-11-28 17:20:14,768:INFO:create_model() successfully completed......................................
2024-11-28 17:20:14,856:INFO:Initializing create_model()
2024-11-28 17:20:14,856:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001899CF0ABC0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:14,856:INFO:Checking exceptions
2024-11-28 17:20:14,857:INFO:Importing libraries
2024-11-28 17:20:14,857:INFO:Copying training dataset
2024-11-28 17:20:14,862:INFO:Defining folds
2024-11-28 17:20:14,862:INFO:Declaring metric variables
2024-11-28 17:20:14,862:INFO:Importing untrained model
2024-11-28 17:20:14,862:INFO:Declaring custom model
2024-11-28 17:20:14,863:INFO:Gradient Boosting Classifier Imported successfully
2024-11-28 17:20:14,864:INFO:Cross validation set to False
2024-11-28 17:20:14,864:INFO:Fitting Model
2024-11-28 17:20:15,037:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-11-28 17:20:15,037:INFO:create_model() successfully completed......................................
2024-11-28 17:20:15,101:INFO:Initializing create_model()
2024-11-28 17:20:15,102:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001899CF0ABC0>, estimator=<catboost.core.CatBoostClassifier object at 0x00000189B9E08D00>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:15,102:INFO:Checking exceptions
2024-11-28 17:20:15,103:INFO:Importing libraries
2024-11-28 17:20:15,103:INFO:Copying training dataset
2024-11-28 17:20:15,107:INFO:Defining folds
2024-11-28 17:20:15,107:INFO:Declaring metric variables
2024-11-28 17:20:15,107:INFO:Importing untrained model
2024-11-28 17:20:15,107:INFO:Declaring custom model
2024-11-28 17:20:15,107:INFO:CatBoost Classifier Imported successfully
2024-11-28 17:20:15,108:INFO:Cross validation set to False
2024-11-28 17:20:15,108:INFO:Fitting Model
2024-11-28 17:20:16,649:INFO:<catboost.core.CatBoostClassifier object at 0x00000189B9E089D0>
2024-11-28 17:20:16,649:INFO:create_model() successfully completed......................................
2024-11-28 17:20:16,754:INFO:Initializing create_model()
2024-11-28 17:20:16,754:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001899CF0ABC0>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:16,754:INFO:Checking exceptions
2024-11-28 17:20:16,756:INFO:Importing libraries
2024-11-28 17:20:16,756:INFO:Copying training dataset
2024-11-28 17:20:16,760:INFO:Defining folds
2024-11-28 17:20:16,760:INFO:Declaring metric variables
2024-11-28 17:20:16,760:INFO:Importing untrained model
2024-11-28 17:20:16,760:INFO:Declaring custom model
2024-11-28 17:20:16,761:INFO:Ada Boost Classifier Imported successfully
2024-11-28 17:20:16,762:INFO:Cross validation set to False
2024-11-28 17:20:16,762:INFO:Fitting Model
2024-11-28 17:20:16,795:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:20:16,868:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2024-11-28 17:20:16,868:INFO:create_model() successfully completed......................................
2024-11-28 17:20:16,939:INFO:Initializing create_model()
2024-11-28 17:20:16,939:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001899CF0ABC0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:16,939:INFO:Checking exceptions
2024-11-28 17:20:16,943:INFO:Importing libraries
2024-11-28 17:20:16,943:INFO:Copying training dataset
2024-11-28 17:20:16,948:INFO:Defining folds
2024-11-28 17:20:16,948:INFO:Declaring metric variables
2024-11-28 17:20:16,948:INFO:Importing untrained model
2024-11-28 17:20:16,948:INFO:Declaring custom model
2024-11-28 17:20:16,949:INFO:Logistic Regression Imported successfully
2024-11-28 17:20:16,950:INFO:Cross validation set to False
2024-11-28 17:20:16,950:INFO:Fitting Model
2024-11-28 17:20:17,104:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:20:17,105:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-11-28 17:20:17,105:INFO:create_model() successfully completed......................................
2024-11-28 17:20:17,169:INFO:Initializing create_model()
2024-11-28 17:20:17,170:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001899CF0ABC0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:17,170:INFO:Checking exceptions
2024-11-28 17:20:17,171:INFO:Importing libraries
2024-11-28 17:20:17,171:INFO:Copying training dataset
2024-11-28 17:20:17,175:INFO:Defining folds
2024-11-28 17:20:17,175:INFO:Declaring metric variables
2024-11-28 17:20:17,175:INFO:Importing untrained model
2024-11-28 17:20:17,175:INFO:Declaring custom model
2024-11-28 17:20:17,175:INFO:Ridge Classifier Imported successfully
2024-11-28 17:20:17,176:INFO:Cross validation set to False
2024-11-28 17:20:17,176:INFO:Fitting Model
2024-11-28 17:20:17,211:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-11-28 17:20:17,211:INFO:create_model() successfully completed......................................
2024-11-28 17:20:17,273:INFO:Initializing create_model()
2024-11-28 17:20:17,273:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001899CF0ABC0>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:17,273:INFO:Checking exceptions
2024-11-28 17:20:17,275:INFO:Importing libraries
2024-11-28 17:20:17,275:INFO:Copying training dataset
2024-11-28 17:20:17,279:INFO:Defining folds
2024-11-28 17:20:17,279:INFO:Declaring metric variables
2024-11-28 17:20:17,280:INFO:Importing untrained model
2024-11-28 17:20:17,280:INFO:Declaring custom model
2024-11-28 17:20:17,280:INFO:Linear Discriminant Analysis Imported successfully
2024-11-28 17:20:17,281:INFO:Cross validation set to False
2024-11-28 17:20:17,281:INFO:Fitting Model
2024-11-28 17:20:17,315:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-11-28 17:20:17,315:INFO:create_model() successfully completed......................................
2024-11-28 17:20:17,376:INFO:Initializing create_model()
2024-11-28 17:20:17,377:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001899CF0ABC0>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:17,377:INFO:Checking exceptions
2024-11-28 17:20:17,378:INFO:Importing libraries
2024-11-28 17:20:17,378:INFO:Copying training dataset
2024-11-28 17:20:17,382:INFO:Defining folds
2024-11-28 17:20:17,382:INFO:Declaring metric variables
2024-11-28 17:20:17,382:INFO:Importing untrained model
2024-11-28 17:20:17,382:INFO:Declaring custom model
2024-11-28 17:20:17,383:INFO:Extra Trees Classifier Imported successfully
2024-11-28 17:20:17,384:INFO:Cross validation set to False
2024-11-28 17:20:17,384:INFO:Fitting Model
2024-11-28 17:20:17,507:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-11-28 17:20:17,507:INFO:create_model() successfully completed......................................
2024-11-28 17:20:17,569:INFO:Initializing create_model()
2024-11-28 17:20:17,569:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001899CF0ABC0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:17,569:INFO:Checking exceptions
2024-11-28 17:20:17,571:INFO:Importing libraries
2024-11-28 17:20:17,571:INFO:Copying training dataset
2024-11-28 17:20:17,574:INFO:Defining folds
2024-11-28 17:20:17,574:INFO:Declaring metric variables
2024-11-28 17:20:17,574:INFO:Importing untrained model
2024-11-28 17:20:17,575:INFO:Declaring custom model
2024-11-28 17:20:17,575:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-28 17:20:17,575:INFO:Cross validation set to False
2024-11-28 17:20:17,575:INFO:Fitting Model
2024-11-28 17:20:17,611:INFO:[LightGBM] [Info] Number of positive: 239, number of negative: 384
2024-11-28 17:20:17,611:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000103 seconds.
2024-11-28 17:20:17,611:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-11-28 17:20:17,611:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-11-28 17:20:17,611:INFO:[LightGBM] [Info] Total Bins 410
2024-11-28 17:20:17,611:INFO:[LightGBM] [Info] Number of data points in the train set: 623, number of used features: 12
2024-11-28 17:20:17,612:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383628 -> initscore=-0.474179
2024-11-28 17:20:17,612:INFO:[LightGBM] [Info] Start training from score -0.474179
2024-11-28 17:20:17,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:20:17,648:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-11-28 17:20:17,648:INFO:create_model() successfully completed......................................
2024-11-28 17:20:17,713:INFO:Initializing create_model()
2024-11-28 17:20:17,713:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001899CF0ABC0>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:17,713:INFO:Checking exceptions
2024-11-28 17:20:17,714:INFO:Importing libraries
2024-11-28 17:20:17,714:INFO:Copying training dataset
2024-11-28 17:20:17,718:INFO:Defining folds
2024-11-28 17:20:17,718:INFO:Declaring metric variables
2024-11-28 17:20:17,718:INFO:Importing untrained model
2024-11-28 17:20:17,719:INFO:Declaring custom model
2024-11-28 17:20:17,720:INFO:Extreme Gradient Boosting Imported successfully
2024-11-28 17:20:17,720:INFO:Cross validation set to False
2024-11-28 17:20:17,721:INFO:Fitting Model
2024-11-28 17:20:17,943:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-11-28 17:20:17,943:INFO:create_model() successfully completed......................................
2024-11-28 17:20:18,008:INFO:Initializing create_model()
2024-11-28 17:20:18,008:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001899CF0ABC0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:18,009:INFO:Checking exceptions
2024-11-28 17:20:18,011:INFO:Importing libraries
2024-11-28 17:20:18,011:INFO:Copying training dataset
2024-11-28 17:20:18,016:INFO:Defining folds
2024-11-28 17:20:18,016:INFO:Declaring metric variables
2024-11-28 17:20:18,016:INFO:Importing untrained model
2024-11-28 17:20:18,016:INFO:Declaring custom model
2024-11-28 17:20:18,016:INFO:Naive Bayes Imported successfully
2024-11-28 17:20:18,017:INFO:Cross validation set to False
2024-11-28 17:20:18,017:INFO:Fitting Model
2024-11-28 17:20:18,052:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-11-28 17:20:18,052:INFO:create_model() successfully completed......................................
2024-11-28 17:20:18,117:INFO:Initializing create_model()
2024-11-28 17:20:18,117:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001899CF0ABC0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:18,118:INFO:Checking exceptions
2024-11-28 17:20:18,120:INFO:Importing libraries
2024-11-28 17:20:18,120:INFO:Copying training dataset
2024-11-28 17:20:18,123:INFO:Defining folds
2024-11-28 17:20:18,123:INFO:Declaring metric variables
2024-11-28 17:20:18,123:INFO:Importing untrained model
2024-11-28 17:20:18,123:INFO:Declaring custom model
2024-11-28 17:20:18,124:INFO:Decision Tree Classifier Imported successfully
2024-11-28 17:20:18,125:INFO:Cross validation set to False
2024-11-28 17:20:18,125:INFO:Fitting Model
2024-11-28 17:20:18,160:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2024-11-28 17:20:18,160:INFO:create_model() successfully completed......................................
2024-11-28 17:20:18,223:INFO:Initializing create_model()
2024-11-28 17:20:18,223:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001899CF0ABC0>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:18,223:INFO:Checking exceptions
2024-11-28 17:20:18,225:INFO:Importing libraries
2024-11-28 17:20:18,225:INFO:Copying training dataset
2024-11-28 17:20:18,229:INFO:Defining folds
2024-11-28 17:20:18,229:INFO:Declaring metric variables
2024-11-28 17:20:18,230:INFO:Importing untrained model
2024-11-28 17:20:18,230:INFO:Declaring custom model
2024-11-28 17:20:18,230:INFO:Quadratic Discriminant Analysis Imported successfully
2024-11-28 17:20:18,231:INFO:Cross validation set to False
2024-11-28 17:20:18,231:INFO:Fitting Model
2024-11-28 17:20:18,263:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:20:18,264:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-11-28 17:20:18,264:INFO:create_model() successfully completed......................................
2024-11-28 17:20:18,324:INFO:Initializing create_model()
2024-11-28 17:20:18,325:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001899CF0ABC0>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:18,326:INFO:Checking exceptions
2024-11-28 17:20:18,327:INFO:Importing libraries
2024-11-28 17:20:18,328:INFO:Copying training dataset
2024-11-28 17:20:18,331:INFO:Defining folds
2024-11-28 17:20:18,331:INFO:Declaring metric variables
2024-11-28 17:20:18,331:INFO:Importing untrained model
2024-11-28 17:20:18,331:INFO:Declaring custom model
2024-11-28 17:20:18,331:INFO:K Neighbors Classifier Imported successfully
2024-11-28 17:20:18,332:INFO:Cross validation set to False
2024-11-28 17:20:18,332:INFO:Fitting Model
2024-11-28 17:20:18,366:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-11-28 17:20:18,366:INFO:create_model() successfully completed......................................
2024-11-28 17:20:18,426:INFO:Initializing create_model()
2024-11-28 17:20:18,427:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001899CF0ABC0>, estimator=DummyClassifier(constant=None, random_state=123, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:18,427:INFO:Checking exceptions
2024-11-28 17:20:18,429:INFO:Importing libraries
2024-11-28 17:20:18,429:INFO:Copying training dataset
2024-11-28 17:20:18,433:INFO:Defining folds
2024-11-28 17:20:18,433:INFO:Declaring metric variables
2024-11-28 17:20:18,433:INFO:Importing untrained model
2024-11-28 17:20:18,433:INFO:Declaring custom model
2024-11-28 17:20:18,433:INFO:Dummy Classifier Imported successfully
2024-11-28 17:20:18,434:INFO:Cross validation set to False
2024-11-28 17:20:18,434:INFO:Fitting Model
2024-11-28 17:20:18,465:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-11-28 17:20:18,465:INFO:create_model() successfully completed......................................
2024-11-28 17:20:18,525:INFO:Initializing create_model()
2024-11-28 17:20:18,525:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001899CF0ABC0>, estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:20:18,525:INFO:Checking exceptions
2024-11-28 17:20:18,527:INFO:Importing libraries
2024-11-28 17:20:18,527:INFO:Copying training dataset
2024-11-28 17:20:18,530:INFO:Defining folds
2024-11-28 17:20:18,531:INFO:Declaring metric variables
2024-11-28 17:20:18,531:INFO:Importing untrained model
2024-11-28 17:20:18,531:INFO:Declaring custom model
2024-11-28 17:20:18,531:INFO:SVM - Linear Kernel Imported successfully
2024-11-28 17:20:18,532:INFO:Cross validation set to False
2024-11-28 17:20:18,532:INFO:Fitting Model
2024-11-28 17:20:18,566:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-11-28 17:20:18,567:INFO:create_model() successfully completed......................................
2024-11-28 17:20:18,641:INFO:_master_model_container: 16
2024-11-28 17:20:18,641:INFO:_display_container: 2
2024-11-28 17:20:18,645:INFO:[RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), <catboost.core.CatBoostClassifier object at 0x00000189B9E089D0>, AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best'), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), DummyClassifier(constant=None, random_state=123, strategy='prior'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)]
2024-11-28 17:20:18,645:INFO:compare_models() successfully completed......................................
2024-11-28 17:24:27,861:INFO:PyCaret ClassificationExperiment
2024-11-28 17:24:27,861:INFO:Logging name: clf-default-name
2024-11-28 17:24:27,861:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-11-28 17:24:27,861:INFO:version 3.3.2
2024-11-28 17:24:27,861:INFO:Initializing setup()
2024-11-28 17:24:27,861:INFO:self.USI: 86ee
2024-11-28 17:24:27,861:INFO:self._variable_keys: {'exp_name_log', 'y_train', 'logging_param', 'y_test', 'is_multiclass', 'X_train', 'USI', 'fold_groups_param', 'data', '_ml_usecase', 'exp_id', 'target_param', 'fold_shuffle_param', 'html_param', 'X', 'memory', 'y', 'X_test', 'pipeline', 'fix_imbalance', '_available_plots', 'gpu_n_jobs_param', 'log_plots_param', 'idx', 'fold_generator', 'seed', 'n_jobs_param', 'gpu_param'}
2024-11-28 17:24:27,861:INFO:Checking environment
2024-11-28 17:24:27,861:INFO:python_version: 3.10.11
2024-11-28 17:24:27,861:INFO:python_build: ('tags/v3.10.11:7d4cc5a', 'Apr  5 2023 00:38:17')
2024-11-28 17:24:27,861:INFO:machine: AMD64
2024-11-28 17:24:27,861:INFO:platform: Windows-10-10.0.19045-SP0
2024-11-28 17:24:27,864:INFO:Memory: svmem(total=34216488960, available=18650087424, percent=45.5, used=15566401536, free=18650087424)
2024-11-28 17:24:27,864:INFO:Physical Core: 6
2024-11-28 17:24:27,864:INFO:Logical Core: 6
2024-11-28 17:24:27,864:INFO:Checking libraries
2024-11-28 17:24:27,864:INFO:System:
2024-11-28 17:24:27,864:INFO:    python: 3.10.11 (tags/v3.10.11:7d4cc5a, Apr  5 2023, 00:38:17) [MSC v.1929 64 bit (AMD64)]
2024-11-28 17:24:27,864:INFO:executable: c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\Scripts\python.exe
2024-11-28 17:24:27,864:INFO:   machine: Windows-10-10.0.19045-SP0
2024-11-28 17:24:27,864:INFO:PyCaret required dependencies:
2024-11-28 17:24:27,865:INFO:                 pip: 23.0.1
2024-11-28 17:24:27,865:INFO:          setuptools: 65.5.0
2024-11-28 17:24:27,865:INFO:             pycaret: 3.3.2
2024-11-28 17:24:27,865:INFO:             IPython: 8.29.0
2024-11-28 17:24:27,865:INFO:          ipywidgets: 8.1.5
2024-11-28 17:24:27,865:INFO:                tqdm: 4.67.1
2024-11-28 17:24:27,865:INFO:               numpy: 1.26.4
2024-11-28 17:24:27,865:INFO:              pandas: 2.1.4
2024-11-28 17:24:27,865:INFO:              jinja2: 3.1.4
2024-11-28 17:24:27,865:INFO:               scipy: 1.11.4
2024-11-28 17:24:27,865:INFO:              joblib: 1.3.2
2024-11-28 17:24:27,865:INFO:             sklearn: 1.4.2
2024-11-28 17:24:27,865:INFO:                pyod: 2.0.2
2024-11-28 17:24:27,865:INFO:            imblearn: 0.12.4
2024-11-28 17:24:27,865:INFO:   category_encoders: 2.6.4
2024-11-28 17:24:27,865:INFO:            lightgbm: 4.5.0
2024-11-28 17:24:27,865:INFO:               numba: 0.60.0
2024-11-28 17:24:27,865:INFO:            requests: 2.32.3
2024-11-28 17:24:27,865:INFO:          matplotlib: 3.7.5
2024-11-28 17:24:27,865:INFO:          scikitplot: 0.3.7
2024-11-28 17:24:27,865:INFO:         yellowbrick: 1.5
2024-11-28 17:24:27,865:INFO:              plotly: 5.24.1
2024-11-28 17:24:27,865:INFO:    plotly-resampler: Not installed
2024-11-28 17:24:27,865:INFO:             kaleido: 0.2.1
2024-11-28 17:24:27,865:INFO:           schemdraw: 0.15
2024-11-28 17:24:27,865:INFO:         statsmodels: 0.14.4
2024-11-28 17:24:27,865:INFO:              sktime: 0.26.0
2024-11-28 17:24:27,865:INFO:               tbats: 1.1.3
2024-11-28 17:24:27,866:INFO:            pmdarima: 2.0.4
2024-11-28 17:24:27,866:INFO:              psutil: 6.1.0
2024-11-28 17:24:27,866:INFO:          markupsafe: 3.0.2
2024-11-28 17:24:27,866:INFO:             pickle5: Not installed
2024-11-28 17:24:27,866:INFO:         cloudpickle: 3.1.0
2024-11-28 17:24:27,866:INFO:         deprecation: 2.1.0
2024-11-28 17:24:27,866:INFO:              xxhash: 3.5.0
2024-11-28 17:24:27,866:INFO:           wurlitzer: Not installed
2024-11-28 17:24:27,866:INFO:PyCaret optional dependencies:
2024-11-28 17:24:27,866:INFO:                shap: Not installed
2024-11-28 17:24:27,866:INFO:           interpret: Not installed
2024-11-28 17:24:27,866:INFO:                umap: Not installed
2024-11-28 17:24:27,866:INFO:     ydata_profiling: Not installed
2024-11-28 17:24:27,866:INFO:  explainerdashboard: Not installed
2024-11-28 17:24:27,866:INFO:             autoviz: Not installed
2024-11-28 17:24:27,866:INFO:           fairlearn: Not installed
2024-11-28 17:24:27,866:INFO:          deepchecks: Not installed
2024-11-28 17:24:27,866:INFO:             xgboost: 2.1.3
2024-11-28 17:24:27,866:INFO:            catboost: 1.2.7
2024-11-28 17:24:27,866:INFO:              kmodes: Not installed
2024-11-28 17:24:27,866:INFO:             mlxtend: 0.23.3
2024-11-28 17:24:27,866:INFO:       statsforecast: Not installed
2024-11-28 17:24:27,866:INFO:        tune_sklearn: Not installed
2024-11-28 17:24:27,866:INFO:                 ray: Not installed
2024-11-28 17:24:27,866:INFO:            hyperopt: Not installed
2024-11-28 17:24:27,866:INFO:              optuna: Not installed
2024-11-28 17:24:27,866:INFO:               skopt: Not installed
2024-11-28 17:24:27,866:INFO:              mlflow: Not installed
2024-11-28 17:24:27,867:INFO:              gradio: Not installed
2024-11-28 17:24:27,867:INFO:             fastapi: Not installed
2024-11-28 17:24:27,867:INFO:             uvicorn: Not installed
2024-11-28 17:24:27,867:INFO:              m2cgen: Not installed
2024-11-28 17:24:27,867:INFO:           evidently: Not installed
2024-11-28 17:24:27,867:INFO:               fugue: Not installed
2024-11-28 17:24:27,867:INFO:           streamlit: 1.39.0
2024-11-28 17:24:27,867:INFO:             prophet: Not installed
2024-11-28 17:24:27,867:INFO:None
2024-11-28 17:24:27,867:INFO:Set up data.
2024-11-28 17:24:27,871:INFO:Set up folding strategy.
2024-11-28 17:24:27,871:INFO:Set up train/test split.
2024-11-28 17:24:27,875:INFO:Set up index.
2024-11-28 17:24:27,875:INFO:Assigning column types.
2024-11-28 17:24:27,878:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-28 17:24:27,916:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-28 17:24:27,916:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-28 17:24:27,940:INFO:Soft dependency imported: xgboost: 2.1.3
2024-11-28 17:24:27,942:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-28 17:24:27,981:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-28 17:24:27,981:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-28 17:24:28,004:INFO:Soft dependency imported: xgboost: 2.1.3
2024-11-28 17:24:28,006:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-28 17:24:28,007:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-28 17:24:28,043:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-28 17:24:28,066:INFO:Soft dependency imported: xgboost: 2.1.3
2024-11-28 17:24:28,068:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-28 17:24:28,106:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-28 17:24:28,131:INFO:Soft dependency imported: xgboost: 2.1.3
2024-11-28 17:24:28,133:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-28 17:24:28,133:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-11-28 17:24:28,193:INFO:Soft dependency imported: xgboost: 2.1.3
2024-11-28 17:24:28,195:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-28 17:24:28,255:INFO:Soft dependency imported: xgboost: 2.1.3
2024-11-28 17:24:28,257:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-28 17:24:28,258:INFO:Preparing preprocessing pipeline...
2024-11-28 17:24:28,259:INFO:Set up simple imputation.
2024-11-28 17:24:28,261:INFO:Set up encoding of ordinal features.
2024-11-28 17:24:28,263:INFO:Set up encoding of categorical features.
2024-11-28 17:24:28,317:INFO:Finished creating preprocessing pipeline.
2024-11-28 17:24:28,334:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\tsai\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare',
                                             'FamilySize', 'IsAlone'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='m...
                                                               mapping=[{'col': 'Sex',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64}],
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None, include=['Embarked'],
                                    transformer=OneHotEncoder(cols=['Embarked'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2024-11-28 17:24:28,334:INFO:Creating final display dataframe.
2024-11-28 17:24:28,506:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target          Survived
2                   Target type            Binary
3           Original data shape         (891, 11)
4        Transformed data shape         (891, 13)
5   Transformed train set shape         (623, 13)
6    Transformed test set shape         (268, 13)
7              Numeric features                 8
8          Categorical features                 2
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              86ee
2024-11-28 17:24:28,574:INFO:Soft dependency imported: xgboost: 2.1.3
2024-11-28 17:24:28,577:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-28 17:24:28,641:INFO:Soft dependency imported: xgboost: 2.1.3
2024-11-28 17:24:28,643:INFO:Soft dependency imported: catboost: 1.2.7
2024-11-28 17:24:28,644:INFO:setup() successfully completed in 0.78s...............
2024-11-28 17:24:28,646:INFO:Initializing compare_models()
2024-11-28 17:24:28,646:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=16, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 16, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-11-28 17:24:28,646:INFO:Checking exceptions
2024-11-28 17:24:28,649:INFO:Preparing display monitor
2024-11-28 17:24:28,669:INFO:Initializing Logistic Regression
2024-11-28 17:24:28,669:INFO:Total runtime is 0.0 minutes
2024-11-28 17:24:28,672:INFO:SubProcess create_model() called ==================================
2024-11-28 17:24:28,672:INFO:Initializing create_model()
2024-11-28 17:24:28,672:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000189B9AE2080>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:24:28,672:INFO:Checking exceptions
2024-11-28 17:24:28,672:INFO:Importing libraries
2024-11-28 17:24:28,673:INFO:Copying training dataset
2024-11-28 17:24:28,678:INFO:Defining folds
2024-11-28 17:24:28,678:INFO:Declaring metric variables
2024-11-28 17:24:28,682:INFO:Importing untrained model
2024-11-28 17:24:28,687:INFO:Logistic Regression Imported successfully
2024-11-28 17:24:28,733:INFO:Starting cross validation
2024-11-28 17:24:28,735:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:24:28,926:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:24:28,929:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:24:28,932:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:24:28,944:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:24:28,946:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:24:28,949:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:24:29,114:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:24:29,116:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:24:29,119:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:24:29,133:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:24:29,175:INFO:Calculating mean and std
2024-11-28 17:24:29,177:INFO:Creating metrics dataframe
2024-11-28 17:24:29,183:INFO:Uploading results into container
2024-11-28 17:24:29,185:INFO:Uploading model into container now
2024-11-28 17:24:29,186:INFO:_master_model_container: 1
2024-11-28 17:24:29,187:INFO:_display_container: 2
2024-11-28 17:24:29,188:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-11-28 17:24:29,188:INFO:create_model() successfully completed......................................
2024-11-28 17:24:29,344:INFO:SubProcess create_model() end ==================================
2024-11-28 17:24:29,344:INFO:Creating metrics dataframe
2024-11-28 17:24:29,351:INFO:Initializing K Neighbors Classifier
2024-11-28 17:24:29,352:INFO:Total runtime is 0.011384427547454834 minutes
2024-11-28 17:24:29,355:INFO:SubProcess create_model() called ==================================
2024-11-28 17:24:29,355:INFO:Initializing create_model()
2024-11-28 17:24:29,355:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000189B9AE2080>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:24:29,355:INFO:Checking exceptions
2024-11-28 17:24:29,355:INFO:Importing libraries
2024-11-28 17:24:29,355:INFO:Copying training dataset
2024-11-28 17:24:29,360:INFO:Defining folds
2024-11-28 17:24:29,360:INFO:Declaring metric variables
2024-11-28 17:24:29,363:INFO:Importing untrained model
2024-11-28 17:24:29,366:INFO:K Neighbors Classifier Imported successfully
2024-11-28 17:24:29,373:INFO:Starting cross validation
2024-11-28 17:24:29,375:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:24:29,719:INFO:Calculating mean and std
2024-11-28 17:24:29,724:INFO:Creating metrics dataframe
2024-11-28 17:24:29,731:INFO:Uploading results into container
2024-11-28 17:24:29,733:INFO:Uploading model into container now
2024-11-28 17:24:29,734:INFO:_master_model_container: 2
2024-11-28 17:24:29,735:INFO:_display_container: 2
2024-11-28 17:24:29,736:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-11-28 17:24:29,736:INFO:create_model() successfully completed......................................
2024-11-28 17:24:29,854:INFO:SubProcess create_model() end ==================================
2024-11-28 17:24:29,854:INFO:Creating metrics dataframe
2024-11-28 17:24:29,864:INFO:Initializing Naive Bayes
2024-11-28 17:24:29,864:INFO:Total runtime is 0.019924724102020265 minutes
2024-11-28 17:24:29,868:INFO:SubProcess create_model() called ==================================
2024-11-28 17:24:29,869:INFO:Initializing create_model()
2024-11-28 17:24:29,869:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000189B9AE2080>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:24:29,869:INFO:Checking exceptions
2024-11-28 17:24:29,869:INFO:Importing libraries
2024-11-28 17:24:29,869:INFO:Copying training dataset
2024-11-28 17:24:29,876:INFO:Defining folds
2024-11-28 17:24:29,876:INFO:Declaring metric variables
2024-11-28 17:24:29,881:INFO:Importing untrained model
2024-11-28 17:24:29,885:INFO:Naive Bayes Imported successfully
2024-11-28 17:24:29,894:INFO:Starting cross validation
2024-11-28 17:24:29,895:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:24:30,091:INFO:Calculating mean and std
2024-11-28 17:24:30,092:INFO:Creating metrics dataframe
2024-11-28 17:24:30,094:INFO:Uploading results into container
2024-11-28 17:24:30,094:INFO:Uploading model into container now
2024-11-28 17:24:30,095:INFO:_master_model_container: 3
2024-11-28 17:24:30,095:INFO:_display_container: 2
2024-11-28 17:24:30,095:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-11-28 17:24:30,095:INFO:create_model() successfully completed......................................
2024-11-28 17:24:30,153:INFO:SubProcess create_model() end ==================================
2024-11-28 17:24:30,153:INFO:Creating metrics dataframe
2024-11-28 17:24:30,160:INFO:Initializing Decision Tree Classifier
2024-11-28 17:24:30,160:INFO:Total runtime is 0.024851636091868086 minutes
2024-11-28 17:24:30,163:INFO:SubProcess create_model() called ==================================
2024-11-28 17:24:30,164:INFO:Initializing create_model()
2024-11-28 17:24:30,164:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000189B9AE2080>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:24:30,164:INFO:Checking exceptions
2024-11-28 17:24:30,164:INFO:Importing libraries
2024-11-28 17:24:30,164:INFO:Copying training dataset
2024-11-28 17:24:30,169:INFO:Defining folds
2024-11-28 17:24:30,169:INFO:Declaring metric variables
2024-11-28 17:24:30,171:INFO:Importing untrained model
2024-11-28 17:24:30,175:INFO:Decision Tree Classifier Imported successfully
2024-11-28 17:24:30,182:INFO:Starting cross validation
2024-11-28 17:24:30,183:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:24:30,414:INFO:Calculating mean and std
2024-11-28 17:24:30,415:INFO:Creating metrics dataframe
2024-11-28 17:24:30,417:INFO:Uploading results into container
2024-11-28 17:24:30,417:INFO:Uploading model into container now
2024-11-28 17:24:30,417:INFO:_master_model_container: 4
2024-11-28 17:24:30,417:INFO:_display_container: 2
2024-11-28 17:24:30,418:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2024-11-28 17:24:30,418:INFO:create_model() successfully completed......................................
2024-11-28 17:24:30,476:INFO:SubProcess create_model() end ==================================
2024-11-28 17:24:30,476:INFO:Creating metrics dataframe
2024-11-28 17:24:30,482:INFO:Initializing SVM - Linear Kernel
2024-11-28 17:24:30,482:INFO:Total runtime is 0.03022297223409017 minutes
2024-11-28 17:24:30,485:INFO:SubProcess create_model() called ==================================
2024-11-28 17:24:30,485:INFO:Initializing create_model()
2024-11-28 17:24:30,485:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000189B9AE2080>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:24:30,485:INFO:Checking exceptions
2024-11-28 17:24:30,485:INFO:Importing libraries
2024-11-28 17:24:30,485:INFO:Copying training dataset
2024-11-28 17:24:30,489:INFO:Defining folds
2024-11-28 17:24:30,489:INFO:Declaring metric variables
2024-11-28 17:24:30,492:INFO:Importing untrained model
2024-11-28 17:24:30,495:INFO:SVM - Linear Kernel Imported successfully
2024-11-28 17:24:30,501:INFO:Starting cross validation
2024-11-28 17:24:30,502:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:24:30,679:INFO:Calculating mean and std
2024-11-28 17:24:30,683:INFO:Creating metrics dataframe
2024-11-28 17:24:30,689:INFO:Uploading results into container
2024-11-28 17:24:30,691:INFO:Uploading model into container now
2024-11-28 17:24:30,692:INFO:_master_model_container: 5
2024-11-28 17:24:30,692:INFO:_display_container: 2
2024-11-28 17:24:30,693:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-11-28 17:24:30,693:INFO:create_model() successfully completed......................................
2024-11-28 17:24:30,765:INFO:SubProcess create_model() end ==================================
2024-11-28 17:24:30,765:INFO:Creating metrics dataframe
2024-11-28 17:24:30,774:INFO:Initializing Ridge Classifier
2024-11-28 17:24:30,774:INFO:Total runtime is 0.03507765531539917 minutes
2024-11-28 17:24:30,777:INFO:SubProcess create_model() called ==================================
2024-11-28 17:24:30,777:INFO:Initializing create_model()
2024-11-28 17:24:30,777:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000189B9AE2080>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:24:30,777:INFO:Checking exceptions
2024-11-28 17:24:30,777:INFO:Importing libraries
2024-11-28 17:24:30,777:INFO:Copying training dataset
2024-11-28 17:24:30,781:INFO:Defining folds
2024-11-28 17:24:30,782:INFO:Declaring metric variables
2024-11-28 17:24:30,784:INFO:Importing untrained model
2024-11-28 17:24:30,787:INFO:Ridge Classifier Imported successfully
2024-11-28 17:24:30,794:INFO:Starting cross validation
2024-11-28 17:24:30,795:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:24:30,973:INFO:Calculating mean and std
2024-11-28 17:24:30,975:INFO:Creating metrics dataframe
2024-11-28 17:24:30,982:INFO:Uploading results into container
2024-11-28 17:24:30,983:INFO:Uploading model into container now
2024-11-28 17:24:30,985:INFO:_master_model_container: 6
2024-11-28 17:24:30,985:INFO:_display_container: 2
2024-11-28 17:24:30,986:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-11-28 17:24:30,986:INFO:create_model() successfully completed......................................
2024-11-28 17:24:31,081:INFO:SubProcess create_model() end ==================================
2024-11-28 17:24:31,081:INFO:Creating metrics dataframe
2024-11-28 17:24:31,093:INFO:Initializing Random Forest Classifier
2024-11-28 17:24:31,093:INFO:Total runtime is 0.04040353298187256 minutes
2024-11-28 17:24:31,097:INFO:SubProcess create_model() called ==================================
2024-11-28 17:24:31,097:INFO:Initializing create_model()
2024-11-28 17:24:31,097:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000189B9AE2080>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:24:31,097:INFO:Checking exceptions
2024-11-28 17:24:31,098:INFO:Importing libraries
2024-11-28 17:24:31,098:INFO:Copying training dataset
2024-11-28 17:24:31,103:INFO:Defining folds
2024-11-28 17:24:31,103:INFO:Declaring metric variables
2024-11-28 17:24:31,106:INFO:Importing untrained model
2024-11-28 17:24:31,110:INFO:Random Forest Classifier Imported successfully
2024-11-28 17:24:31,118:INFO:Starting cross validation
2024-11-28 17:24:31,119:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:24:31,716:INFO:Calculating mean and std
2024-11-28 17:24:31,716:INFO:Creating metrics dataframe
2024-11-28 17:24:31,719:INFO:Uploading results into container
2024-11-28 17:24:31,719:INFO:Uploading model into container now
2024-11-28 17:24:31,719:INFO:_master_model_container: 7
2024-11-28 17:24:31,720:INFO:_display_container: 2
2024-11-28 17:24:31,720:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-11-28 17:24:31,720:INFO:create_model() successfully completed......................................
2024-11-28 17:24:31,786:INFO:SubProcess create_model() end ==================================
2024-11-28 17:24:31,786:INFO:Creating metrics dataframe
2024-11-28 17:24:31,794:INFO:Initializing Quadratic Discriminant Analysis
2024-11-28 17:24:31,794:INFO:Total runtime is 0.052077500025431316 minutes
2024-11-28 17:24:31,797:INFO:SubProcess create_model() called ==================================
2024-11-28 17:24:31,797:INFO:Initializing create_model()
2024-11-28 17:24:31,797:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000189B9AE2080>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:24:31,797:INFO:Checking exceptions
2024-11-28 17:24:31,797:INFO:Importing libraries
2024-11-28 17:24:31,797:INFO:Copying training dataset
2024-11-28 17:24:31,801:INFO:Defining folds
2024-11-28 17:24:31,801:INFO:Declaring metric variables
2024-11-28 17:24:31,803:INFO:Importing untrained model
2024-11-28 17:24:31,806:INFO:Quadratic Discriminant Analysis Imported successfully
2024-11-28 17:24:31,812:INFO:Starting cross validation
2024-11-28 17:24:31,813:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:24:31,866:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:24:31,869:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:24:31,877:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:24:31,879:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:24:31,884:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:24:31,941:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:24:31,941:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:24:31,947:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:24:31,955:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:24:31,996:INFO:Calculating mean and std
2024-11-28 17:24:31,997:INFO:Creating metrics dataframe
2024-11-28 17:24:31,999:INFO:Uploading results into container
2024-11-28 17:24:31,999:INFO:Uploading model into container now
2024-11-28 17:24:32,000:INFO:_master_model_container: 8
2024-11-28 17:24:32,000:INFO:_display_container: 2
2024-11-28 17:24:32,000:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-11-28 17:24:32,000:INFO:create_model() successfully completed......................................
2024-11-28 17:24:32,057:INFO:SubProcess create_model() end ==================================
2024-11-28 17:24:32,057:INFO:Creating metrics dataframe
2024-11-28 17:24:32,064:INFO:Initializing Ada Boost Classifier
2024-11-28 17:24:32,064:INFO:Total runtime is 0.056578465302785236 minutes
2024-11-28 17:24:32,067:INFO:SubProcess create_model() called ==================================
2024-11-28 17:24:32,068:INFO:Initializing create_model()
2024-11-28 17:24:32,068:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000189B9AE2080>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:24:32,068:INFO:Checking exceptions
2024-11-28 17:24:32,068:INFO:Importing libraries
2024-11-28 17:24:32,068:INFO:Copying training dataset
2024-11-28 17:24:32,072:INFO:Defining folds
2024-11-28 17:24:32,072:INFO:Declaring metric variables
2024-11-28 17:24:32,076:INFO:Importing untrained model
2024-11-28 17:24:32,079:INFO:Ada Boost Classifier Imported successfully
2024-11-28 17:24:32,085:INFO:Starting cross validation
2024-11-28 17:24:32,086:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:24:32,141:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:24:32,141:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:24:32,143:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:24:32,145:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:24:32,146:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:24:32,159:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:24:32,305:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:24:32,307:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:24:32,311:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:24:32,316:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:24:32,475:INFO:Calculating mean and std
2024-11-28 17:24:32,476:INFO:Creating metrics dataframe
2024-11-28 17:24:32,478:INFO:Uploading results into container
2024-11-28 17:24:32,478:INFO:Uploading model into container now
2024-11-28 17:24:32,479:INFO:_master_model_container: 9
2024-11-28 17:24:32,479:INFO:_display_container: 2
2024-11-28 17:24:32,479:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2024-11-28 17:24:32,479:INFO:create_model() successfully completed......................................
2024-11-28 17:24:32,547:INFO:SubProcess create_model() end ==================================
2024-11-28 17:24:32,547:INFO:Creating metrics dataframe
2024-11-28 17:24:32,555:INFO:Initializing Gradient Boosting Classifier
2024-11-28 17:24:32,555:INFO:Total runtime is 0.06476002136866252 minutes
2024-11-28 17:24:32,558:INFO:SubProcess create_model() called ==================================
2024-11-28 17:24:32,558:INFO:Initializing create_model()
2024-11-28 17:24:32,558:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000189B9AE2080>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:24:32,558:INFO:Checking exceptions
2024-11-28 17:24:32,558:INFO:Importing libraries
2024-11-28 17:24:32,559:INFO:Copying training dataset
2024-11-28 17:24:32,562:INFO:Defining folds
2024-11-28 17:24:32,562:INFO:Declaring metric variables
2024-11-28 17:24:32,564:INFO:Importing untrained model
2024-11-28 17:24:32,567:INFO:Gradient Boosting Classifier Imported successfully
2024-11-28 17:24:32,572:INFO:Starting cross validation
2024-11-28 17:24:32,574:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:24:33,016:INFO:Calculating mean and std
2024-11-28 17:24:33,020:INFO:Creating metrics dataframe
2024-11-28 17:24:33,024:INFO:Uploading results into container
2024-11-28 17:24:33,025:INFO:Uploading model into container now
2024-11-28 17:24:33,026:INFO:_master_model_container: 10
2024-11-28 17:24:33,026:INFO:_display_container: 2
2024-11-28 17:24:33,027:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-11-28 17:24:33,027:INFO:create_model() successfully completed......................................
2024-11-28 17:24:33,124:INFO:SubProcess create_model() end ==================================
2024-11-28 17:24:33,124:INFO:Creating metrics dataframe
2024-11-28 17:24:33,143:INFO:Initializing Linear Discriminant Analysis
2024-11-28 17:24:33,143:INFO:Total runtime is 0.0745696226755778 minutes
2024-11-28 17:24:33,149:INFO:SubProcess create_model() called ==================================
2024-11-28 17:24:33,150:INFO:Initializing create_model()
2024-11-28 17:24:33,150:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000189B9AE2080>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:24:33,150:INFO:Checking exceptions
2024-11-28 17:24:33,150:INFO:Importing libraries
2024-11-28 17:24:33,150:INFO:Copying training dataset
2024-11-28 17:24:33,157:INFO:Defining folds
2024-11-28 17:24:33,157:INFO:Declaring metric variables
2024-11-28 17:24:33,161:INFO:Importing untrained model
2024-11-28 17:24:33,164:INFO:Linear Discriminant Analysis Imported successfully
2024-11-28 17:24:33,170:INFO:Starting cross validation
2024-11-28 17:24:33,172:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:24:33,343:INFO:Calculating mean and std
2024-11-28 17:24:33,344:INFO:Creating metrics dataframe
2024-11-28 17:24:33,346:INFO:Uploading results into container
2024-11-28 17:24:33,346:INFO:Uploading model into container now
2024-11-28 17:24:33,346:INFO:_master_model_container: 11
2024-11-28 17:24:33,346:INFO:_display_container: 2
2024-11-28 17:24:33,347:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-11-28 17:24:33,347:INFO:create_model() successfully completed......................................
2024-11-28 17:24:33,406:INFO:SubProcess create_model() end ==================================
2024-11-28 17:24:33,406:INFO:Creating metrics dataframe
2024-11-28 17:24:33,414:INFO:Initializing Extra Trees Classifier
2024-11-28 17:24:33,414:INFO:Total runtime is 0.07908888657887778 minutes
2024-11-28 17:24:33,416:INFO:SubProcess create_model() called ==================================
2024-11-28 17:24:33,417:INFO:Initializing create_model()
2024-11-28 17:24:33,417:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000189B9AE2080>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:24:33,417:INFO:Checking exceptions
2024-11-28 17:24:33,417:INFO:Importing libraries
2024-11-28 17:24:33,417:INFO:Copying training dataset
2024-11-28 17:24:33,421:INFO:Defining folds
2024-11-28 17:24:33,421:INFO:Declaring metric variables
2024-11-28 17:24:33,424:INFO:Importing untrained model
2024-11-28 17:24:33,427:INFO:Extra Trees Classifier Imported successfully
2024-11-28 17:24:33,432:INFO:Starting cross validation
2024-11-28 17:24:33,434:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:24:33,946:INFO:Calculating mean and std
2024-11-28 17:24:33,947:INFO:Creating metrics dataframe
2024-11-28 17:24:33,949:INFO:Uploading results into container
2024-11-28 17:24:33,949:INFO:Uploading model into container now
2024-11-28 17:24:33,950:INFO:_master_model_container: 12
2024-11-28 17:24:33,950:INFO:_display_container: 2
2024-11-28 17:24:33,950:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-11-28 17:24:33,950:INFO:create_model() successfully completed......................................
2024-11-28 17:24:34,008:INFO:SubProcess create_model() end ==================================
2024-11-28 17:24:34,008:INFO:Creating metrics dataframe
2024-11-28 17:24:34,015:INFO:Initializing Extreme Gradient Boosting
2024-11-28 17:24:34,015:INFO:Total runtime is 0.08909590641657512 minutes
2024-11-28 17:24:34,018:INFO:SubProcess create_model() called ==================================
2024-11-28 17:24:34,018:INFO:Initializing create_model()
2024-11-28 17:24:34,018:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000189B9AE2080>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:24:34,019:INFO:Checking exceptions
2024-11-28 17:24:34,019:INFO:Importing libraries
2024-11-28 17:24:34,019:INFO:Copying training dataset
2024-11-28 17:24:34,023:INFO:Defining folds
2024-11-28 17:24:34,023:INFO:Declaring metric variables
2024-11-28 17:24:34,026:INFO:Importing untrained model
2024-11-28 17:24:34,029:INFO:Extreme Gradient Boosting Imported successfully
2024-11-28 17:24:34,035:INFO:Starting cross validation
2024-11-28 17:24:34,036:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:24:34,334:INFO:Calculating mean and std
2024-11-28 17:24:34,335:INFO:Creating metrics dataframe
2024-11-28 17:24:34,337:INFO:Uploading results into container
2024-11-28 17:24:34,337:INFO:Uploading model into container now
2024-11-28 17:24:34,338:INFO:_master_model_container: 13
2024-11-28 17:24:34,338:INFO:_display_container: 2
2024-11-28 17:24:34,339:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-11-28 17:24:34,339:INFO:create_model() successfully completed......................................
2024-11-28 17:24:34,397:INFO:SubProcess create_model() end ==================================
2024-11-28 17:24:34,397:INFO:Creating metrics dataframe
2024-11-28 17:24:34,405:INFO:Initializing Light Gradient Boosting Machine
2024-11-28 17:24:34,405:INFO:Total runtime is 0.09559472799301148 minutes
2024-11-28 17:24:34,408:INFO:SubProcess create_model() called ==================================
2024-11-28 17:24:34,408:INFO:Initializing create_model()
2024-11-28 17:24:34,408:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000189B9AE2080>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:24:34,408:INFO:Checking exceptions
2024-11-28 17:24:34,408:INFO:Importing libraries
2024-11-28 17:24:34,408:INFO:Copying training dataset
2024-11-28 17:24:34,412:INFO:Defining folds
2024-11-28 17:24:34,412:INFO:Declaring metric variables
2024-11-28 17:24:34,415:INFO:Importing untrained model
2024-11-28 17:24:34,417:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-28 17:24:34,422:INFO:Starting cross validation
2024-11-28 17:24:34,424:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:24:35,311:INFO:Calculating mean and std
2024-11-28 17:24:35,312:INFO:Creating metrics dataframe
2024-11-28 17:24:35,315:INFO:Uploading results into container
2024-11-28 17:24:35,316:INFO:Uploading model into container now
2024-11-28 17:24:35,316:INFO:_master_model_container: 14
2024-11-28 17:24:35,316:INFO:_display_container: 2
2024-11-28 17:24:35,317:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-11-28 17:24:35,317:INFO:create_model() successfully completed......................................
2024-11-28 17:24:35,376:INFO:SubProcess create_model() end ==================================
2024-11-28 17:24:35,376:INFO:Creating metrics dataframe
2024-11-28 17:24:35,384:INFO:Initializing CatBoost Classifier
2024-11-28 17:24:35,385:INFO:Total runtime is 0.11193433205286663 minutes
2024-11-28 17:24:35,387:INFO:SubProcess create_model() called ==================================
2024-11-28 17:24:35,388:INFO:Initializing create_model()
2024-11-28 17:24:35,388:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000189B9AE2080>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:24:35,388:INFO:Checking exceptions
2024-11-28 17:24:35,388:INFO:Importing libraries
2024-11-28 17:24:35,388:INFO:Copying training dataset
2024-11-28 17:24:35,392:INFO:Defining folds
2024-11-28 17:24:35,392:INFO:Declaring metric variables
2024-11-28 17:24:35,395:INFO:Importing untrained model
2024-11-28 17:24:35,398:INFO:CatBoost Classifier Imported successfully
2024-11-28 17:24:35,404:INFO:Starting cross validation
2024-11-28 17:24:35,406:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:24:39,796:INFO:Calculating mean and std
2024-11-28 17:24:39,797:INFO:Creating metrics dataframe
2024-11-28 17:24:39,799:INFO:Uploading results into container
2024-11-28 17:24:39,800:INFO:Uploading model into container now
2024-11-28 17:24:39,800:INFO:_master_model_container: 15
2024-11-28 17:24:39,800:INFO:_display_container: 2
2024-11-28 17:24:39,800:INFO:<catboost.core.CatBoostClassifier object at 0x00000189BA1C9690>
2024-11-28 17:24:39,800:INFO:create_model() successfully completed......................................
2024-11-28 17:24:39,858:INFO:SubProcess create_model() end ==================================
2024-11-28 17:24:39,858:INFO:Creating metrics dataframe
2024-11-28 17:24:39,867:INFO:Initializing Dummy Classifier
2024-11-28 17:24:39,867:INFO:Total runtime is 0.18663124640782675 minutes
2024-11-28 17:24:39,869:INFO:SubProcess create_model() called ==================================
2024-11-28 17:24:39,870:INFO:Initializing create_model()
2024-11-28 17:24:39,870:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000189B9AE2080>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:24:39,870:INFO:Checking exceptions
2024-11-28 17:24:39,870:INFO:Importing libraries
2024-11-28 17:24:39,870:INFO:Copying training dataset
2024-11-28 17:24:39,874:INFO:Defining folds
2024-11-28 17:24:39,874:INFO:Declaring metric variables
2024-11-28 17:24:39,877:INFO:Importing untrained model
2024-11-28 17:24:39,880:INFO:Dummy Classifier Imported successfully
2024-11-28 17:24:39,885:INFO:Starting cross validation
2024-11-28 17:24:39,886:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:24:39,968:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:24:39,969:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:24:39,974:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:24:39,975:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:24:39,987:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:24:40,037:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:24:40,041:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:24:40,043:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:24:40,043:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:24:40,061:INFO:Calculating mean and std
2024-11-28 17:24:40,062:INFO:Creating metrics dataframe
2024-11-28 17:24:40,064:INFO:Uploading results into container
2024-11-28 17:24:40,065:INFO:Uploading model into container now
2024-11-28 17:24:40,065:INFO:_master_model_container: 16
2024-11-28 17:24:40,065:INFO:_display_container: 2
2024-11-28 17:24:40,066:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-11-28 17:24:40,066:INFO:create_model() successfully completed......................................
2024-11-28 17:24:40,128:INFO:SubProcess create_model() end ==================================
2024-11-28 17:24:40,128:INFO:Creating metrics dataframe
2024-11-28 17:24:40,138:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-11-28 17:24:40,146:INFO:Initializing create_model()
2024-11-28 17:24:40,146:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:24:40,146:INFO:Checking exceptions
2024-11-28 17:24:40,148:INFO:Importing libraries
2024-11-28 17:24:40,148:INFO:Copying training dataset
2024-11-28 17:24:40,152:INFO:Defining folds
2024-11-28 17:24:40,152:INFO:Declaring metric variables
2024-11-28 17:24:40,152:INFO:Importing untrained model
2024-11-28 17:24:40,152:INFO:Declaring custom model
2024-11-28 17:24:40,153:INFO:Random Forest Classifier Imported successfully
2024-11-28 17:24:40,154:INFO:Cross validation set to False
2024-11-28 17:24:40,154:INFO:Fitting Model
2024-11-28 17:24:40,328:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-11-28 17:24:40,328:INFO:create_model() successfully completed......................................
2024-11-28 17:24:40,406:INFO:Initializing create_model()
2024-11-28 17:24:40,406:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:24:40,406:INFO:Checking exceptions
2024-11-28 17:24:40,409:INFO:Importing libraries
2024-11-28 17:24:40,409:INFO:Copying training dataset
2024-11-28 17:24:40,412:INFO:Defining folds
2024-11-28 17:24:40,412:INFO:Declaring metric variables
2024-11-28 17:24:40,412:INFO:Importing untrained model
2024-11-28 17:24:40,412:INFO:Declaring custom model
2024-11-28 17:24:40,413:INFO:Gradient Boosting Classifier Imported successfully
2024-11-28 17:24:40,414:INFO:Cross validation set to False
2024-11-28 17:24:40,414:INFO:Fitting Model
2024-11-28 17:24:40,571:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-11-28 17:24:40,571:INFO:create_model() successfully completed......................................
2024-11-28 17:24:40,633:INFO:Initializing create_model()
2024-11-28 17:24:40,634:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator=<catboost.core.CatBoostClassifier object at 0x00000189BA1C9690>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:24:40,634:INFO:Checking exceptions
2024-11-28 17:24:40,636:INFO:Importing libraries
2024-11-28 17:24:40,636:INFO:Copying training dataset
2024-11-28 17:24:40,640:INFO:Defining folds
2024-11-28 17:24:40,640:INFO:Declaring metric variables
2024-11-28 17:24:40,641:INFO:Importing untrained model
2024-11-28 17:24:40,641:INFO:Declaring custom model
2024-11-28 17:24:40,641:INFO:CatBoost Classifier Imported successfully
2024-11-28 17:24:40,642:INFO:Cross validation set to False
2024-11-28 17:24:40,642:INFO:Fitting Model
2024-11-28 17:24:41,992:INFO:<catboost.core.CatBoostClassifier object at 0x00000189BA1CB7F0>
2024-11-28 17:24:41,992:INFO:create_model() successfully completed......................................
2024-11-28 17:24:42,053:INFO:Initializing create_model()
2024-11-28 17:24:42,054:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:24:42,054:INFO:Checking exceptions
2024-11-28 17:24:42,056:INFO:Importing libraries
2024-11-28 17:24:42,057:INFO:Copying training dataset
2024-11-28 17:24:42,060:INFO:Defining folds
2024-11-28 17:24:42,060:INFO:Declaring metric variables
2024-11-28 17:24:42,060:INFO:Importing untrained model
2024-11-28 17:24:42,060:INFO:Declaring custom model
2024-11-28 17:24:42,061:INFO:Ada Boost Classifier Imported successfully
2024-11-28 17:24:42,062:INFO:Cross validation set to False
2024-11-28 17:24:42,062:INFO:Fitting Model
2024-11-28 17:24:42,093:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:24:42,164:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2024-11-28 17:24:42,164:INFO:create_model() successfully completed......................................
2024-11-28 17:24:42,226:INFO:Initializing create_model()
2024-11-28 17:24:42,226:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:24:42,226:INFO:Checking exceptions
2024-11-28 17:24:42,228:INFO:Importing libraries
2024-11-28 17:24:42,229:INFO:Copying training dataset
2024-11-28 17:24:42,232:INFO:Defining folds
2024-11-28 17:24:42,232:INFO:Declaring metric variables
2024-11-28 17:24:42,232:INFO:Importing untrained model
2024-11-28 17:24:42,232:INFO:Declaring custom model
2024-11-28 17:24:42,233:INFO:Logistic Regression Imported successfully
2024-11-28 17:24:42,234:INFO:Cross validation set to False
2024-11-28 17:24:42,234:INFO:Fitting Model
2024-11-28 17:24:42,374:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:24:42,375:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-11-28 17:24:42,375:INFO:create_model() successfully completed......................................
2024-11-28 17:24:42,436:INFO:Initializing create_model()
2024-11-28 17:24:42,437:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:24:42,437:INFO:Checking exceptions
2024-11-28 17:24:42,440:INFO:Importing libraries
2024-11-28 17:24:42,440:INFO:Copying training dataset
2024-11-28 17:24:42,444:INFO:Defining folds
2024-11-28 17:24:42,444:INFO:Declaring metric variables
2024-11-28 17:24:42,444:INFO:Importing untrained model
2024-11-28 17:24:42,444:INFO:Declaring custom model
2024-11-28 17:24:42,444:INFO:Ridge Classifier Imported successfully
2024-11-28 17:24:42,445:INFO:Cross validation set to False
2024-11-28 17:24:42,445:INFO:Fitting Model
2024-11-28 17:24:42,479:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-11-28 17:24:42,479:INFO:create_model() successfully completed......................................
2024-11-28 17:24:42,541:INFO:Initializing create_model()
2024-11-28 17:24:42,541:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator=LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:24:42,542:INFO:Checking exceptions
2024-11-28 17:24:42,544:INFO:Importing libraries
2024-11-28 17:24:42,544:INFO:Copying training dataset
2024-11-28 17:24:42,547:INFO:Defining folds
2024-11-28 17:24:42,547:INFO:Declaring metric variables
2024-11-28 17:24:42,547:INFO:Importing untrained model
2024-11-28 17:24:42,547:INFO:Declaring custom model
2024-11-28 17:24:42,548:INFO:Linear Discriminant Analysis Imported successfully
2024-11-28 17:24:42,549:INFO:Cross validation set to False
2024-11-28 17:24:42,549:INFO:Fitting Model
2024-11-28 17:24:42,581:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-11-28 17:24:42,581:INFO:create_model() successfully completed......................................
2024-11-28 17:24:42,644:INFO:Initializing create_model()
2024-11-28 17:24:42,644:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:24:42,644:INFO:Checking exceptions
2024-11-28 17:24:42,647:INFO:Importing libraries
2024-11-28 17:24:42,647:INFO:Copying training dataset
2024-11-28 17:24:42,650:INFO:Defining folds
2024-11-28 17:24:42,650:INFO:Declaring metric variables
2024-11-28 17:24:42,650:INFO:Importing untrained model
2024-11-28 17:24:42,650:INFO:Declaring custom model
2024-11-28 17:24:42,651:INFO:Extra Trees Classifier Imported successfully
2024-11-28 17:24:42,652:INFO:Cross validation set to False
2024-11-28 17:24:42,652:INFO:Fitting Model
2024-11-28 17:24:42,783:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-11-28 17:24:42,783:INFO:create_model() successfully completed......................................
2024-11-28 17:24:42,845:INFO:Initializing create_model()
2024-11-28 17:24:42,845:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:24:42,846:INFO:Checking exceptions
2024-11-28 17:24:42,854:INFO:Importing libraries
2024-11-28 17:24:42,854:INFO:Copying training dataset
2024-11-28 17:24:42,860:INFO:Defining folds
2024-11-28 17:24:42,860:INFO:Declaring metric variables
2024-11-28 17:24:42,860:INFO:Importing untrained model
2024-11-28 17:24:42,860:INFO:Declaring custom model
2024-11-28 17:24:42,861:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-28 17:24:42,862:INFO:Cross validation set to False
2024-11-28 17:24:42,862:INFO:Fitting Model
2024-11-28 17:24:42,897:INFO:[LightGBM] [Info] Number of positive: 239, number of negative: 384
2024-11-28 17:24:42,897:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000111 seconds.
2024-11-28 17:24:42,897:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-11-28 17:24:42,897:INFO:[LightGBM] [Info] Total Bins 410
2024-11-28 17:24:42,898:INFO:[LightGBM] [Info] Number of data points in the train set: 623, number of used features: 12
2024-11-28 17:24:42,898:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383628 -> initscore=-0.474179
2024-11-28 17:24:42,898:INFO:[LightGBM] [Info] Start training from score -0.474179
2024-11-28 17:24:42,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-11-28 17:24:42,934:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-11-28 17:24:42,934:INFO:create_model() successfully completed......................................
2024-11-28 17:24:43,052:INFO:Initializing create_model()
2024-11-28 17:24:43,052:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:24:43,053:INFO:Checking exceptions
2024-11-28 17:24:43,056:INFO:Importing libraries
2024-11-28 17:24:43,056:INFO:Copying training dataset
2024-11-28 17:24:43,062:INFO:Defining folds
2024-11-28 17:24:43,062:INFO:Declaring metric variables
2024-11-28 17:24:43,062:INFO:Importing untrained model
2024-11-28 17:24:43,062:INFO:Declaring custom model
2024-11-28 17:24:43,063:INFO:Extreme Gradient Boosting Imported successfully
2024-11-28 17:24:43,064:INFO:Cross validation set to False
2024-11-28 17:24:43,064:INFO:Fitting Model
2024-11-28 17:24:43,171:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-11-28 17:24:43,171:INFO:create_model() successfully completed......................................
2024-11-28 17:24:43,233:INFO:Initializing create_model()
2024-11-28 17:24:43,234:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:24:43,234:INFO:Checking exceptions
2024-11-28 17:24:43,236:INFO:Importing libraries
2024-11-28 17:24:43,236:INFO:Copying training dataset
2024-11-28 17:24:43,241:INFO:Defining folds
2024-11-28 17:24:43,241:INFO:Declaring metric variables
2024-11-28 17:24:43,241:INFO:Importing untrained model
2024-11-28 17:24:43,241:INFO:Declaring custom model
2024-11-28 17:24:43,241:INFO:Naive Bayes Imported successfully
2024-11-28 17:24:43,242:INFO:Cross validation set to False
2024-11-28 17:24:43,242:INFO:Fitting Model
2024-11-28 17:24:43,276:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-11-28 17:24:43,276:INFO:create_model() successfully completed......................................
2024-11-28 17:24:43,337:INFO:Initializing create_model()
2024-11-28 17:24:43,337:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:24:43,337:INFO:Checking exceptions
2024-11-28 17:24:43,339:INFO:Importing libraries
2024-11-28 17:24:43,339:INFO:Copying training dataset
2024-11-28 17:24:43,343:INFO:Defining folds
2024-11-28 17:24:43,343:INFO:Declaring metric variables
2024-11-28 17:24:43,343:INFO:Importing untrained model
2024-11-28 17:24:43,343:INFO:Declaring custom model
2024-11-28 17:24:43,344:INFO:Decision Tree Classifier Imported successfully
2024-11-28 17:24:43,345:INFO:Cross validation set to False
2024-11-28 17:24:43,345:INFO:Fitting Model
2024-11-28 17:24:43,379:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2024-11-28 17:24:43,379:INFO:create_model() successfully completed......................................
2024-11-28 17:24:43,441:INFO:Initializing create_model()
2024-11-28 17:24:43,441:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:24:43,442:INFO:Checking exceptions
2024-11-28 17:24:43,444:INFO:Importing libraries
2024-11-28 17:24:43,444:INFO:Copying training dataset
2024-11-28 17:24:43,447:INFO:Defining folds
2024-11-28 17:24:43,447:INFO:Declaring metric variables
2024-11-28 17:24:43,447:INFO:Importing untrained model
2024-11-28 17:24:43,447:INFO:Declaring custom model
2024-11-28 17:24:43,448:INFO:Quadratic Discriminant Analysis Imported successfully
2024-11-28 17:24:43,448:INFO:Cross validation set to False
2024-11-28 17:24:43,449:INFO:Fitting Model
2024-11-28 17:24:43,481:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:24:43,482:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-11-28 17:24:43,482:INFO:create_model() successfully completed......................................
2024-11-28 17:24:43,542:INFO:Initializing create_model()
2024-11-28 17:24:43,542:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:24:43,543:INFO:Checking exceptions
2024-11-28 17:24:43,545:INFO:Importing libraries
2024-11-28 17:24:43,545:INFO:Copying training dataset
2024-11-28 17:24:43,549:INFO:Defining folds
2024-11-28 17:24:43,549:INFO:Declaring metric variables
2024-11-28 17:24:43,549:INFO:Importing untrained model
2024-11-28 17:24:43,549:INFO:Declaring custom model
2024-11-28 17:24:43,549:INFO:K Neighbors Classifier Imported successfully
2024-11-28 17:24:43,550:INFO:Cross validation set to False
2024-11-28 17:24:43,550:INFO:Fitting Model
2024-11-28 17:24:43,584:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-11-28 17:24:43,584:INFO:create_model() successfully completed......................................
2024-11-28 17:24:43,646:INFO:Initializing create_model()
2024-11-28 17:24:43,646:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator=DummyClassifier(constant=None, random_state=123, strategy='prior'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:24:43,646:INFO:Checking exceptions
2024-11-28 17:24:43,649:INFO:Importing libraries
2024-11-28 17:24:43,649:INFO:Copying training dataset
2024-11-28 17:24:43,652:INFO:Defining folds
2024-11-28 17:24:43,652:INFO:Declaring metric variables
2024-11-28 17:24:43,652:INFO:Importing untrained model
2024-11-28 17:24:43,652:INFO:Declaring custom model
2024-11-28 17:24:43,653:INFO:Dummy Classifier Imported successfully
2024-11-28 17:24:43,653:INFO:Cross validation set to False
2024-11-28 17:24:43,653:INFO:Fitting Model
2024-11-28 17:24:43,685:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-11-28 17:24:43,685:INFO:create_model() successfully completed......................................
2024-11-28 17:24:43,748:INFO:Initializing create_model()
2024-11-28 17:24:43,748:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:24:43,748:INFO:Checking exceptions
2024-11-28 17:24:43,750:INFO:Importing libraries
2024-11-28 17:24:43,751:INFO:Copying training dataset
2024-11-28 17:24:43,754:INFO:Defining folds
2024-11-28 17:24:43,754:INFO:Declaring metric variables
2024-11-28 17:24:43,754:INFO:Importing untrained model
2024-11-28 17:24:43,754:INFO:Declaring custom model
2024-11-28 17:24:43,755:INFO:SVM - Linear Kernel Imported successfully
2024-11-28 17:24:43,755:INFO:Cross validation set to False
2024-11-28 17:24:43,756:INFO:Fitting Model
2024-11-28 17:24:43,790:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-11-28 17:24:43,790:INFO:create_model() successfully completed......................................
2024-11-28 17:24:43,865:INFO:_master_model_container: 16
2024-11-28 17:24:43,865:INFO:_display_container: 2
2024-11-28 17:24:43,868:INFO:[RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), <catboost.core.CatBoostClassifier object at 0x00000189BA1CB7F0>, AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001), LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...), GaussianNB(priors=None, var_smoothing=1e-09), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best'), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform'), DummyClassifier(constant=None, random_state=123, strategy='prior'), SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)]
2024-11-28 17:24:43,868:INFO:compare_models() successfully completed......................................
2024-11-28 17:24:43,904:INFO:Initializing compare_models()
2024-11-28 17:24:43,904:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-11-28 17:24:43,904:INFO:Checking exceptions
2024-11-28 17:24:43,907:INFO:Preparing display monitor
2024-11-28 17:24:43,929:INFO:Initializing Logistic Regression
2024-11-28 17:24:43,929:INFO:Total runtime is 0.0 minutes
2024-11-28 17:24:43,932:INFO:SubProcess create_model() called ==================================
2024-11-28 17:24:43,932:INFO:Initializing create_model()
2024-11-28 17:24:43,932:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000189BA209480>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:24:43,932:INFO:Checking exceptions
2024-11-28 17:24:43,932:INFO:Importing libraries
2024-11-28 17:24:43,933:INFO:Copying training dataset
2024-11-28 17:24:43,939:INFO:Defining folds
2024-11-28 17:24:43,939:INFO:Declaring metric variables
2024-11-28 17:24:43,943:INFO:Importing untrained model
2024-11-28 17:24:43,946:INFO:Logistic Regression Imported successfully
2024-11-28 17:24:43,952:INFO:Starting cross validation
2024-11-28 17:24:43,953:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:24:44,161:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:24:44,167:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:24:44,177:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:24:44,181:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:24:44,192:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:24:44,200:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:24:44,339:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:24:44,344:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:24:44,359:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:24:44,362:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:24:44,395:INFO:Calculating mean and std
2024-11-28 17:24:44,395:INFO:Creating metrics dataframe
2024-11-28 17:24:44,397:INFO:Uploading results into container
2024-11-28 17:24:44,397:INFO:Uploading model into container now
2024-11-28 17:24:44,397:INFO:_master_model_container: 17
2024-11-28 17:24:44,397:INFO:_display_container: 3
2024-11-28 17:24:44,398:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-11-28 17:24:44,398:INFO:create_model() successfully completed......................................
2024-11-28 17:24:44,458:INFO:SubProcess create_model() end ==================================
2024-11-28 17:24:44,458:INFO:Creating metrics dataframe
2024-11-28 17:24:44,465:INFO:Initializing K Neighbors Classifier
2024-11-28 17:24:44,465:INFO:Total runtime is 0.008921428521474203 minutes
2024-11-28 17:24:44,469:INFO:SubProcess create_model() called ==================================
2024-11-28 17:24:44,469:INFO:Initializing create_model()
2024-11-28 17:24:44,469:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000189BA209480>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:24:44,469:INFO:Checking exceptions
2024-11-28 17:24:44,469:INFO:Importing libraries
2024-11-28 17:24:44,469:INFO:Copying training dataset
2024-11-28 17:24:44,475:INFO:Defining folds
2024-11-28 17:24:44,475:INFO:Declaring metric variables
2024-11-28 17:24:44,478:INFO:Importing untrained model
2024-11-28 17:24:44,481:INFO:K Neighbors Classifier Imported successfully
2024-11-28 17:24:44,489:INFO:Starting cross validation
2024-11-28 17:24:44,491:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:24:44,782:INFO:Calculating mean and std
2024-11-28 17:24:44,783:INFO:Creating metrics dataframe
2024-11-28 17:24:44,784:INFO:Uploading results into container
2024-11-28 17:24:44,785:INFO:Uploading model into container now
2024-11-28 17:24:44,785:INFO:_master_model_container: 18
2024-11-28 17:24:44,785:INFO:_display_container: 3
2024-11-28 17:24:44,786:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-11-28 17:24:44,786:INFO:create_model() successfully completed......................................
2024-11-28 17:24:44,847:INFO:SubProcess create_model() end ==================================
2024-11-28 17:24:44,847:INFO:Creating metrics dataframe
2024-11-28 17:24:44,852:INFO:Initializing Naive Bayes
2024-11-28 17:24:44,852:INFO:Total runtime is 0.015386597315470377 minutes
2024-11-28 17:24:44,855:INFO:SubProcess create_model() called ==================================
2024-11-28 17:24:44,856:INFO:Initializing create_model()
2024-11-28 17:24:44,856:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000189BA209480>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:24:44,856:INFO:Checking exceptions
2024-11-28 17:24:44,856:INFO:Importing libraries
2024-11-28 17:24:44,856:INFO:Copying training dataset
2024-11-28 17:24:44,860:INFO:Defining folds
2024-11-28 17:24:44,860:INFO:Declaring metric variables
2024-11-28 17:24:44,863:INFO:Importing untrained model
2024-11-28 17:24:44,866:INFO:Naive Bayes Imported successfully
2024-11-28 17:24:44,874:INFO:Starting cross validation
2024-11-28 17:24:44,876:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:24:45,046:INFO:Calculating mean and std
2024-11-28 17:24:45,047:INFO:Creating metrics dataframe
2024-11-28 17:24:45,050:INFO:Uploading results into container
2024-11-28 17:24:45,050:INFO:Uploading model into container now
2024-11-28 17:24:45,050:INFO:_master_model_container: 19
2024-11-28 17:24:45,051:INFO:_display_container: 3
2024-11-28 17:24:45,051:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-11-28 17:24:45,051:INFO:create_model() successfully completed......................................
2024-11-28 17:24:45,110:INFO:SubProcess create_model() end ==================================
2024-11-28 17:24:45,110:INFO:Creating metrics dataframe
2024-11-28 17:24:45,116:INFO:Initializing Decision Tree Classifier
2024-11-28 17:24:45,116:INFO:Total runtime is 0.019771353403727213 minutes
2024-11-28 17:24:45,118:INFO:SubProcess create_model() called ==================================
2024-11-28 17:24:45,118:INFO:Initializing create_model()
2024-11-28 17:24:45,118:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000189BA209480>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:24:45,118:INFO:Checking exceptions
2024-11-28 17:24:45,118:INFO:Importing libraries
2024-11-28 17:24:45,118:INFO:Copying training dataset
2024-11-28 17:24:45,123:INFO:Defining folds
2024-11-28 17:24:45,123:INFO:Declaring metric variables
2024-11-28 17:24:45,125:INFO:Importing untrained model
2024-11-28 17:24:45,128:INFO:Decision Tree Classifier Imported successfully
2024-11-28 17:24:45,134:INFO:Starting cross validation
2024-11-28 17:24:45,135:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:24:45,309:INFO:Calculating mean and std
2024-11-28 17:24:45,312:INFO:Creating metrics dataframe
2024-11-28 17:24:45,318:INFO:Uploading results into container
2024-11-28 17:24:45,319:INFO:Uploading model into container now
2024-11-28 17:24:45,320:INFO:_master_model_container: 20
2024-11-28 17:24:45,321:INFO:_display_container: 3
2024-11-28 17:24:45,322:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2024-11-28 17:24:45,322:INFO:create_model() successfully completed......................................
2024-11-28 17:24:45,417:INFO:SubProcess create_model() end ==================================
2024-11-28 17:24:45,417:INFO:Creating metrics dataframe
2024-11-28 17:24:45,425:INFO:Initializing SVM - Linear Kernel
2024-11-28 17:24:45,425:INFO:Total runtime is 0.024935301144917807 minutes
2024-11-28 17:24:45,428:INFO:SubProcess create_model() called ==================================
2024-11-28 17:24:45,428:INFO:Initializing create_model()
2024-11-28 17:24:45,428:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000189BA209480>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:24:45,428:INFO:Checking exceptions
2024-11-28 17:24:45,428:INFO:Importing libraries
2024-11-28 17:24:45,428:INFO:Copying training dataset
2024-11-28 17:24:45,433:INFO:Defining folds
2024-11-28 17:24:45,433:INFO:Declaring metric variables
2024-11-28 17:24:45,436:INFO:Importing untrained model
2024-11-28 17:24:45,441:INFO:SVM - Linear Kernel Imported successfully
2024-11-28 17:24:45,447:INFO:Starting cross validation
2024-11-28 17:24:45,448:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:24:45,618:INFO:Calculating mean and std
2024-11-28 17:24:45,622:INFO:Creating metrics dataframe
2024-11-28 17:24:45,628:INFO:Uploading results into container
2024-11-28 17:24:45,629:INFO:Uploading model into container now
2024-11-28 17:24:45,630:INFO:_master_model_container: 21
2024-11-28 17:24:45,630:INFO:_display_container: 3
2024-11-28 17:24:45,631:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-11-28 17:24:45,631:INFO:create_model() successfully completed......................................
2024-11-28 17:24:45,697:INFO:SubProcess create_model() end ==================================
2024-11-28 17:24:45,697:INFO:Creating metrics dataframe
2024-11-28 17:24:45,703:INFO:Initializing Ridge Classifier
2024-11-28 17:24:45,703:INFO:Total runtime is 0.02955772082010905 minutes
2024-11-28 17:24:45,706:INFO:SubProcess create_model() called ==================================
2024-11-28 17:24:45,707:INFO:Initializing create_model()
2024-11-28 17:24:45,707:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000189BA209480>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:24:45,707:INFO:Checking exceptions
2024-11-28 17:24:45,707:INFO:Importing libraries
2024-11-28 17:24:45,707:INFO:Copying training dataset
2024-11-28 17:24:45,710:INFO:Defining folds
2024-11-28 17:24:45,711:INFO:Declaring metric variables
2024-11-28 17:24:45,713:INFO:Importing untrained model
2024-11-28 17:24:45,716:INFO:Ridge Classifier Imported successfully
2024-11-28 17:24:45,723:INFO:Starting cross validation
2024-11-28 17:24:45,724:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:24:45,898:INFO:Calculating mean and std
2024-11-28 17:24:45,902:INFO:Creating metrics dataframe
2024-11-28 17:24:45,910:INFO:Uploading results into container
2024-11-28 17:24:45,912:INFO:Uploading model into container now
2024-11-28 17:24:45,913:INFO:_master_model_container: 22
2024-11-28 17:24:45,914:INFO:_display_container: 3
2024-11-28 17:24:45,915:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-11-28 17:24:45,916:INFO:create_model() successfully completed......................................
2024-11-28 17:24:46,024:INFO:SubProcess create_model() end ==================================
2024-11-28 17:24:46,024:INFO:Creating metrics dataframe
2024-11-28 17:24:46,032:INFO:Initializing Random Forest Classifier
2024-11-28 17:24:46,032:INFO:Total runtime is 0.035052716732025146 minutes
2024-11-28 17:24:46,034:INFO:SubProcess create_model() called ==================================
2024-11-28 17:24:46,035:INFO:Initializing create_model()
2024-11-28 17:24:46,035:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000189BA209480>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:24:46,035:INFO:Checking exceptions
2024-11-28 17:24:46,035:INFO:Importing libraries
2024-11-28 17:24:46,035:INFO:Copying training dataset
2024-11-28 17:24:46,040:INFO:Defining folds
2024-11-28 17:24:46,040:INFO:Declaring metric variables
2024-11-28 17:24:46,042:INFO:Importing untrained model
2024-11-28 17:24:46,046:INFO:Random Forest Classifier Imported successfully
2024-11-28 17:24:46,053:INFO:Starting cross validation
2024-11-28 17:24:46,054:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:24:46,655:INFO:Calculating mean and std
2024-11-28 17:24:46,656:INFO:Creating metrics dataframe
2024-11-28 17:24:46,658:INFO:Uploading results into container
2024-11-28 17:24:46,659:INFO:Uploading model into container now
2024-11-28 17:24:46,659:INFO:_master_model_container: 23
2024-11-28 17:24:46,659:INFO:_display_container: 3
2024-11-28 17:24:46,660:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-11-28 17:24:46,660:INFO:create_model() successfully completed......................................
2024-11-28 17:24:46,724:INFO:SubProcess create_model() end ==================================
2024-11-28 17:24:46,724:INFO:Creating metrics dataframe
2024-11-28 17:24:46,732:INFO:Initializing Quadratic Discriminant Analysis
2024-11-28 17:24:46,732:INFO:Total runtime is 0.04670679966608683 minutes
2024-11-28 17:24:46,736:INFO:SubProcess create_model() called ==================================
2024-11-28 17:24:46,736:INFO:Initializing create_model()
2024-11-28 17:24:46,736:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000189BA209480>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:24:46,736:INFO:Checking exceptions
2024-11-28 17:24:46,736:INFO:Importing libraries
2024-11-28 17:24:46,736:INFO:Copying training dataset
2024-11-28 17:24:46,741:INFO:Defining folds
2024-11-28 17:24:46,741:INFO:Declaring metric variables
2024-11-28 17:24:46,744:INFO:Importing untrained model
2024-11-28 17:24:46,746:INFO:Quadratic Discriminant Analysis Imported successfully
2024-11-28 17:24:46,788:INFO:Starting cross validation
2024-11-28 17:24:46,790:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:24:46,844:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:24:46,847:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:24:46,848:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:24:46,850:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:24:46,850:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:24:46,864:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:24:46,915:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:24:46,921:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:24:46,923:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:24:46,927:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-28 17:24:46,963:INFO:Calculating mean and std
2024-11-28 17:24:46,967:INFO:Creating metrics dataframe
2024-11-28 17:24:46,972:INFO:Uploading results into container
2024-11-28 17:24:46,974:INFO:Uploading model into container now
2024-11-28 17:24:46,975:INFO:_master_model_container: 24
2024-11-28 17:24:46,975:INFO:_display_container: 3
2024-11-28 17:24:46,976:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-11-28 17:24:46,976:INFO:create_model() successfully completed......................................
2024-11-28 17:24:47,091:INFO:SubProcess create_model() end ==================================
2024-11-28 17:24:47,091:INFO:Creating metrics dataframe
2024-11-28 17:24:47,109:INFO:Initializing Ada Boost Classifier
2024-11-28 17:24:47,110:INFO:Total runtime is 0.053011739253997804 minutes
2024-11-28 17:24:47,115:INFO:SubProcess create_model() called ==================================
2024-11-28 17:24:47,115:INFO:Initializing create_model()
2024-11-28 17:24:47,115:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000189BA209480>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:24:47,115:INFO:Checking exceptions
2024-11-28 17:24:47,116:INFO:Importing libraries
2024-11-28 17:24:47,116:INFO:Copying training dataset
2024-11-28 17:24:47,123:INFO:Defining folds
2024-11-28 17:24:47,124:INFO:Declaring metric variables
2024-11-28 17:24:47,129:INFO:Importing untrained model
2024-11-28 17:24:47,133:INFO:Ada Boost Classifier Imported successfully
2024-11-28 17:24:47,141:INFO:Starting cross validation
2024-11-28 17:24:47,143:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:24:47,198:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:24:47,199:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:24:47,199:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:24:47,201:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:24:47,201:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:24:47,210:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:24:47,362:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:24:47,363:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:24:47,364:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:24:47,368:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:24:47,490:INFO:Calculating mean and std
2024-11-28 17:24:47,493:INFO:Creating metrics dataframe
2024-11-28 17:24:47,497:INFO:Uploading results into container
2024-11-28 17:24:47,498:INFO:Uploading model into container now
2024-11-28 17:24:47,499:INFO:_master_model_container: 25
2024-11-28 17:24:47,499:INFO:_display_container: 3
2024-11-28 17:24:47,500:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2024-11-28 17:24:47,500:INFO:create_model() successfully completed......................................
2024-11-28 17:24:47,598:INFO:SubProcess create_model() end ==================================
2024-11-28 17:24:47,599:INFO:Creating metrics dataframe
2024-11-28 17:24:47,616:INFO:Initializing Gradient Boosting Classifier
2024-11-28 17:24:47,617:INFO:Total runtime is 0.06145707766215007 minutes
2024-11-28 17:24:47,622:INFO:SubProcess create_model() called ==================================
2024-11-28 17:24:47,623:INFO:Initializing create_model()
2024-11-28 17:24:47,623:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000189BA209480>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:24:47,623:INFO:Checking exceptions
2024-11-28 17:24:47,623:INFO:Importing libraries
2024-11-28 17:24:47,623:INFO:Copying training dataset
2024-11-28 17:24:47,633:INFO:Defining folds
2024-11-28 17:24:47,633:INFO:Declaring metric variables
2024-11-28 17:24:47,638:INFO:Importing untrained model
2024-11-28 17:24:47,643:INFO:Gradient Boosting Classifier Imported successfully
2024-11-28 17:24:47,652:INFO:Starting cross validation
2024-11-28 17:24:47,653:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:24:48,093:INFO:Calculating mean and std
2024-11-28 17:24:48,097:INFO:Creating metrics dataframe
2024-11-28 17:24:48,102:INFO:Uploading results into container
2024-11-28 17:24:48,103:INFO:Uploading model into container now
2024-11-28 17:24:48,104:INFO:_master_model_container: 26
2024-11-28 17:24:48,105:INFO:_display_container: 3
2024-11-28 17:24:48,107:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-11-28 17:24:48,107:INFO:create_model() successfully completed......................................
2024-11-28 17:24:48,190:INFO:SubProcess create_model() end ==================================
2024-11-28 17:24:48,190:INFO:Creating metrics dataframe
2024-11-28 17:24:48,197:INFO:Initializing Linear Discriminant Analysis
2024-11-28 17:24:48,197:INFO:Total runtime is 0.07113072077433269 minutes
2024-11-28 17:24:48,200:INFO:SubProcess create_model() called ==================================
2024-11-28 17:24:48,200:INFO:Initializing create_model()
2024-11-28 17:24:48,200:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000189BA209480>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:24:48,200:INFO:Checking exceptions
2024-11-28 17:24:48,201:INFO:Importing libraries
2024-11-28 17:24:48,201:INFO:Copying training dataset
2024-11-28 17:24:48,205:INFO:Defining folds
2024-11-28 17:24:48,205:INFO:Declaring metric variables
2024-11-28 17:24:48,208:INFO:Importing untrained model
2024-11-28 17:24:48,212:INFO:Linear Discriminant Analysis Imported successfully
2024-11-28 17:24:48,219:INFO:Starting cross validation
2024-11-28 17:24:48,220:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:24:48,390:INFO:Calculating mean and std
2024-11-28 17:24:48,393:INFO:Creating metrics dataframe
2024-11-28 17:24:48,397:INFO:Uploading results into container
2024-11-28 17:24:48,398:INFO:Uploading model into container now
2024-11-28 17:24:48,399:INFO:_master_model_container: 27
2024-11-28 17:24:48,399:INFO:_display_container: 3
2024-11-28 17:24:48,400:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-11-28 17:24:48,400:INFO:create_model() successfully completed......................................
2024-11-28 17:24:48,486:INFO:SubProcess create_model() end ==================================
2024-11-28 17:24:48,486:INFO:Creating metrics dataframe
2024-11-28 17:24:48,496:INFO:Initializing Extra Trees Classifier
2024-11-28 17:24:48,496:INFO:Total runtime is 0.07611763874689739 minutes
2024-11-28 17:24:48,500:INFO:SubProcess create_model() called ==================================
2024-11-28 17:24:48,500:INFO:Initializing create_model()
2024-11-28 17:24:48,500:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000189BA209480>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:24:48,500:INFO:Checking exceptions
2024-11-28 17:24:48,500:INFO:Importing libraries
2024-11-28 17:24:48,500:INFO:Copying training dataset
2024-11-28 17:24:48,505:INFO:Defining folds
2024-11-28 17:24:48,505:INFO:Declaring metric variables
2024-11-28 17:24:48,510:INFO:Importing untrained model
2024-11-28 17:24:48,513:INFO:Extra Trees Classifier Imported successfully
2024-11-28 17:24:48,519:INFO:Starting cross validation
2024-11-28 17:24:48,521:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:24:49,068:INFO:Calculating mean and std
2024-11-28 17:24:49,071:INFO:Creating metrics dataframe
2024-11-28 17:24:49,077:INFO:Uploading results into container
2024-11-28 17:24:49,078:INFO:Uploading model into container now
2024-11-28 17:24:49,079:INFO:_master_model_container: 28
2024-11-28 17:24:49,079:INFO:_display_container: 3
2024-11-28 17:24:49,080:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2024-11-28 17:24:49,081:INFO:create_model() successfully completed......................................
2024-11-28 17:24:49,168:INFO:SubProcess create_model() end ==================================
2024-11-28 17:24:49,168:INFO:Creating metrics dataframe
2024-11-28 17:24:49,178:INFO:Initializing Extreme Gradient Boosting
2024-11-28 17:24:49,178:INFO:Total runtime is 0.08747069040934247 minutes
2024-11-28 17:24:49,181:INFO:SubProcess create_model() called ==================================
2024-11-28 17:24:49,182:INFO:Initializing create_model()
2024-11-28 17:24:49,182:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator=xgboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000189BA209480>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:24:49,182:INFO:Checking exceptions
2024-11-28 17:24:49,182:INFO:Importing libraries
2024-11-28 17:24:49,182:INFO:Copying training dataset
2024-11-28 17:24:49,187:INFO:Defining folds
2024-11-28 17:24:49,187:INFO:Declaring metric variables
2024-11-28 17:24:49,190:INFO:Importing untrained model
2024-11-28 17:24:49,194:INFO:Extreme Gradient Boosting Imported successfully
2024-11-28 17:24:49,200:INFO:Starting cross validation
2024-11-28 17:24:49,202:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:24:49,471:INFO:Calculating mean and std
2024-11-28 17:24:49,475:INFO:Creating metrics dataframe
2024-11-28 17:24:49,479:INFO:Uploading results into container
2024-11-28 17:24:49,480:INFO:Uploading model into container now
2024-11-28 17:24:49,481:INFO:_master_model_container: 29
2024-11-28 17:24:49,481:INFO:_display_container: 3
2024-11-28 17:24:49,483:INFO:XGBClassifier(base_score=None, booster='gbtree', callbacks=None,
              colsample_bylevel=None, colsample_bynode=None,
              colsample_bytree=None, device='cpu', early_stopping_rounds=None,
              enable_categorical=False, eval_metric=None, feature_types=None,
              gamma=None, grow_policy=None, importance_type=None,
              interaction_constraints=None, learning_rate=None, max_bin=None,
              max_cat_threshold=None, max_cat_to_onehot=None,
              max_delta_step=None, max_depth=None, max_leaves=None,
              min_child_weight=None, missing=nan, monotone_constraints=None,
              multi_strategy=None, n_estimators=None, n_jobs=-1,
              num_parallel_tree=None, objective='binary:logistic', ...)
2024-11-28 17:24:49,483:INFO:create_model() successfully completed......................................
2024-11-28 17:24:49,581:INFO:SubProcess create_model() end ==================================
2024-11-28 17:24:49,581:INFO:Creating metrics dataframe
2024-11-28 17:24:49,600:INFO:Initializing Light Gradient Boosting Machine
2024-11-28 17:24:49,600:INFO:Total runtime is 0.09452005227406822 minutes
2024-11-28 17:24:49,606:INFO:SubProcess create_model() called ==================================
2024-11-28 17:24:49,606:INFO:Initializing create_model()
2024-11-28 17:24:49,607:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000189BA209480>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:24:49,607:INFO:Checking exceptions
2024-11-28 17:24:49,607:INFO:Importing libraries
2024-11-28 17:24:49,607:INFO:Copying training dataset
2024-11-28 17:24:49,612:INFO:Defining folds
2024-11-28 17:24:49,613:INFO:Declaring metric variables
2024-11-28 17:24:49,616:INFO:Importing untrained model
2024-11-28 17:24:49,620:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-28 17:24:49,628:INFO:Starting cross validation
2024-11-28 17:24:49,629:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:24:50,276:INFO:Calculating mean and std
2024-11-28 17:24:50,277:INFO:Creating metrics dataframe
2024-11-28 17:24:50,280:INFO:Uploading results into container
2024-11-28 17:24:50,280:INFO:Uploading model into container now
2024-11-28 17:24:50,280:INFO:_master_model_container: 30
2024-11-28 17:24:50,280:INFO:_display_container: 3
2024-11-28 17:24:50,281:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-11-28 17:24:50,281:INFO:create_model() successfully completed......................................
2024-11-28 17:24:50,337:INFO:SubProcess create_model() end ==================================
2024-11-28 17:24:50,337:INFO:Creating metrics dataframe
2024-11-28 17:24:50,346:INFO:Initializing CatBoost Classifier
2024-11-28 17:24:50,346:INFO:Total runtime is 0.10695295731226606 minutes
2024-11-28 17:24:50,349:INFO:SubProcess create_model() called ==================================
2024-11-28 17:24:50,349:INFO:Initializing create_model()
2024-11-28 17:24:50,350:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator=catboost, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000189BA209480>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:24:50,350:INFO:Checking exceptions
2024-11-28 17:24:50,350:INFO:Importing libraries
2024-11-28 17:24:50,350:INFO:Copying training dataset
2024-11-28 17:24:50,354:INFO:Defining folds
2024-11-28 17:24:50,354:INFO:Declaring metric variables
2024-11-28 17:24:50,356:INFO:Importing untrained model
2024-11-28 17:24:50,359:INFO:CatBoost Classifier Imported successfully
2024-11-28 17:24:50,366:INFO:Starting cross validation
2024-11-28 17:24:50,368:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:24:55,102:INFO:Calculating mean and std
2024-11-28 17:24:55,107:INFO:Creating metrics dataframe
2024-11-28 17:24:55,118:INFO:Uploading results into container
2024-11-28 17:24:55,120:INFO:Uploading model into container now
2024-11-28 17:24:55,122:INFO:_master_model_container: 31
2024-11-28 17:24:55,123:INFO:_display_container: 3
2024-11-28 17:24:55,124:INFO:<catboost.core.CatBoostClassifier object at 0x00000189BA2AE680>
2024-11-28 17:24:55,124:INFO:create_model() successfully completed......................................
2024-11-28 17:24:55,271:INFO:SubProcess create_model() end ==================================
2024-11-28 17:24:55,271:INFO:Creating metrics dataframe
2024-11-28 17:24:55,285:INFO:Initializing Dummy Classifier
2024-11-28 17:24:55,285:INFO:Total runtime is 0.18926969766616825 minutes
2024-11-28 17:24:55,290:INFO:SubProcess create_model() called ==================================
2024-11-28 17:24:55,290:INFO:Initializing create_model()
2024-11-28 17:24:55,291:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000189BA209480>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:24:55,291:INFO:Checking exceptions
2024-11-28 17:24:55,291:INFO:Importing libraries
2024-11-28 17:24:55,291:INFO:Copying training dataset
2024-11-28 17:24:55,296:INFO:Defining folds
2024-11-28 17:24:55,297:INFO:Declaring metric variables
2024-11-28 17:24:55,301:INFO:Importing untrained model
2024-11-28 17:24:55,304:INFO:Dummy Classifier Imported successfully
2024-11-28 17:24:55,315:INFO:Starting cross validation
2024-11-28 17:24:55,317:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:24:55,397:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:24:55,398:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:24:55,398:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:24:55,400:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:24:55,401:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:24:55,434:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:24:55,466:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:24:55,466:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:24:55,467:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:24:55,470:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-28 17:24:55,488:INFO:Calculating mean and std
2024-11-28 17:24:55,492:INFO:Creating metrics dataframe
2024-11-28 17:24:55,499:INFO:Uploading results into container
2024-11-28 17:24:55,501:INFO:Uploading model into container now
2024-11-28 17:24:55,502:INFO:_master_model_container: 32
2024-11-28 17:24:55,502:INFO:_display_container: 3
2024-11-28 17:24:55,503:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-11-28 17:24:55,503:INFO:create_model() successfully completed......................................
2024-11-28 17:24:55,613:INFO:SubProcess create_model() end ==================================
2024-11-28 17:24:55,613:INFO:Creating metrics dataframe
2024-11-28 17:24:55,626:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-11-28 17:24:55,634:INFO:Initializing create_model()
2024-11-28 17:24:55,634:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:24:55,634:INFO:Checking exceptions
2024-11-28 17:24:55,636:INFO:Importing libraries
2024-11-28 17:24:55,636:INFO:Copying training dataset
2024-11-28 17:24:55,640:INFO:Defining folds
2024-11-28 17:24:55,640:INFO:Declaring metric variables
2024-11-28 17:24:55,640:INFO:Importing untrained model
2024-11-28 17:24:55,640:INFO:Declaring custom model
2024-11-28 17:24:55,641:INFO:Random Forest Classifier Imported successfully
2024-11-28 17:24:55,641:INFO:Cross validation set to False
2024-11-28 17:24:55,641:INFO:Fitting Model
2024-11-28 17:24:55,798:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2024-11-28 17:24:55,798:INFO:create_model() successfully completed......................................
2024-11-28 17:24:55,859:INFO:Initializing create_model()
2024-11-28 17:24:55,860:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:24:55,860:INFO:Checking exceptions
2024-11-28 17:24:55,862:INFO:Importing libraries
2024-11-28 17:24:55,862:INFO:Copying training dataset
2024-11-28 17:24:55,865:INFO:Defining folds
2024-11-28 17:24:55,865:INFO:Declaring metric variables
2024-11-28 17:24:55,866:INFO:Importing untrained model
2024-11-28 17:24:55,866:INFO:Declaring custom model
2024-11-28 17:24:55,866:INFO:Gradient Boosting Classifier Imported successfully
2024-11-28 17:24:55,867:INFO:Cross validation set to False
2024-11-28 17:24:55,867:INFO:Fitting Model
2024-11-28 17:24:56,024:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-11-28 17:24:56,024:INFO:create_model() successfully completed......................................
2024-11-28 17:24:56,085:INFO:Initializing create_model()
2024-11-28 17:24:56,085:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator=<catboost.core.CatBoostClassifier object at 0x00000189BA2AE680>, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:24:56,085:INFO:Checking exceptions
2024-11-28 17:24:56,088:INFO:Importing libraries
2024-11-28 17:24:56,088:INFO:Copying training dataset
2024-11-28 17:24:56,092:INFO:Defining folds
2024-11-28 17:24:56,092:INFO:Declaring metric variables
2024-11-28 17:24:56,092:INFO:Importing untrained model
2024-11-28 17:24:56,092:INFO:Declaring custom model
2024-11-28 17:24:56,093:INFO:CatBoost Classifier Imported successfully
2024-11-28 17:24:56,094:INFO:Cross validation set to False
2024-11-28 17:24:56,094:INFO:Fitting Model
2024-11-28 17:24:57,435:INFO:<catboost.core.CatBoostClassifier object at 0x00000189BA2AD870>
2024-11-28 17:24:57,435:INFO:create_model() successfully completed......................................
2024-11-28 17:24:57,496:INFO:Initializing create_model()
2024-11-28 17:24:57,496:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator=AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:24:57,496:INFO:Checking exceptions
2024-11-28 17:24:57,498:INFO:Importing libraries
2024-11-28 17:24:57,498:INFO:Copying training dataset
2024-11-28 17:24:57,502:INFO:Defining folds
2024-11-28 17:24:57,502:INFO:Declaring metric variables
2024-11-28 17:24:57,502:INFO:Importing untrained model
2024-11-28 17:24:57,502:INFO:Declaring custom model
2024-11-28 17:24:57,503:INFO:Ada Boost Classifier Imported successfully
2024-11-28 17:24:57,503:INFO:Cross validation set to False
2024-11-28 17:24:57,504:INFO:Fitting Model
2024-11-28 17:24:57,537:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:24:57,607:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2024-11-28 17:24:57,607:INFO:create_model() successfully completed......................................
2024-11-28 17:24:57,668:INFO:Initializing create_model()
2024-11-28 17:24:57,668:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:24:57,669:INFO:Checking exceptions
2024-11-28 17:24:57,671:INFO:Importing libraries
2024-11-28 17:24:57,671:INFO:Copying training dataset
2024-11-28 17:24:57,675:INFO:Defining folds
2024-11-28 17:24:57,675:INFO:Declaring metric variables
2024-11-28 17:24:57,675:INFO:Importing untrained model
2024-11-28 17:24:57,675:INFO:Declaring custom model
2024-11-28 17:24:57,676:INFO:Logistic Regression Imported successfully
2024-11-28 17:24:57,676:INFO:Cross validation set to False
2024-11-28 17:24:57,676:INFO:Fitting Model
2024-11-28 17:24:57,811:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:24:57,812:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-11-28 17:24:57,812:INFO:create_model() successfully completed......................................
2024-11-28 17:24:57,892:INFO:_master_model_container: 32
2024-11-28 17:24:57,892:INFO:_display_container: 3
2024-11-28 17:24:57,893:INFO:[RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), <catboost.core.CatBoostClassifier object at 0x00000189BA2AD870>, AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)]
2024-11-28 17:24:57,893:INFO:compare_models() successfully completed......................................
2024-11-28 17:24:57,894:INFO:Initializing blend_models()
2024-11-28 17:24:57,894:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator_list=[RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), <catboost.core.CatBoostClassifier object at 0x00000189BA2AD870>, AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2024-11-28 17:24:57,894:INFO:Checking exceptions
2024-11-28 17:24:57,908:INFO:Importing libraries
2024-11-28 17:24:57,908:INFO:Copying training dataset
2024-11-28 17:24:57,911:INFO:Getting model names
2024-11-28 17:24:57,914:INFO:SubProcess create_model() called ==================================
2024-11-28 17:24:57,918:INFO:Initializing create_model()
2024-11-28 17:24:57,918:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator=VotingClassifier(estimators=[('Random Forest Classifier',
                              RandomForestClassifier(bootstrap=True,
                                                     ccp_alpha=0.0,
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs...
                                                 random_state=123)),
                             ('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000189CED39B40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:24:57,918:INFO:Checking exceptions
2024-11-28 17:24:57,918:INFO:Importing libraries
2024-11-28 17:24:57,918:INFO:Copying training dataset
2024-11-28 17:24:57,923:INFO:Defining folds
2024-11-28 17:24:57,923:INFO:Declaring metric variables
2024-11-28 17:24:57,926:INFO:Importing untrained model
2024-11-28 17:24:57,926:INFO:Declaring custom model
2024-11-28 17:24:57,932:INFO:Voting Classifier Imported successfully
2024-11-28 17:24:57,942:INFO:Starting cross validation
2024-11-28 17:24:57,943:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:24:58,090:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:24:58,094:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:24:58,125:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:24:58,128:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:24:58,135:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:24:58,303:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:24:58,623:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:24:58,665:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:24:58,669:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:24:58,747:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:24:58,815:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:24:58,909:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:01,063:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:01,097:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:01,319:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:01,358:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:01,575:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:01,579:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:01,818:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:01,868:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:03,708:INFO:Calculating mean and std
2024-11-28 17:25:03,712:INFO:Creating metrics dataframe
2024-11-28 17:25:03,735:INFO:Finalizing model
2024-11-28 17:25:03,863:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:04,023:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:05,322:INFO:Uploading results into container
2024-11-28 17:25:05,325:INFO:Uploading model into container now
2024-11-28 17:25:05,326:INFO:_master_model_container: 33
2024-11-28 17:25:05,326:INFO:_display_container: 4
2024-11-28 17:25:05,351:INFO:VotingClassifier(estimators=[('Random Forest Classifier',
                              RandomForestClassifier(bootstrap=True,
                                                     ccp_alpha=0.0,
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs...
                                                 random_state=123)),
                             ('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2024-11-28 17:25:05,351:INFO:create_model() successfully completed......................................
2024-11-28 17:25:05,447:INFO:SubProcess create_model() end ==================================
2024-11-28 17:25:05,454:INFO:_master_model_container: 33
2024-11-28 17:25:05,454:INFO:_display_container: 4
2024-11-28 17:25:05,459:INFO:VotingClassifier(estimators=[('Random Forest Classifier',
                              RandomForestClassifier(bootstrap=True,
                                                     ccp_alpha=0.0,
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs...
                                                 random_state=123)),
                             ('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2024-11-28 17:25:05,459:INFO:blend_models() successfully completed......................................
2024-11-28 17:25:05,533:INFO:Initializing tune_model()
2024-11-28 17:25:05,534:INFO:tune_model(estimator=VotingClassifier(estimators=[('Random Forest Classifier',
                              RandomForestClassifier(bootstrap=True,
                                                     ccp_alpha=0.0,
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs...
                                                 random_state=123)),
                             ('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>)
2024-11-28 17:25:05,534:INFO:Checking exceptions
2024-11-28 17:25:05,546:INFO:Copying training dataset
2024-11-28 17:25:05,551:INFO:Checking base model
2024-11-28 17:25:05,551:INFO:Base model : Voting Classifier
2024-11-28 17:25:05,551:INFO:Model has a special tunable class, using that
2024-11-28 17:25:05,555:INFO:Declaring metric variables
2024-11-28 17:25:05,559:INFO:Defining Hyperparameters
2024-11-28 17:25:05,633:INFO:Tuning with n_jobs=-1
2024-11-28 17:25:05,634:INFO:Initializing RandomizedSearchCV
2024-11-28 17:25:05,721:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:05,721:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:05,722:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:05,740:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:05,748:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:06,225:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:06,228:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:06,231:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:06,272:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:06,371:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:06,382:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:06,766:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:08,379:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:08,480:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:08,901:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:08,995:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:09,504:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:09,589:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:09,793:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:10,004:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:10,109:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:10,309:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:10,310:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:10,835:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:11,819:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:11,920:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:12,341:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:12,467:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:13,021:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:13,152:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:13,266:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:13,532:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:13,652:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:13,837:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:14,020:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:14,555:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:15,753:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:15,828:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:16,316:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:16,389:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:16,922:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:17,006:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:17,067:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:17,194:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:17,502:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:17,520:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:17,571:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:17,698:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:19,135:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:19,176:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:19,647:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:19,691:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:20,642:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:20,664:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:20,674:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:21,001:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:21,166:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:21,182:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:21,188:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:21,582:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:22,511:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:22,583:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:23,054:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:23,124:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:23,790:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:23,809:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:24,212:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:24,289:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:24,296:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:24,503:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:24,746:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:24,979:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:26,338:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:26,546:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:26,785:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:26,868:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:27,061:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:27,287:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:27,997:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:28,018:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:28,507:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:28,564:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:28,607:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:29,194:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:29,353:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:29,669:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:29,879:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:30,187:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:30,651:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:31,174:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:31,828:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:32,057:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:32,159:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:32,382:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:32,596:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:32,651:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:32,684:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:32,821:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:33,171:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:33,401:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:34,527:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:35,063:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:35,246:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:35,248:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:35,640:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:35,794:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:35,849:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:36,224:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:36,229:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:36,247:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:36,759:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:36,781:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:38,317:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:38,425:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:38,794:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:38,870:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:39,007:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:39,248:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:39,356:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:39,597:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:39,773:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:39,817:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:40,100:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:40,269:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:41,987:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:42,213:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:42,412:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:42,556:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:42,701:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:42,763:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:42,956:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:43,127:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:43,230:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:43,466:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:43,655:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:43,984:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:45,400:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:45,568:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:45,670:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:45,908:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:45,942:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:46,076:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:46,164:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:46,466:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:46,486:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:46,974:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:47,027:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:47,457:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:48,781:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:48,795:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:49,211:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:49,303:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:49,319:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:49,366:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:49,747:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:49,894:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:50,139:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:50,559:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:50,669:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:51,085:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:51,774:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:52,012:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:52,291:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:52,517:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:53,093:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:53,412:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:53,642:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:53,949:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:54,210:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:54,452:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:54,730:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:54,740:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:54,976:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:55,117:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:55,265:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:55,620:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:56,786:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:57,308:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:57,411:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:57,520:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:57,934:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:58,039:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:58,428:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:58,820:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:58,965:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:59,066:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:25:59,350:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:25:59,599:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:26:00,015:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:26:00,579:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:26:00,693:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:26:01,190:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:26:01,225:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:26:01,700:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:26:01,881:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:26:02,258:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:26:02,405:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:26:02,483:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:26:02,774:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:26:02,994:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:26:04,826:INFO:best_params: {'actual_estimator__weight_4': 0.15000000000000002, 'actual_estimator__weight_3': 0.35000000000000003, 'actual_estimator__weight_2': 0.36000000000000004, 'actual_estimator__weight_1': 0.68, 'actual_estimator__weight_0': 0.9600000000000001}
2024-11-28 17:26:04,827:INFO:Hyperparameter search completed
2024-11-28 17:26:04,827:INFO:Getting base sklearn object from tunable
2024-11-28 17:26:04,849:INFO:SubProcess create_model() called ==================================
2024-11-28 17:26:04,853:INFO:Initializing create_model()
2024-11-28 17:26:04,854:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator=VotingClassifier(estimators=[('Random Forest Classifier',
                              RandomForestClassifier(bootstrap=True,
                                                     ccp_alpha=0.0,
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs...
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft',
                 weights=[0.9600000000000001, 0.68, 0.36000000000000004,
                          0.35000000000000003, 0.15000000000000002]), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000189B84720E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'estimators': [('Random Forest Classifier', RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)), ('Gradient Boosting Classifier', GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)), ('CatBoost Classifier', <catboost.core.CatBoostClassifier object at 0x00000189BA2124D0>), ('Ada Boost Classifier', AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)), ('Logistic Regression', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False))], 'flatten_transform': True, 'n_jobs': -1, 'voting': 'soft', 'weights': [0.9600000000000001, 0.68, 0.36000000000000004, 0.35000000000000003, 0.15000000000000002]})
2024-11-28 17:26:04,854:INFO:Checking exceptions
2024-11-28 17:26:04,854:INFO:Importing libraries
2024-11-28 17:26:04,854:INFO:Copying training dataset
2024-11-28 17:26:04,859:INFO:Defining folds
2024-11-28 17:26:04,859:INFO:Declaring metric variables
2024-11-28 17:26:04,862:INFO:Importing untrained model
2024-11-28 17:26:04,862:INFO:Declaring custom model
2024-11-28 17:26:04,866:INFO:Voting Classifier Imported successfully
2024-11-28 17:26:04,874:INFO:Starting cross validation
2024-11-28 17:26:04,876:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:26:04,951:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:26:04,965:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:26:04,981:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:26:04,995:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:26:05,114:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:26:05,174:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:26:05,625:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:26:05,634:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:26:05,640:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:26:05,779:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:26:05,800:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:26:05,869:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:26:07,842:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:26:08,362:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:26:09,140:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:26:09,170:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:26:09,200:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:26:09,662:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:26:09,681:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:26:09,687:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:26:11,614:INFO:Calculating mean and std
2024-11-28 17:26:11,616:INFO:Creating metrics dataframe
2024-11-28 17:26:11,620:INFO:Finalizing model
2024-11-28 17:26:11,668:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:26:11,889:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:26:13,395:INFO:Uploading results into container
2024-11-28 17:26:13,396:INFO:Uploading model into container now
2024-11-28 17:26:13,397:INFO:_master_model_container: 34
2024-11-28 17:26:13,397:INFO:_display_container: 5
2024-11-28 17:26:13,401:INFO:VotingClassifier(estimators=[('Random Forest Classifier',
                              RandomForestClassifier(bootstrap=True,
                                                     ccp_alpha=0.0,
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs...
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft',
                 weights=[0.9600000000000001, 0.68, 0.36000000000000004,
                          0.35000000000000003, 0.15000000000000002])
2024-11-28 17:26:13,401:INFO:create_model() successfully completed......................................
2024-11-28 17:26:13,462:INFO:SubProcess create_model() end ==================================
2024-11-28 17:26:13,462:INFO:choose_better activated
2024-11-28 17:26:13,464:INFO:SubProcess create_model() called ==================================
2024-11-28 17:26:13,468:INFO:Initializing create_model()
2024-11-28 17:26:13,468:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator=VotingClassifier(estimators=[('Random Forest Classifier',
                              RandomForestClassifier(bootstrap=True,
                                                     ccp_alpha=0.0,
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs...
                                                 random_state=123)),
                             ('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:26:13,468:INFO:Checking exceptions
2024-11-28 17:26:13,470:INFO:Importing libraries
2024-11-28 17:26:13,470:INFO:Copying training dataset
2024-11-28 17:26:13,475:INFO:Defining folds
2024-11-28 17:26:13,475:INFO:Declaring metric variables
2024-11-28 17:26:13,475:INFO:Importing untrained model
2024-11-28 17:26:13,475:INFO:Declaring custom model
2024-11-28 17:26:13,477:INFO:Voting Classifier Imported successfully
2024-11-28 17:26:13,477:INFO:Starting cross validation
2024-11-28 17:26:13,478:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-28 17:26:13,551:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:26:13,601:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:26:13,613:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:26:13,642:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:26:13,649:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:26:13,666:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:26:14,216:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:26:14,227:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:26:14,242:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:26:14,261:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:26:14,268:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:26:14,279:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:26:16,327:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:26:16,422:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:26:16,853:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:26:16,954:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:26:17,371:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:26:17,393:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:26:17,931:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:26:17,987:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:26:19,911:INFO:Calculating mean and std
2024-11-28 17:26:19,912:INFO:Creating metrics dataframe
2024-11-28 17:26:19,913:INFO:Finalizing model
2024-11-28 17:26:19,955:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:26:20,150:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:26:21,488:INFO:Uploading results into container
2024-11-28 17:26:21,489:INFO:Uploading model into container now
2024-11-28 17:26:21,489:INFO:_master_model_container: 35
2024-11-28 17:26:21,489:INFO:_display_container: 6
2024-11-28 17:26:21,493:INFO:VotingClassifier(estimators=[('Random Forest Classifier',
                              RandomForestClassifier(bootstrap=True,
                                                     ccp_alpha=0.0,
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs...
                                                 random_state=123)),
                             ('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2024-11-28 17:26:21,493:INFO:create_model() successfully completed......................................
2024-11-28 17:26:21,557:INFO:SubProcess create_model() end ==================================
2024-11-28 17:26:21,561:INFO:VotingClassifier(estimators=[('Random Forest Classifier',
                              RandomForestClassifier(bootstrap=True,
                                                     ccp_alpha=0.0,
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs...
                                                 random_state=123)),
                             ('Logistic Regression',
                              LogisticRegression(C=1.0, class_weight=None,
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None) result for Accuracy is 0.8153
2024-11-28 17:26:21,565:INFO:VotingClassifier(estimators=[('Random Forest Classifier',
                              RandomForestClassifier(bootstrap=True,
                                                     ccp_alpha=0.0,
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs...
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft',
                 weights=[0.9600000000000001, 0.68, 0.36000000000000004,
                          0.35000000000000003, 0.15000000000000002]) result for Accuracy is 0.8233
2024-11-28 17:26:21,569:INFO:VotingClassifier(estimators=[('Random Forest Classifier',
                              RandomForestClassifier(bootstrap=True,
                                                     ccp_alpha=0.0,
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs...
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft',
                 weights=[0.9600000000000001, 0.68, 0.36000000000000004,
                          0.35000000000000003, 0.15000000000000002]) is best model
2024-11-28 17:26:21,569:INFO:choose_better completed
2024-11-28 17:26:21,580:INFO:_master_model_container: 35
2024-11-28 17:26:21,580:INFO:_display_container: 5
2024-11-28 17:26:21,586:INFO:VotingClassifier(estimators=[('Random Forest Classifier',
                              RandomForestClassifier(bootstrap=True,
                                                     ccp_alpha=0.0,
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs...
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft',
                 weights=[0.9600000000000001, 0.68, 0.36000000000000004,
                          0.35000000000000003, 0.15000000000000002])
2024-11-28 17:26:21,586:INFO:tune_model() successfully completed......................................
2024-11-28 17:26:21,751:INFO:Initializing evaluate_model()
2024-11-28 17:26:21,753:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator=VotingClassifier(estimators=[('Random Forest Classifier',
                              RandomForestClassifier(bootstrap=True,
                                                     ccp_alpha=0.0,
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs...
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft',
                 weights=[0.9600000000000001, 0.68, 0.36000000000000004,
                          0.35000000000000003, 0.15000000000000002]), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-11-28 17:26:21,775:INFO:Initializing plot_model()
2024-11-28 17:26:21,775:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Random Forest Classifier',
                              RandomForestClassifier(bootstrap=True,
                                                     ccp_alpha=0.0,
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs...
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft',
                 weights=[0.9600000000000001, 0.68, 0.36000000000000004,
                          0.35000000000000003, 0.15000000000000002]), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, system=True)
2024-11-28 17:26:21,775:INFO:Checking exceptions
2024-11-28 17:26:21,777:INFO:Preloading libraries
2024-11-28 17:26:21,802:INFO:Copying training dataset
2024-11-28 17:26:21,802:INFO:Plot type: pipeline
2024-11-28 17:26:21,959:INFO:Visual Rendered Successfully
2024-11-28 17:26:22,028:INFO:plot_model() successfully completed......................................
2024-11-28 17:26:22,037:INFO:Initializing finalize_model()
2024-11-28 17:26:22,037:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator=VotingClassifier(estimators=[('Random Forest Classifier',
                              RandomForestClassifier(bootstrap=True,
                                                     ccp_alpha=0.0,
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs...
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft',
                 weights=[0.9600000000000001, 0.68, 0.36000000000000004,
                          0.35000000000000003, 0.15000000000000002]), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-11-28 17:26:22,042:INFO:Finalizing VotingClassifier(estimators=[('Random Forest Classifier',
                              RandomForestClassifier(bootstrap=True,
                                                     ccp_alpha=0.0,
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs...
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft',
                 weights=[0.9600000000000001, 0.68, 0.36000000000000004,
                          0.35000000000000003, 0.15000000000000002])
2024-11-28 17:26:22,050:INFO:Initializing create_model()
2024-11-28 17:26:22,050:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator=VotingClassifier(estimators=[('Random Forest Classifier',
                              RandomForestClassifier(bootstrap=True,
                                                     ccp_alpha=0.0,
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs...
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft',
                 weights=[0.9600000000000001, 0.68, 0.36000000000000004,
                          0.35000000000000003, 0.15000000000000002]), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-11-28 17:26:22,050:INFO:Checking exceptions
2024-11-28 17:26:22,052:INFO:Importing libraries
2024-11-28 17:26:22,052:INFO:Copying training dataset
2024-11-28 17:26:22,052:INFO:Defining folds
2024-11-28 17:26:22,053:INFO:Declaring metric variables
2024-11-28 17:26:22,053:INFO:Importing untrained model
2024-11-28 17:26:22,053:INFO:Declaring custom model
2024-11-28 17:26:22,054:INFO:Voting Classifier Imported successfully
2024-11-28 17:26:22,056:INFO:Cross validation set to False
2024-11-28 17:26:22,056:INFO:Fitting Model
2024-11-28 17:26:22,110:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-28 17:26:22,314:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-28 17:26:24,012:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare',
                                             'FamilySize', 'IsAlone'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Transfor...
                                                                  fit_intercept=True,
                                                                  intercept_scaling=1,
                                                                  l1_ratio=None,
                                                                  max_iter=1000,
                                                                  multi_class='auto',
                                                                  n_jobs=None,
                                                                  penalty='l2',
                                                                  random_state=123,
                                                                  solver='lbfgs',
                                                                  tol=0.0001,
                                                                  verbose=0,
                                                                  warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=[0.9600000000000001, 0.68,
                                           0.36000000000000004,
                                           0.35000000000000003,
                                           0.15000000000000002]))],
         verbose=False)
2024-11-28 17:26:24,012:INFO:create_model() successfully completed......................................
2024-11-28 17:26:24,089:INFO:_master_model_container: 35
2024-11-28 17:26:24,089:INFO:_display_container: 5
2024-11-28 17:26:24,120:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare',
                                             'FamilySize', 'IsAlone'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Transfor...
                                                                  fit_intercept=True,
                                                                  intercept_scaling=1,
                                                                  l1_ratio=None,
                                                                  max_iter=1000,
                                                                  multi_class='auto',
                                                                  n_jobs=None,
                                                                  penalty='l2',
                                                                  random_state=123,
                                                                  solver='lbfgs',
                                                                  tol=0.0001,
                                                                  verbose=0,
                                                                  warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=[0.9600000000000001, 0.68,
                                           0.36000000000000004,
                                           0.35000000000000003,
                                           0.15000000000000002]))],
         verbose=False)
2024-11-28 17:26:24,120:INFO:finalize_model() successfully completed......................................
2024-11-28 17:26:24,208:INFO:Initializing predict_model()
2024-11-28 17:26:24,209:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare',
                                             'FamilySize', 'IsAlone'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 Transfor...
                                                                  fit_intercept=True,
                                                                  intercept_scaling=1,
                                                                  l1_ratio=None,
                                                                  max_iter=1000,
                                                                  multi_class='auto',
                                                                  n_jobs=None,
                                                                  penalty='l2',
                                                                  random_state=123,
                                                                  solver='lbfgs',
                                                                  tol=0.0001,
                                                                  verbose=0,
                                                                  warm_start=False))],
                                  flatten_transform=True, n_jobs=-1,
                                  verbose=False, voting='soft',
                                  weights=[0.9600000000000001, 0.68,
                                           0.36000000000000004,
                                           0.35000000000000003,
                                           0.15000000000000002]))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000189CEE27910>)
2024-11-28 17:26:24,209:INFO:Checking exceptions
2024-11-28 17:26:24,209:INFO:Preloading libraries
2024-11-28 17:26:24,210:INFO:Set up data.
2024-11-28 17:26:24,213:INFO:Set up index.
2024-11-28 17:26:28,077:INFO:Initializing plot_model()
2024-11-28 17:26:28,077:INFO:plot_model(plot=auc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Random Forest Classifier',
                              RandomForestClassifier(bootstrap=True,
                                                     ccp_alpha=0.0,
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs...
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft',
                 weights=[0.9600000000000001, 0.68, 0.36000000000000004,
                          0.35000000000000003, 0.15000000000000002]), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, system=True)
2024-11-28 17:26:28,077:INFO:Checking exceptions
2024-11-28 17:26:28,080:INFO:Preloading libraries
2024-11-28 17:26:28,104:INFO:Copying training dataset
2024-11-28 17:26:28,104:INFO:Plot type: auc
2024-11-28 17:26:28,251:INFO:Fitting Model
2024-11-28 17:26:28,252:WARNING:c:\Users\tsai\Desktop\aiot_data_analysis\tensorflow_gpu_env\lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names
  warnings.warn(

2024-11-28 17:26:28,252:INFO:Scoring test/hold-out set
2024-11-28 17:26:28,494:INFO:Visual Rendered Successfully
2024-11-28 17:26:28,555:INFO:plot_model() successfully completed......................................
2024-11-28 17:26:30,454:INFO:Initializing plot_model()
2024-11-28 17:26:30,455:INFO:plot_model(plot=vc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Random Forest Classifier',
                              RandomForestClassifier(bootstrap=True,
                                                     ccp_alpha=0.0,
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs...
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft',
                 weights=[0.9600000000000001, 0.68, 0.36000000000000004,
                          0.35000000000000003, 0.15000000000000002]), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, system=True)
2024-11-28 17:26:30,455:INFO:Checking exceptions
2024-11-28 17:26:30,457:INFO:Preloading libraries
2024-11-28 17:26:30,476:INFO:Copying training dataset
2024-11-28 17:26:30,476:INFO:Plot type: vc
2024-11-28 17:26:30,477:INFO:Determining param_name
2024-11-28 17:26:33,274:INFO:Initializing plot_model()
2024-11-28 17:26:33,275:INFO:plot_model(plot=calibration, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=VotingClassifier(estimators=[('Random Forest Classifier',
                              RandomForestClassifier(bootstrap=True,
                                                     ccp_alpha=0.0,
                                                     class_weight=None,
                                                     criterion='gini',
                                                     max_depth=None,
                                                     max_features='sqrt',
                                                     max_leaf_nodes=None,
                                                     max_samples=None,
                                                     min_impurity_decrease=0.0,
                                                     min_samples_leaf=1,
                                                     min_samples_split=2,
                                                     min_weight_fraction_leaf=0.0,
                                                     monotonic_cst=None,
                                                     n_estimators=100,
                                                     n_jobs...
                                                 dual=False, fit_intercept=True,
                                                 intercept_scaling=1,
                                                 l1_ratio=None, max_iter=1000,
                                                 multi_class='auto',
                                                 n_jobs=None, penalty='l2',
                                                 random_state=123,
                                                 solver='lbfgs', tol=0.0001,
                                                 verbose=0,
                                                 warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft',
                 weights=[0.9600000000000001, 0.68, 0.36000000000000004,
                          0.35000000000000003, 0.15000000000000002]), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000189BA20A860>, system=True)
2024-11-28 17:26:33,275:INFO:Checking exceptions
2024-11-28 17:26:33,277:INFO:Preloading libraries
2024-11-28 17:26:33,296:INFO:Copying training dataset
2024-11-28 17:26:33,296:INFO:Plot type: calibration
2024-11-28 17:26:33,307:INFO:Scoring test/hold-out set
2024-11-28 17:26:33,539:INFO:Visual Rendered Successfully
2024-11-28 17:26:33,607:INFO:plot_model() successfully completed......................................
